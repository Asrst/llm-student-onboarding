question,contexts,ground_truth,evolution_type,metadata,episode_done
What are the different types of data sources used for augmentation in RAG models?,"['various question-answering tasks.\nIn essence, these inference-stage enhancements provide\nlightweight, cost-effective alternatives that leverage the ca-\npabilities of pre-trained models without necessitating further\ntraining. The principal advantage is maintaining static LLM\nparameters while supplying contextually relevant information\nto meet specific task demands. Nevertheless, this approach is\nnot without limitations, as it requires meticulous data pro-\ncessing and optimization, and is bound by the foundational\nmodel’s intrinsic capabilities. To address diverse task require-\nments effectively, this method is often paired with procedural\noptimization techniques such as step-wise reasoning, iterative\nretrieval, and adaptive retrieval strategies.\n6.2 Augmentation Source\nThe effectiveness of RAG models is heavily impacted by the\nselection of data sources for augmentation. Different levels of\nknowledge and dimensions require distinct processing tech-\nniques. They are categorized as unstructured data, structured\ndata, and content generated by LLMs. The technology tree\nof representative RAG research with different augmentation\naspects is depicted in Figure 5. The leaves, colored in three\ndifferent shades, represent enhancements using various types\nof data: unstructured data, structured data, and content gener-\nated by LLMs. The diagram clearly shows that initially, aug-\nmentation was mainly achieved through unstructured data,\nsuch as pure text. This approach later expanded to include\nthe use of structured data (e.g. knowledge graph) for further\nimprovement. More recently, there has been a growing trend\nin research that utilizes content generated by the LLMs them-\nselves for retrieval and augmentation purposes.\nAugmented with Unstructured Data\nUnstructured text, is gathered from corpora, such as prompt\ndata for fine-tuning large models [Cheng et al. , 2023a ]and\ncross-lingual data [Liet al. , 2023b ]. Retrieval units vary from\ntokens (e.g., kNN-LM [Khandelwal et al. , 2019 ]) to phrases\n(e.g., NPM, COG [Leeet al. , 2020, Lan et al. , 2022 ]) and\ndocument paragraphs, with finer granularities offering pre-\ncision at the cost of increased retrieval complexity.\nFLARE [Jiang et al. , 2023b ]introduces an active re-\ntrieval approach, triggered by the LM’s generation of low-\nprobability words. It creates a temporary sentence for doc-\nument retrieval, then regenerates the sentence with the re-\ntrieved context to predict subsequent sentences. RETRO uses\nthe previous chunk to retrieve the nearest neighbor at the\nchunk level, combined with the previous chunk’s context, it\nguides the generation of the next chunk. To preserve causal-\nity, the generation of the next block Cionly utilizes the near-\nest neighbor of the previous block N(Ci−1)and not N(Ci).\nAugmented with Structured Data\nStructured data, such as knowledge graphs (KGs), pro-\nvide high-quality context and mitigate model hallucina-\ntions. RET-LLMs [Modarressi et al. , 2023 ]constructs a\nknowledge graph memory from past dialogues for future ref-\nerence. SUGRE [Kang et al. , 2023 ]employs Graph Neu-\nral Networks (GNNs) to encode relevant KG subgraphs,\nensuring consistency between retrieved facts and gener-\nated text through multi-modal contrastive learning. Knowl-edGPT [Wang et al. , 2023d ]generates KB search queries and\nstores knowledge in a personalized base, enhancing the RAG\nmodel’s knowledge richness and contextuality.\nLLMs-Generated Content in RAG\nAddressing the limitations of external auxiliary information\nin RAG, some research has focused on exploiting LLMs’ in-\nternal knowledge. SKR [Wang et al. , 2023e ]classifies ques-\ntions as known or unknown, applying retrieval enhancement\nselectively. GenRead [Yuet al. , 2022 ]replaces the retriever\nwith an LLM generator, finding that LLM-generated con-\ntexts often contain more accurate answers due to better align-\nment with the pre-training objectives of causal language mod-\neling. Selfmem [Cheng et al. , 2023b ]iteratively creates an\nunbounded memory pool with a retrieval-enhanced genera-\ntor, using a memory selector to choose outputs that serve as\ndual problems to the original question, thus self-enhancing\nthe generative model.\nThese methodologies']","The different types of data sources used for augmentation in RAG models are unstructured data, structured data, and content generated by LLMs.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 13, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What is the purpose of Retrieval-Augmented Generation in refining the capabilities of chat?,"['Retrieval-Augmented Generation for Large Language Models: A Survey\nYunfan Gao1,Yun Xiong2,Xinyu Gao2,Kangxiang Jia2,Jinliu Pan2,Yuxi Bi3,Yi\nDai1,Jiawei Sun1,Qianyu Guo4,Meng Wang3and Haofen Wang1,3∗\n1Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University\n2Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n3College of Design and Innovation, Tongji University\n4School of Computer Science, Fudan University\nAbstract\nLarge Language Models (LLMs) demonstrate\nsignificant capabilities but face challenges such\nas hallucination, outdated knowledge, and non-\ntransparent, untraceable reasoning processes.\nRetrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating\nknowledge from external databases. This enhances\nthe accuracy and credibility of the models, particu-\nlarly for knowledge-intensive tasks, and allows for\ncontinuous knowledge updates and integration of\ndomain-specific information. RAG synergistically\nmerges LLMs’ intrinsic knowledge with the vast,\ndynamic repositories of external databases. This\ncomprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms,\nencompassing the Naive RAG, the Advanced RAG,\nand the Modular RAG. It meticulously scrutinizes\nthe tripartite foundation of RAG frameworks,\nwhich includes the retrieval , the generation and\nthe augmentation techniques. The paper highlights\nthe state-of-the-art technologies embedded in\neach of these critical components, providing a\nprofound understanding of the advancements in\nRAG systems. Furthermore, this paper introduces\nthe metrics and benchmarks for assessing RAG\nmodels, along with the most up-to-date evaluation\nframework. In conclusion, the paper delineates\nprospective avenues for research, including the\nidentification of challenges, the expansion of\nmulti-modalities, and the progression of the RAG\ninfrastructure and its ecosystem.1.\n1 Introduction\nLarge language models (LLMs) such as the GPT se-\nries[Brown et al. , 2020, OpenAI, 2023 ]and the LLama se-\nries [Touvron et al. , 2023 ], along with other models like\nGemini [Google, 2023 ], have achieved remarkable suc-\ncess in natural language processing, demonstrating supe-\n∗Corresponding Author.Email:haofen.wang@tongji.edu.cn\n1Resources are available at https://github.com/Tongji-KGLLM/\nRAG-Surveyrior performance on various benchmarks including Super-\nGLUE [Wang et al. , 2019 ], MMLU [Hendrycks et al. , 2020 ],\nand BIG-bench [Srivastava et al. , 2022 ]. Despite these\nadvancements, LLMs exhibit notable limitations, par-\nticularly in handling domain-specific or highly special-\nized queries [Kandpal et al. , 2023 ]. A common issue is\nthe generation of incorrect information, or ”hallucina-\ntions” [Zhang et al. , 2023b ], especially when queries extend\nbeyond the model’s training data or necessitate up-to-date in-\nformation. These shortcomings underscore the impractical-\nity of deploying LLMs as black-box solutions in real-world\nproduction environments without additional safeguards. One\npromising approach to mitigate these limitations is Retrieval-\nAugmented Generation (RAG), which integrates external\ndata retrieval into the generative process, thereby enhancing\nthe model’s ability to provide accurate and relevant responses.\nRAG, introduced by Lewis et al. [Lewis et al. , 2020 ]in\nmid-2020, stands as a paradigm within the realm of LLMs,\nenhancing generative tasks. Specifically, RAG involves an\ninitial retrieval step where the LLMs query an external data\nsource to obtain relevant information before proceeding to an-\nswer questions or generate text. This process not only informs\nthe subsequent generation phase but also ensures that the re-\nsponses are grounded in retrieved evidence, thereby signif-\nicantly enhancing the accuracy and relevance of the output.\nThe dynamic retrieval of information from knowledge bases\nduring the inference phase allows RAG to address issues such\nas the generation of factually incorrect content, commonly\nreferred to as “hallucinations.” The integration of RAG into\nLLMs has seen rapid adoption and has become a pivotal tech-\nnology in refining the capabilities of chat']","Retrieval-Augmented Generation (RAG) is integrated into Large Language Models (LLMs) to enhance their capabilities in chat. RAG involves an initial retrieval step where LLMs query an external data source to obtain relevant information, ensuring that the responses are grounded in retrieved evidence. This significantly enhances the accuracy and relevance of the output, addressing issues such as the generation of factually incorrect content or 'hallucinations'. Therefore, the purpose of RAG is to improve the accuracy and quality of chat responses by incorporating external knowledge.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 0, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are some challenges and advancements in RAG models?,"['certain. Initial studies [Wang et al. , 2023b ]have begun to ad-\ndress this, yet the parameter count in RAG models still lags\nbehind that of LLMs. The possibility of an Inverse Scaling\nLaw9, where smaller models outperform larger ones, is par-\nticularly intriguing and merits further investigation.\nProduction-Ready RAG . RAG’s practicality and alignment\nwith engineering requirements have facilitated its adoption.\nHowever, enhancing retrieval efficiency, improving document\nrecall in large knowledge bases, and ensuring data secu-\nrity—such as preventing inadvertent disclosure of document\nsources or metadata by LLMs—are critical engineering chal-\nlenges that remain to be addressed [Alon et al. , 2022 ].\nModality Extension of RAG\nRAG has transcended its initial text-based question-\nanswering confines, embracing a diverse array of modal data.\nThis expansion has spawned innovative multimodal models\nthat integrate RAG concepts across various domains:\nImage . RA-CM3 [Yasunaga et al. , 2022 ]stands as a pio-\nneering multimodal model of both retrieving and generating\ntext and images. BLIP-2 [Liet al. , 2023a ]leverages frozen\nimage encoders alongside LLMs for efficient visual language\npre-training, enabling zero-shot image-to-text conversions.\nThe “Visualize Before You Write” method [Zhuet al. , 2022 ]\nemploys image generation to steer the LM’s text generation,\nshowing promise in open-ended text generation tasks.\nAudio and Video . The GSS method retrieves and stitches\ntogether audio clips to convert machine-translated data into\nspeech-translated data [Zhao et al. , 2022 ]. UEOP marks\na significant advancement in end-to-end automatic speech\nrecognition by incorporating external, offline strategies for\nvoice-to-text conversion [Chan et al. , 2023 ]. Additionally,\nKNN-based attention fusion leverages audio embeddings and\nsemantically related text embeddings to refine ASR, thereby\naccelerating domain adaptation. Vid2Seq augments language\nmodels with specialized temporal markers, facilitating the\nprediction of event boundaries and textual descriptions within\na unified output sequence [Yang et al. , 2023a ].\nCode . RBPS [Nashid et al. , 2023 ]excels in small-scale\nlearning tasks by retrieving code examples that align with de-\nvelopers’ objectives through encoding and frequency analy-\nsis. This approach has demonstrated efficacy in tasks such as\ntest assertion generation and program repair. For structured\nknowledge, the CoK method [Liet al. , 2023c ]first extracts\nfacts pertinent to the input query from a knowledge graph,\nthen integrates these facts as hints within the input, enhancing\nperformance in knowledge graph question-answering tasks.\n8.2 Ecosystem of RAG\nDownstream Tasks and Evaluation\nRAG has shown considerable promise in enriching language\nmodels with the capacity to handle intricate queries and pro-\nduce detailed responses by leveraging extensive knowledge\nbases. Empirical evidence suggests that RAG excels in a\nvariety of downstream tasks, including open-ended question\nanswering and fact verification. The integration of RAG not\nonly bolsters the precision and relevance of responses but also\ntheir diversity and depth.\n9https://github.com/inverse-scaling/prizeThe scalability and versatility of RAG across multiple do-\nmains warrant further investigation, particularly in special-\nized fields such as medicine, law, and education. In these ar-\neas, RAG could potentially reduce training costs and enhance\nperformance compared to traditional fine-tuning approaches\nin professional domain knowledge question answering.\nConcurrently, refining the evaluation framework for RAG\nis essential to maximize its efficacy and utility across different\ntasks. This entails the development of nuanced metrics and\nassessment tools that can gauge aspects such as contextual\nrelevance, creativity of content, and non-maleficence.\nFurthermore, improving the interpretability of RAG-driven\nmodels continues to be a key goal. Doing so would allow\nusers to understand the reasoning behind the responses gener-\nated by the model, thereby promoting trust and transparency\nin the use of RAG applications.\nTechnical Stack\nThe development of the RAG ecosystem is greatly impacted\nby the progression of its technical stack. Key tools like\nLangChain and LLamaIndex have quickly gained popularity\nwith the emergence of ChatGPT, providing extensive RAG-\nrelated APIs and becoming essential in the realm of LLMs.\nEmerging technical stacks, while not as feature-rich']","Enhancing retrieval efficiency, improving document recall in large knowledge bases, and ensuring data security are critical engineering challenges in RAG models. Advancements include the expansion of RAG to embrace multimodal data, such as images, audio, video, and code. There have been innovations in multimodal models that integrate RAG concepts across various domains, such as RA-CM3 for text and image retrieval and generation, BLIP-2 for efficient visual language pre-training, and GSS for speech translation. Additionally, there have been advancements in end-to-end automatic speech recognition and code retrieval. The development of the RAG ecosystem is also influenced by the progression of its technical stack, with tools like LangChain and LLamaIndex gaining popularity.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 19, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
How can the retriever's output be aligned with the preferences of the Large Language Model?,"['While these methods improve semantic representation\nby incorporating domain knowledge and task-specific fine-\ntuning, retrievers may not always exhibit optimal compatibil-\nity with certain LLMs. To address this, some researchers have\nexplored direct supervision of the fine-tuning process using\nfeedback from LLMs. This direct supervision seeks to align\nthe retriever more closely with the LLM, thereby improving\nperformance on downstream tasks. A more comprehensive\ndiscussion on this topic is presented in Section 4.3.\n4.2 Aligning Queries and Documents\nIn the context of RAG applications, retrievers may utilize\na single embedding model for encoding both the query and\nthe documents, or employ separate models for each. Addi-\ntionally, the user’s original query may suffer from imprecise\nphrasing and lack of semantic information. Therefore, it is\ncrucial to align the semantic space of the user’s query with\nthose of the documents. This section introduces two funda-\nmental techniques aimed at achieving this alignment.\nQuery Rewriting\nQuery rewriting is a fundamental approach for aligning\nthe semantics of a query and a document. Methods\nsuch as Query2Doc and ITER-RETGEN leverage LLMs\nto create a pseudo-document by combining the origi-\nnal query with additional guidance [Wang et al. , 2023c,\nShao et al. , 2023 ]. HyDE constructs query vectors using\ntextual cues to generate a “hypothetical” document captur-\ning essential patterns [Gao et al. , 2022 ]. RRR introduces a\nframework that reverses the traditional retrieval and read-\ning order, focusing on query rewriting [Maet al. , 2023a ].\nSTEP-BACKPROMPTING enables LLMs to perform ab-\nstract reasoning and retrieval based on high-level con-\ncepts [Zheng et al. , 2023 ]. Additionally, the multi-query re-\ntrieval method utilizes LLMs to generate and execute multiple\nsearch queries simultaneously, advantageous for addressing\ncomplex problems with multiple sub-problems.\nEmbedding Transformation\nBeyond broad strategies such as query rewriting, there exist\nmore granular techniques specifically designed for embed-\nding transformations. LlamaIndex [Liu, 2023 ]exemplifies\nthis by introducing an adapter module that can be integrated\nfollowing the query encoder. This adapter facilitates fine-\ntuning, thereby optimizing the representation of query em-\nbeddings to map them into a latent space that is more closely\naligned with the intended tasks.\nThe challenge of aligning queries with structured exter-\nnal documents, particularly when addressing the incongruity\nbetween structured and unstructured data, is addressed by\nSANTA [Liet al. , 2023d ]. It enhances the retriever’s sen-\nsitivity to structured information through two pre-training\nstrategies: first, by leveraging the intrinsic alignment between\nstructured and unstructured data to inform contrastive learn-\ning in a structured-aware pre-training scheme; and second, by\nimplementing Masked Entity Prediction. The latter utilizes\nan entity-centric masking strategy that encourages language\nmodels to predict and fill in the masked entities, thereby fos-\ntering a deeper understanding of structured data.The issue of aligning queries with structured exter-\nnal documents, especially when dealing with the dispar-\nity between structured and unstructured data, is tackled by\nSANTA [Liet al. , 2023d ]. This approach improves the re-\ntriever’s ability to recognize structured information through\ntwo pre-training strategies: firstly, by utilizing the inher-\nent alignment between structured and unstructured data to\nguide contrastive learning in a structured-aware pre-training\nscheme; and secondly, by employing Masked Entity Predic-\ntion. The latter uses an entity-centric masking strategy to\nprompt language models to predict and complete the masked\nentities, thus promoting a more profound comprehension of\nstructured data.\n4.3 Aligning Retriever and LLM\nIn the RAG pipeline, enhancing retrieval hit rate through var-\nious techniques may not necessarily improve the final out-\ncome, as the retrieved documents may not align with the spe-\ncific requirements of the LLMs. Therefore, this section in-\ntroduces two methods aimed at aligning the retriever outputs\nwith the preferences of the LLMs.\nFine-tuning Retrievers\nSeveral studies utilize feedback signals from LLMs to refine\nretrieval models. For instance, AAR [Yuet al. , 2023b ]intro-\nduces supervisory signals for a pre-trained retriever', 'can align the semantic spaces of queries and documents? 3)\nHow can the retriever’s output be aligned with the preferences\nof the Large Language Model?\n4.1 Enhancing Semantic Representations\nIn RAG, the semantic space is essential as it involves the mul-\ntidimensional mapping of queries and documents. Retrieval\naccuracy in this semantic space significantly impacts RAG\noutcomes. This section will present two methods for building\naccurate semantic spaces.\nChunk optimization\nWhen managing external documents, the initial step involves\nbreaking them down into smaller chunks to extract fine-\ngrained features, which are then embedded to represent their\nsemantics. However, embedding overly large or excessively\nsmall text chunks may lead to sub-optimal outcomes. There-\nfore, identifying the optimal chunk size for documents within\nthe corpus is crucial to ensuring the accuracy and relevance\nof the retrieved results.\nChoosing an appropriate chunking strategy requires care-\nful consideration of several vital factors, such as the nature\nof the indexed content, the embedding model and its opti-\nmal block size, the expected length and complexity of user\nqueries, and the specific application’s utilization of the re-\ntrieved results. For instance, the selection of a chunking\nmodel should be based on the content’s length—whether it\nis longer or shorter. Additionally, different embedding mod-\nels demonstrate distinct performance characteristics at vary-\ning block sizes. For example, sentence-transformer performs\nbetter with single sentences, while text-embedding-ada-002\nexcels with blocks containing 256 or 512 tokens.\nAdditionally, factors like the length and complexity of user\ninput questions, and the specific needs of the application (e.g.,\nsemantic search or question answering), have effect on the\nchoice of a chunking strategy. This choice can be directly in-\nfluenced by the token limits of the selected LLMs, requiring\nadjustments to the block size. In reality, getting precise query\nresults involves flexibly applying different chunking strate-\ngies. There is no one-size-fits-all ”best” strategy, only the\nmost appropriate one for a particular context.\nCurrent research in RAG explores various block optimiza-\ntion techniques aimed at improving both retrieval efficiency\nand accuracy. One such approach involves the use of slid-\ning window technology, enabling layered retrieval by merg-\ning globally related information across multiple retrieval pro-\ncesses. Another strategy, known as the “small2big” method,\nutilizes small text blocks during the initial search phase and\nsubsequently provides larger related text blocks to the lan-\nguage model for processing.\nThe abstract embedding technique prioritizes top K re-\ntrieval based on document abstracts (or summaries), offering\na comprehensive understanding of the entire document con-\ntext. Additionally, the metadata filtering technique leverages\ndocument metadata to enhance the filtering process. An in-\nnovative approach, the graph indexing technique, transforms\nentities and relationships into nodes and connections, sig-\nnificantly improving relevance, particularly in the context of\nmulti-hop problems.The combination of these diverse methods has led to no-\ntable advancements, resulting in enhanced retrieval outcomes\nand improved performance for RAG.\nFine-tuning Embedding Models\nOnce the appropriate size of chunks is determined, the\nnext crucial step involves embedding these chunks and the\nquery into the semantic space using an embedding model.\nThe effectiveness of the embedding is critical as it impacts\nthe model’s ability to represent the corpus. Recent re-\nsearch has introduced prominent embedding models such as\nAngIE, V oyage, BGE,etc [Li and Li, 2023, V oyageAI, 2023,\nBAAI, 2023 ]. These models have undergone pre-training on\nextensive corpora. However, their capability to accurately\ncapture domain-specific information may be limited when ap-\nplied to specialized domains.\nMoreover, task-specific fine-tuning of embedding models\nis essential to ensure that the model comprehends the user\nquery in terms of content relevance. A model without fine-\ntuning may not adequately address the requirements of a spe-\ncific task. Consequently, fine-tuning an embedding model be-\ncomes crucial for downstream applications. There are two\nprimary paradigms in embedding fine-tuning methods.\nDomain Knowledge Fine-tuning . To ensure that an embed-\nding model accurately captures domain-specific information,\nit is imperative to utilize domain-specific datasets for fine-\ntuning. This process diverges from standard language model\nfine-tuning, chiefly in the nature of the datasets involved.']",Several studies utilize feedback signals from LLMs to refine retrieval models.,simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 8, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 7, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the degree requirements for the MS-BAIS program?,"[""Course Registration BAIS\nSearching for classes and current enrollment:\nYou can search on Oasis, but the staff schedule search  is an easier interface to use.\nVisit http://www .registrar .usf.edu/ssearch/staff/staff.php\n(https://usfweb.usf.edu/DSS/StaffScheduleSearch) (http://www.registrar.usf.edu/ssearch/staff/staff.php) Please\nmake sure that you read the description of the course carefully .  Some courses are only available to students\nwho are enrolled in specific programs, such as the Global BAIS or the Online MBA, and if you are not\nenrolled in these programs, you will not be eligible to register for these courses.\nIf you need to register for an alternate calendar course , you can use the alternate calendar link:\n https://www .usf.edu/registrar/register/altcalendar .aspx\n(https://www.usf.edu/registrar/register/altcalendar.aspx) (https://www.usf.edu/registrar/register/altcalendar.aspx)\n.  If this doesn’t work, email Dr . Reichgelt ( muma-msbais@usf.edu  (mailto:muma-msbais@usf.edu,) ) or\ncontact the Registrar ’s office at 974-2000.\n \nCourse sequencing & prerequisite checks:\nAs described in the catalog  (https://catalog.usf.edu/preview_program.php?\ncatoid=18&poid=7726&hl=%22BAIS%22&returnto=searchhttps://catalog.usf.edu/preview_program.php?\ncatoid=18&poid=7726&hl=%22BAIS%22&returnto=search) , certain classes have course prerequisites (e.g.,\nISM 6124 Advanced Systems Analysis and Design and ISM 6218 Advanced Database Systems  are both\nprerequisites for ISM 6155 Enterprise Information Systems Management ).  In general, you cannot directly\nregister for the advanced classes without completing the prerequisites in a prior semester . Note that\nconcurrent enrollment in prerequisite and advanced classes is not allowed.  \nIn addition, certain core MS-BAIS classes like Advanced Database Management have pre-program\nprerequisites such as a database prerequisite, which can be met by virtue of a prior course in database\nmanagement from your previous university or adequate working experience with databases in a corporate\nenvironment. Similarly , there are prerequisites for Advanced Systems Analysis & Design and Distributed\nInformation Systems. If you don't meet these core prerequisites, you will have to register for basic courses in\nthese areas at USF and these courses will NOT  count toward the 33-credit MS-BAIS degree requirement. If\nyou are unsure which prerequisites you need, email Dr . Reichgelt ( muma-msbais@usf.edu  (mailto:muma-\nmsbais@usf.edu,) ) with your U# and USF email address and request a prerequisite check.  Every new\nstudent must have their prerequisites checked and any outstanding prerequisites should be completed by\nthe end of your first semester .\nThe following are the required pre-program prerequisites:\nDatabase prerequisite  >> prerequisite for >> ISM 6218 Advanced Database Management.\nSystems analysis & design prerequisite  >> prerequisite for >>  ISM 6124 Advanced Systems Analysis &\nDesign \nOOP  prerequisite  >> prerequisite for  >> ISM 6225 Distributed Information Systems \nStats prerequisite  >> prerequisite for > QMB 6304 Analytical Methods for Business"", 'MS-BAIS Advising F AQ\nHow does the MS-BAIS program work?\nThe program requires a minimum of 33 credits, which must include 5 core classes, 3 MS-BAIS electives and\n3 additional electives from our department or other departments if they are 6000 level courses relevant to the\nmajor . Most of these classes are 3 credits each. In addition, you can also take MS-BAIS internships and\nindependent study , which are 1-2 credit courses and those courses will also count toward your 33 credit\ndegree requirements.\nBefore registering for any out-of-department electives, please consult Dr . Johannes Reichgelt to make sure\nthat this course would count toward your degree requirement. For non-departmental courses, you will need a\npermit from that department.\n \nWhat are the dif ferent core and elective course options that I have for my MS-BAIS degree?\nMS-BAIS core classes:\n1. ISM 6124: Advanced Systems Analysis & Design (Prerequisite: Systems Analysis & Design or equivalent\nprofessional knowledge)\n2. ISM 6218: Advanced Database Management (Prerequisite: Database Design/Management or equivalent\nprofessional knowledge)\n3. ISM 6225: Distributed Information Systems (Prerequisite: Object-Oriented Programming or equivalent\nprofessional knowledge)\n4. QMB 6304: Analytical Methods for Business (Prerequisite: One prior course on inferential statistics at\nundergraduate or graduate level)\n5. ISM 6155: Enterprise Information Systems Management (MS-BAIS capstone)\nNOTE : In order not to jeopardize your chances to graduate on time, it is crucial that you complete the core\ncourses as early as possible.  W e have had a number students who did not take core courses when they\nwere available, and then had to postpone their graduation.  This is particularly problematic for international\nstudents who have to maintain a full course load and therefore may have to take more courses than is\nstrictly necessary to complete their program.  While we can ensure that there are suf ficient seats in the core\ncourses overall, we cannot guarantee that you will be able to take a core course in the semester that you\nwant.\nMS-BAIS electives:  \nWe have many electives. This is a partial list of approved electives in no particular order . Refer to our course\ncatalog for a complete list.\n1. ISM 6136: Data Mining\n2. ISM 6419: Data V isualization\n3. ISM 6137: Statistical Data Mining (Prerequisite: QMB 6304)\n4. ISM 6251: Data Science Programming (Prerequisite: ISM 6136)\n5. ISM 6208: Data W arehousing (Prerequisite: ISM 6218)\n6. ISM 6562: Big Data for Business (Prerequisite: ISM 6225)\n7. ISM 6328: Information Security & Risk Management']","The program requires a minimum of 33 credits, which must include 5 core classes, 3 MS-BAIS electives and 3 additional electives from our department or other departments if they are 6000 level courses relevant to the major. Most of these classes are 3 credits each. In addition, you can also take MS-BAIS internships and independent study, which are 1-2 credit courses and those courses will also count toward your 33 credit degree requirements.",simple,"[{'source': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}, {'source': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How does the Master of Business Analytics and Information Systems program facilitate networking opportunities with industry professionals?,"['Pre-Application Phase\n\nUnderstanding Program Fit and Outcomes\n\nQ01: ""How do I know if the Master of Business Analytics and Information Systems program is right for me?""\n\nA01: ""This program is ideal for individuals who have a strong interest in data analysis, technology, and business decision-making. If you\'re passionate about leveraging data to solve complex business problems and drive strategic decisions, this program can provide the skills and knowledge you need. We recommend reviewing our curriculum and speaking with current students or alumni to gauge how well the program aligns with your career goals.""\n\nQ02: ""What specializations are available in the Master of Business Analytics and Information Systems program?""\n\nA1: ""Our program offers several specializations, including Data Analytics, Information Systems Management, Business Intelligence, and more. Each path is designed to equip students with in-demand skills and knowledge relevant to the current job market.""\n\nApplication Strategy\n\nQ01: ""What can I do to strengthen my application?""\n\nA01: ""To strengthen your application, focus on highlighting your quantitative and analytical skills, any relevant work experience, and your passion for the field of business analytics. Letters of recommendation should come from individuals who can speak to your academic and professional abilities. A well-crafted statement of purpose that clearly articulates your career goals and how the program can help you achieve them is also crucial.""\n\nQ02: ""What are the prerequisites for applying to this program?""\n\nA02: ""Applicants are expected to have a bachelor\'s degree from an accredited institution, a fundamental understanding of statistics and computer programming, and a competitive GPA. Additional requirements include letters of recommendation, a statement of purpose, and a resume.""\n\nQ03: ""How can I apply as an international student?""\n\nA03: ""International students can apply through our online application portal. You\'ll need to submit your academic transcripts, proof of English language proficiency (TOEFL/IELTS), financial support documents, and a copy of your passport, among other requirements.""\n\nProgram Differentiators\n\n\n\nQ01: ""What sets your Master of Business Analytics and Information Systems program apart from others?""\n\nA01: ""Our program stands out due to its strong emphasis on practical, hands-on experience, its integration with the latest technologies and industry practices, and the extensive network of alumni and industry partners. Additionally, our faculty includes leading experts in business analytics and information systems, who bring real-world insights and research into the classroom.""\n\nFinancial Planning\n\nQ01: ""What kind of financial aid is available for students?""\n\nA01: ""Our institution offers a variety of financial aid options for students, including scholarships, grants, work-study opportunities, and loans. We recommend prospective students apply for financial aid early to maximize their chances of receiving support. Our financial aid office is available to help you navigate the process and identify the best options for your situation.""\n\nPreparing for the Program\n\nQ01: ""How can I prepare academically for the program?""\n\nA01: ""To prepare academically, we recommend brushing up on your quantitative skills, particularly in statistics and mathematics. Familiarity with programming languages such as Python or R, and database management systems, will also be beneficial. Engaging in online courses or workshops that cover these areas can be a great way to prepare.""\n\nApplication Timing and Deadlines\n\nQ01: ""Is there an advantage to applying early to the program?""\n\nA01: ""Applying early can have several advantages, including receiving an earlier decision, having more time to plan for relocation and financing, and in some cases, being considered for early scholarship awards. We encourage applicants to submit their materials as soon as they are ready to take advantage of these benefits.""\n\nProgram Expectations\n\nQ01: ""What is expected from students in the Master of Business Analytics and Information Systems program?""\n\nA01: ""We expect our students to demonstrate a strong commitment to their studies, a willingness to engage in collaborative and individual projects, and an eagerness to learn and apply new concepts and technologies. Successful students typically possess strong analytical skills, effective communication abilities, and the capacity to think critically and solve complex problems.""\n\nApplication Process\n\n\n\nQ01: ""What documents do I need for the student visa application?""\n\nA01: ""You\'ll need a valid passport, the acceptance letter from our institution, proof of financial support, completed visa application forms, and a passport-sized photograph. Depending on your country, additional documents may be required.""\n\nQ02: ""Is there a deadline for applying to the Master\'s program?""\n\nA02: ""Yes, our application deadlines are as follows: Fall semester - May 1st, Spring semester - October 1st. We recommend applying early to ensure sufficient time for visa processing.""\n\nPost-Acceptance and Pre-Arrival\n\nQ01', ': ""What are the next steps after receiving my acceptance letter?""\n\nA01: ""Congratulations on your acceptance! The next steps include securing your student visa, arranging for housing, registering for classes, and attending the international student orientation. Detailed information will be provided in your acceptance package.""\n\nQ02: ""How do I find accommodation?""\n\nA02: ""Our institution offers on-campus housing options, including dormitories and apartments. Alternatively, you can opt for off-campus housing. Our student services office provides resources and assistance to help you find suitable accommodation.""\n\nOrientation and First Semester\n\nQ01: ""What should I expect during the orientation week?""\n\nA01: ""Orientation week includes campus tours, registration assistance, workshops on academic success, and social events to meet fellow students and faculty. It\'s a great opportunity to get acclimated to the campus and the community.""\n\nQ02: ""How can I register for courses?""\n\nA02: ""Course registration can be completed online through the student portal. If you need guidance on selecting courses relevant to your specialization, academic advisors are available to assist you.""\n\nContinuous Support\n\nQ01: ""Where can I get help if I\'m struggling with my coursework?""\n\nA01: ""We offer a range of support services, including tutoring, study groups, and academic advising. Don\'t hesitate to reach out for help; our goal is to ensure your success.""\n\n\n\nFinancial Information and Scholarships\n\nQ01: ""Are there scholarship opportunities for international students in the Master\'s program?""\n\nA01: ""Yes, our institution offers a range of scholarships for international students based on academic merit, financial need, and leadership qualities. We encourage you to apply early and visit our financial aid website for detailed information on eligibility and application procedures.""\n\nQ02: ""What is the estimated cost of attendance for the Master\'s program?""\n\nA02: ""The estimated cost of attendance includes tuition fees, accommodation, books and supplies, and living expenses. For the upcoming academic year, the total estimated cost is approximately $XX,XXX. Please note, this figure is subject to change and varies based on personal spending habits and accommodation choices.""\n\nVisa and Immigration\n\nQ01: ""What should I do if my student visa gets denied?""\n\nA01: ""In the event of a visa denial, it\'s important to understand the reason for the denial. You may reapply if you believe that your circumstances have changed or if you can provide additional information that was not presented in the initial application. Our international student office can provide guidance on the reapplication process.""\n\nQ02: ""Can I work while studying in the program?""\n\nA02: ""International students on a student visa are allowed to work on-campus for up to 20 hours per week during the academic term and full-time during breaks. Off-campus employment opportunities are subject to specific visa regulations and typically require authorization.""\n\nAcademic Life\n\nQ01: ""How can I get involved in research projects or internships during my studies?""\n\nA01: ""Our program encourages practical experience through research projects and internships. You can express your interest to faculty members, visit the career services office, or attend job fairs and networking events to explore opportunities.""\n\nQ02: ""What kind of support services are available for international students?""\n\nA02: ""We offer a wide range of support services including academic advising, career services, counseling, health services, and an international student office dedicated to assisting with visa issues, cultural adjustment, and other specific needs.""\n\nCampus Life and Community\n\nQ01: ""Are there any clubs or organizations I can join as an international student?""\n\n\n\nA01: ""Yes, our campus has a vibrant community with various clubs and organizations, including cultural associations, professional societies, and interest-based clubs. Joining these groups is a great way to meet people, develop new skills, and integrate into the campus community.""\n\nQ02: ""What resources are available to help me improve my English language skills?""\n\nA02: ""Our institution offers English language support services including ESL (English as a Second Language) courses, tutoring, writing workshops, and conversation practice sessions. These resources are designed to help non-native speakers enhance their academic and social communication skills.""\n\nAfter Graduation\n\nQ01: ""What are the career prospects after completing this Master\'s program?""\n\nA01: ""Graduates of our program have gone on to successful careers in data analysis, IT management, consulting, business intelligence, and more. Our career services office provides career counseling, resume workshops, interview preparation, and job placement assistance to support your professional development.""\n\nQ02: ""Is there an alumni network I can join after graduation?""\n\nA02: ""Absolutely. Our alumni network is a']","The Master of Business Analytics and Information Systems program facilitates networking opportunities with industry professionals through its extensive network of alumni and industry partners. Students have the opportunity to connect with and learn from leading experts in business analytics and information systems, who bring real-world insights and research into the classroom. Additionally, the program organizes events such as job fairs and networking events, providing students with the chance to interact with professionals in their field of interest.",simple,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}, {'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
What are the benefits and challenges of augmented pre-training in language models?,"['training of autoregressive language models constitutes a\npromising avenue, marrying sophisticated retrieval tech-\nniques with expansive language models to yield more precise\nand efficient language generation.\nThe benefits of augmented pre-training include a robust\nfoundational model that outperforms standard GPT models\nin perplexity, text generation quality, and task-specific per-\nformance, all while utilizing fewer parameters. This method\nis particularly adept at handling knowledge-intensive tasks\nand facilitates the development of domain-specific models\nthrough training on specialized corpora.\nNonetheless, this approach faces challenges such as the\nnecessity for extensive pre-training datasets and resources,\nas well as diminished update frequencies with increasing\nmodel sizes. Despite these hurdles, the approach offers\nsignificant advantages in model resilience. Once trained,\nretrieval-enhanced models can operate independently of ex-\nternal libraries, enhancing generation speed and operational\nefficiency. The potential gains identified render this method-\nology a compelling subject for ongoing investigation and in-\nnovation in artificial intelligence and machine learning.\nFine-tuning Stage\nRAG and Fine-tuning are powerful tools for enhancing\nLLMs, and combining the two can meet the needs of more\nspecific scenarios. On one hand, fine-tuning allows for the\nretrieval of documents with a unique style, achieving bet-\nter semantic expression and aligning the differences between\nqueries and documents. This ensures that the output of the\nretriever is more aptly suited to the scenario at hand. On\nthe other hand, fine-tuning can fulfill the generation needs of\nmaking stylized and targeted adjustments. Furthermore, fine-\ntuning can also be used to align the retriever and generator for\nimproved model synergy.\nThe main goal of fine-tuning the retriever is to improve\nthe quality of semantic representations, achieved by directly\nfine-tuning the Embedding model using a corpus [Liu, 2023 ].\nBy aligning the retriever’s capabilities with the prefer-\nences of the LLMs through feedback signals, both can\nbe better coordinated [Yuet al. , 2023b, Izacard et al. , 2022,\nYang et al. , 2023b, Shi et al. , 2023 ]. Fine-tuning the retriever\nfor specific downstream tasks can lead to improved adapt-\nability [cite]. The introduction of task-agnostic fine-tuning\naims to enhance the retriever’s versatility in multi-task sce-\nnarios [Cheng et al. , 2023a ].\nFine-tuning generator can result in outputs that are\nmore stylized and customized. On one hand, it allows\nfor specialized adaptation to different input data formats.\nFor example, fine-tuning LLMs to fit the structure of\nknowledge graphs [Kang et al. , 2023 ], the structure of text\npairs [Kang et al. , 2023, Cheng et al. , 2023b ], and other spe-\ncific structures [Liet al. , 2023d ]. On the other hand, by con-\nstructing directive datasets, one can demand LLMs to gen-\nerate specific formats content. For instance, in adaptive or\niterative retrieval scenarios, LLMs are fine-tuned to generate\ncontent that will help determine the timing for the next step\nof action [Jiang et al. , 2023b, Asai et al. , 2023 ].\nBy synergistically fine-tuning both the retriever and the\ngenerator, we can enhance the model’s generalization capa-bilities and avoid overfitting that may arise from training them\nseparately. However, joint fine-tuning also leads to increased\nresource consumption. RA-DIT [Linet al. , 2023 ]presents\na lightweight, dual-instruction tuning framework that can\neffectively add retrieval capabilities to any LLMs. The\nretrieval-enhanced directive fine-tuning updates the LLM,\nguiding it to make more efficient use of the information re-\ntrieved and to disregard distracting content.\nDespite its advantages, fine-tuning has limitations, includ-\ning the need for specialized datasets for RAG fine-tuning\nand the requirement for significant computational resources.\nHowever, this stage allows for customizing models to specific\nneeds and data formats, potentially reducing resource usage\ncompared to the pre-training phase while still being able to\nfine-tune the model’s output style.\nIn summary, the fine-tuning stage is essential for the adap-\ntation of RAG models to specific tasks, enabling the refine-\nment of both retrievers and generators. This stage enhances\nthe model’s versatility and adaptability to various tasks, de-\n']","The benefits of augmented pre-training include a robust foundational model that outperforms standard GPT models in perplexity, text generation quality, and task-specific performance, all while utilizing fewer parameters. This method is particularly adept at handling knowledge-intensive tasks and facilitates the development of domain-specific models through training on specialized corpora. However, this approach faces challenges such as the necessity for extensive pre-training datasets and resources, as well as diminished update frequencies with increasing model sizes.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 12, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
How does the utilization of innovative data sources in RAG contribute to improving task effectiveness?,"[' underscore the breadth of innovative\ndata source utilization in RAG, striving to improve model per-\nformance and task effectiveness.\n6.3 Augmentation Process\nIn the domain of RAG, the standard practice often involves\na singular retrieval step followed by generation, which can\nlead to inefficiencies. A notable issue, termed the “lost\nin the middle” phenomenon, arises when a single retrieval\nyields redundant content that may dilute or contradict es-\nsential information, thereby degrading the generation qual-\nity[Liuet al. , 2023a ]. Furthermore, such singular retrieval is\ntypically insufficient for complex problems demanding multi-\nstep reasoning, as it provides a limited scope of informa-\ntion[Yoran et al. , 2023 ].\nAs illustrated in Figure 5, to circumvent these challenges,\ncontemporary research has proposed methods for refining the\nretrieval process: iterative retrieval, recursive retrieval and\nadaptive retrieval. Iterative retrieval allows the model to en-\ngage in multiple retrieval cycles, enhancing the depth and\nrelevance of the information obtained. Recursive retrieval\nprocess where the results of one retrieval operation are used\nas the input for the subsequent retrieval. It helps to delve\ndeeper into relevant information, particularly when dealing\nwith complex or multi-step queries. Recursive retrieval is of-\nten used in scenarios where a gradual approach is needed to\nconverge on a final answer, such as in academic research, le-\ngal case analysis, or certain types of data mining tasks. Adap-\ntive retrieval, on the other hand, offers a dynamic adjustment\nmechanism, tailoring the retrieval process to the specific de-\nmands of varying tasks and contexts.\nIterative Retrieval\nIterative retrieval in RAG models is a process where doc-\numents are repeatedly collected based on the initial query\nand the text generated thus far, providing a more compre-\nhensive knowledge base for LLMs [Borgeaud et al. , 2022,\nArora et al. , 2023 ]. This approach has been shown to en-\nhance the robustness of subsequent answer generation by of-\nfering additional contextual references through multiple re-\ntrieval iterations. However, it may suffer from semantic dis-\ncontinuity and the accumulation of irrelevant information, as']","The utilization of innovative data sources in RAG contributes to improving task effectiveness by enhancing model performance and providing a more comprehensive knowledge base for LLMs. Methods such as iterative retrieval, recursive retrieval, and adaptive retrieval refine the retrieval process, allowing for deeper and more relevant information to be obtained. This improves the robustness of subsequent answer generation and tailors the retrieval process to the specific demands of varying tasks and contexts.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 13, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are some challenges in the generation process of the Naive RAG system?,"['Figure 2: A representative instance of the RAG process applied to question answering\nthe input into a vector representation. It then proceeds to\ncompute the similarity scores between the query vector and\nthe vectorized chunks within the indexed corpus. The system\nprioritizes and retrieves the top K chunks that demonstrate\nthe greatest similarity to the query. These chunks are subse-\nquently used as the expanded contextual basis for addressing\nthe user’s request.\nGeneration\nThe posed query and selected documents are synthesized into\na coherent prompt to which a large language model is tasked\nwith formulating a response. The model’s approach to an-\nswering may vary depending on task-specific criteria, allow-\ning it to either draw upon its inherent parametric knowledge\nor restrict its responses to the information contained within\nthe provided documents. In cases of ongoing dialogues,\nany existing conversational history can be integrated into the\nprompt, enabling the model to engage in multi-turn dialogue\ninteractions effectively.\nDrawbacks in Naive RAG\nNaive RAG faces significant challenges in three key areas:\n“Retrieval,” “Generation,” and “Augmentation”.\nRetrieval quality poses diverse challenges, including low\nprecision, leading to misaligned retrieved chunks and po-\ntential issues like hallucination or mid-air drop. Low recall\nalso occurs, resulting in the failure to retrieve all relevant\nchunks, thereby hindering the LLMs’ ability to craft compre-hensive responses. Outdated information further compounds\nthe problem, potentially yielding inaccurate retrieval results.\nResponse generation quality presents hallucination chal-\nlenge, where the model generates answers not grounded in\nthe provided context, as well as issues of irrelevant context\nand potential toxicity or bias in the model’s output.\nThe augmentation process presents its own challenges in\neffectively integrating context from retrieved passages with\nthe current generation task, potentially leading to disjointed\nor incoherent output. Redundancy and repetition are also\nconcerns, especially when multiple retrieved passages con-\ntain similar information, resulting in repetitive content in the\ngenerated response.\nDiscerning the importance and relevance of multiple re-\ntrieved passages to the generation task is another challenge,\nrequiring the proper balance of each passage’s value. Addi-\ntionally, reconciling differences in writing styles and tones to\nensure consistency in the output is crucial.\nLastly, there’s a risk of generation models overly depend-\ning on augmented information, potentially resulting in out-\nputs that merely reiterate the retrieved content without pro-\nviding new value or synthesized information.\n3.2 Advanced RAG\nAdvanced RAG has been developed with targeted enhance-\nments to address the shortcomings of Naive RAG. In terms\nof retrieval quality, Advanced RAG implements pre-retrieval']","Naive RAG faces significant challenges in three key areas: ""Retrieval,"" ""Generation,"" and ""Augmentation."" Retrieval quality poses diverse challenges, including low precision, leading to misaligned retrieved chunks and potential issues like hallucination or mid-air drop. Low recall also occurs, resulting in the failure to retrieve all relevant chunks, thereby hindering the LLMs’ ability to craft comprehensive responses. Outdated information further compounds the problem, potentially yielding inaccurate retrieval results. Response generation quality presents hallucination challenge, where the model generates answers not grounded in the provided context, as well as issues of irrelevant context and potential toxicity or bias in the model’s output. The augmentation process presents its own challenges in effectively integrating context from retrieved passages with the current generation task, potentially leading to disjointed or incoherent output. Redundancy and repetition are also concerns, especially when multiple retrieved passages contain similar information, resulting in repetitive content in the generated response. Discerning the importance and relevance of multiple retrieved passages to the generation task is another challenge, requiring the proper balance of each passage’s value. Additionally, reconciling differences in writing styles and tones to ensure consistency in the output is crucial. Lastly, there’s a risk of generation models overly depending on augmented information, potentially resulting in outputs that merely reiterate the retrieved content without providing new value or synthesized information.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 3, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the consequences of violating academic integrity?,"['Academic Integrity\nThe MS-BAIS program follow USF\'s of ficial policies on academic integrity , which are described in detail at\nhttps://www .usf.edu/undergrad/students/ethics-integrity .aspx\n(https://www.usf.edu/undergrad/students/ethics-integrity.aspx) . We encourage you to read through this page\nto familiarize yourself of our of ficial policy and consequences for violations. Students are routinely expelled\nfrom USF (without degree) every year for violations of our of ficial academic integrity policies. ""I did not know""\nor ""This is not considered plagiarism in the culture where I\'m from"" will not be considered an acceptable\nexcuse if you happen to be involved in any of these transgressions. \n \nWhat are violations of academic integrity?\nCheating : Cheating is using or attempting to use materials, information, notes, study aids, or other\nassistance in any assignment, group work, examination, or evaluation that have not been authorized by the\ninstructor .\nPlagiarism : Plagiarism is representing someone else\'s work as your own. For example, you download\nmaterials from the internet for your class project and did not cite or give credit to the original source where\nwe took the material from. Whether intentional or not, plagiarism is an of fense liable under USF academic\nintegrity policies.\n \nWhy is this a big deal?\nThe job of a university is not only to teach, but build responsible and productive members of our society . We\ndon\'t believe we can accomplish the second goal if we allow or overlook ethical transgressions in the\nconduct of our academic and extracurricular activities. W e understand that students don\'t start with an\nintention to cheat, but are forced to do so because of circumstances such as taking too many courses in one\nsemester , try to work full-time while also taking a full academic load, and trying to be perfect for their friends\nand family . These things can put a good person in a bad situation. Before soon, ""I would never cheat""\nbecomes ""W ell, just this once"" which turns into repeated instances of cheating. It is a slippery slope from\nwhere you can\'t get out. W e must intervene to arrest the moral and intellectual slide, and hence, we\nrigorously enforce our academic integrity policies.\n \nWhat are the consequences of academic integrity violations?\nFirst, both cheating and plagiarism have the same penalty and are cumulative throughout your stay at USF ,\nmeaning they accrue over your dif ferent classes with dif ferent professors. The USF of ficial policy for\ntransgressions can be found at https://usf.app.box.com/v/usfregulation3027\n(https://usf.app.box.com/v/usfregulation3027)\nIn general, we follow the following rules:\nFirst of fense:\nZero in the concerned assignment or exam.']","The consequences of violating academic integrity include receiving a zero on the concerned assignment or exam for the first offense. The penalties for cheating and plagiarism are cumulative throughout a student's stay at USF, meaning they accrue over different classes with different professors. More information on the official policy for transgressions can be found at https://usf.app.box.com/v/usfregulation3027.",simple,"[{'source': 'data/pdfs/Academic Integrity_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Academic Integrity_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
"What are the requirements for the work experience in the ""Dissertation and Thesis"" type of CPT?","['TYPES OF CPT\nWhen you apply for CPT, you must select a type. USF has three types\nof CPT:\nNECESSARY FOR COURSE – Work experience ful\x00lls a requirement of\na course as speci\x00ed by the o\x00cial course description available to the\npublic in a university catalog or website department course listings.\nThe work experience must be directly related to the major/program\nlisted on the \x00rst page of the student’s I-20 and commensurate with\nthe current educational level.\nUSF CENTER FOR CAREER & PROFESSIONAL DEVELOPMENT CO-OP\nOR INTERNSHIP (For Undergraduate Students Only) – The work\nexperience is assigned and monitored by USF’s Career Services. \xa0The\nwork experience must be directly related to the program (major) and\ncommensurate with the current educational level.\nDISSERTATION AND THESIS – The work experience must be\nnecessary and contribute to the production of the \x00nal thesis or\ndissertation. \xa0The student must be in candidacy and enrolled in\ndissertation hours OR already in thesis track and enrolled in thesis\nhours. \xa0\nPlease watch the video below to learn more about the CPT options at\nUSF.\xa0How t o Apply for CPT How t o Apply for CPT']",The work experience must be necessary and contribute to the production of the final thesis or dissertation. The student must be in candidacy and enrolled in dissertation hours OR already in thesis track and enrolled in thesis hours.,simple,"[{'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 3, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}]",True
What is the purpose of the Search Module in the RAG system?,"['Figure 3: Comparison between the three paradigms of RAG\nis depicted in Figure 3. However, Modular RAG is not stan-\ndalone. Advanced RAG is a specialized form of modular\nRAG, and further, Naive RAG itself is a special case of Ad-\nvanced RAG. The relationship among the three paradigms is\none of inheritance and development.\nNew Modules\nSearch Module . In contrast to the similarity retrieval in\nNaive/Advanced RAG, the Search Module is tailored to spe-\ncific scenarios and incorporates direct searches on additional\ncorpora. This integration is achieved using code generated\nby the LLM, query languages such as SQL or Cypher, and\nother custom tools. The data sources for these searches can\ninclude search engines, text data, tabular data, and knowledge\ngraphs [Wang et al. , 2023d ].\nMemory Module . This module harnesses the memory ca-\npabilities of the LLM to guide retrieval. The approach in-\nvolves identifying memories most similar to the current input.\nSelfmem [Cheng et al. , 2023b ]utilizes a retrieval-enhanced\ngenerator to create an unbounded memory pool iteratively,\ncombining the “original question” and “dual question”. By\nemploying a retrieval-enhanced generative model that uses its\nown outputs to improve itself, the text becomes more aligned\nwith the data distribution during the reasoning process. Con-\nsequently, the model’s own outputs are utilized instead of the\ntraining data [Wang et al. , 2022a ].\nFusion . RAG-Fusion [Raudaschl, 2023 ]enhances tradi-\ntional search systems by addressing their limitations through\na multi-query approach that expands user queries into mul-tiple, diverse perspectives using an LLM. This approach not\nonly captures the explicit information users seek but also un-\ncovers deeper, transformative knowledge. The fusion pro-\ncess involves parallel vector searches of both original and\nexpanded queries, intelligent re-ranking to optimize results,\nand pairing the best outcomes with new queries. This sophis-\nticated method ensures search results that align closely with\nboth the explicit and implicit intentions of the user, leading to\nmore insightful and relevant information discovery.\nRouting . The RAG system’s retrieval process utilizes di-\nverse sources, differing in domain, language, and format,\nwhich can be either alternated or merged based on the sit-\nuation [Liet al. , 2023b ]. Query routing decides the subse-\nquent action to a user’s query, with options ranging from\nsummarization, searching specific databases, or merging dif-\nferent pathways into a single response. The query router also\nchooses the appropriate data store for the query, which may\ninclude various sources like vector stores, graph databases, or\nrelational databases, or a hierarchy of indices—for instance, a\nsummary index and a document block vector index for multi-\ndocument storage. The query router’s decision-making is pre-\ndefined and executed via LLMs calls, which direct the query\nto the chosen index.\nPredict . It addresses the common issues of redundancy\nand noise in retrieved content. Instead of directly retrieving\nfrom a data source, this module utilizes the LLM to generate\nthe necessary context [Yuet al. , 2022 ]. The content produced\nby the LLM is more likely to contain pertinent information\ncompared to that obtained through direct retrieval.']","The Search Module in the RAG system is tailored to specific scenarios and incorporates direct searches on additional corpora. It integrates code generated by the LLM, query languages such as SQL or Cypher, and other custom tools to retrieve information from search engines, text data, tabular data, and knowledge graphs.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 5, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What is the difference between the modular RAG structure and the traditional Naive RAG framework?,"['23a ]re-\ncalculate the semantic similarity between relevant text and the\nquery, addressing the challenge of interpreting vector-based\nsimulated searches for semantic similarity.\nPrompt Compression . Research indicates that noise in re-\ntrieved documents adversely affects RAG performance. In\npost-processing, the emphasis lies in compressing irrelevant\ncontext, highlighting pivotal paragraphs, and reducing the\noverall context length. Approaches such as Selective Context\nand LLMLingua [Litman et al. , 2020, Anderson et al. , 2022 ]\nutilize small language models to calculate prompt mu-\ntual information or perplexity, estimating element impor-\ntance. Recomp [Xuet al. , 2023a ]addresses this by train-\ning compressors at different granularities, while Long\nContext [Xuet al. , 2023b ]and “Walking in the Memory\nMaze” [Chen et al. , 2023a ]design summarization techniques\nto enhance LLM’s key information perception, particularly in\ndealing with extensive contexts.\n3.3 Modular RAG\nThe modular RAG structure diverges from the tradi-\ntional Naive RAG framework, providing greater versatil-\nity and flexibility. It integrates various methods to en-\nhance functional modules, such as incorporating a search\nmodule for similarity retrieval and applying a fine-tuning\napproach in the retriever [Linet al. , 2023 ]. Restructured\nRAG modules [Yuet al. , 2022 ]and iterative methodologies\nlike[Shao et al. , 2023 ]have been developed to address spe-\ncific issues. The modular RAG paradigm is increasingly be-\ncoming the norm in the RAG domain, allowing for either a\nserialized pipeline or an end-to-end training approach across\nmultiple modules. The comparison of three RAG paradigms\n4https://www.llamaindex.ai\n5https://www.langchain.com/\n6https://haystack.deepset.ai/blog/\nenhancing-rag-pipelines-in-haystack\n7https://huggingface.co/BAAI/bge-reranker-large']","The modular RAG structure diverges from the traditional Naive RAG framework by providing greater versatility and flexibility. It integrates various methods to enhance functional modules, such as incorporating a search module for similarity retrieval and applying a fine-tuning approach in the retriever. Restructured RAG modules and iterative methodologies have been developed to address specific issues. The modular RAG paradigm allows for either a serialized pipeline or an end-to-end training approach across multiple modules.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 4, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What is the role of knowledge updates in the RAG model?,"['Table 1: Comparison between RAG and Fine-Tuning\nFeature Comparison RAG Fine-Tuning\nKnowledge UpdatesDirectly updating the retrieval knowledge\nbase ensures that the information remains\ncurrent without the need for frequent retrain-\ning, making it well-suited for dynamic data\nenvironments.Stores static data, requiring retraining for\nknowledge and data updates.\nExternal KnowledgeProficient in leveraging external resources,\nparticularly suitable for accessing documents\nor other structured/unstructured databases.Can be utilized to align the externally ac-\nquired knowledge from pretraining with large\nlanguage models, but may be less practical\nfor frequently changing data sources.\nData ProcessingInvolves minimal data processing and han-\ndling.Depends on the creation of high-quality\ndatasets, and limited datasets may not result\nin significant performance improvements.\nModel CustomizationFocuses on information retrieval and inte-\ngrating external knowledge but may not fully\ncustomize model behavior or writing style.Allows adjustments of LLM behavior, writ-\ning style, or specific domain knowledge\nbased on specific tones or terms.\nInterpretabilityResponses can be traced back to specific data\nsources, providing higher interpretability and\ntraceability.Similar to a black box, it is not always clear\nwhy the model reacts a certain way, resulting\nin relatively lower interpretability.\nComputational ResourcesDepends on computational resources to sup-\nport retrieval strategies and technologies re-\nlated to databases. Additionally, it requires\nthe maintenance of external data source inte-\ngration and updates.The preparation and curation of high-quality\ntraining datasets, defining fine-tuning objec-\ntives, and providing corresponding computa-\ntional resources are necessary.\nLatency RequirementsInvolves data retrieval, which may lead to\nhigher latency.LLM after fine-tuning can respond without\nretrieval, resulting in lower latency.\nReducing HallucinationsInherently less prone to hallucinations as\neach answer is grounded in retrieved evi-\ndence.Can help reduce hallucinations by training\nthe model based on specific domain data but\nmay still exhibit hallucinations when faced\nwith unfamiliar input.\nEthical and Privacy IssuesEthical and privacy concerns arise from the\nstorage and retrieval of text from external\ndatabases.Ethical and privacy concerns may arise due\nto sensitive content in the training data.\nmodel [Liu, 2023 ]. Additionally, both retrieval and genera-\ntion quality assessments can be conducted through manual\nor automatic evaluation methods [Liu, 2023, Lan et al. , 2022,\nLeng et al. , 2023 ].\n7.2 Evaluation Aspects\nContemporary evaluation practices of RAG models empha-\nsize three primary quality scores and four essential abilities,\nwhich collectively inform the evaluation of the two principal\ntargets of the RAG model: retrieval and generation.\nQuality Scores\nQuality scores include context relevance, answer faith-\nfulness, and answer relevance. These quality scoresevaluate the efficiency of the RAG model from differ-\nent perspectives in the process of information retrieval\nand generation [Eset al. , 2023, Saad-Falcon et al. , 2023,\nJarvis and Allard, 2023 ]. The quality scores—context rele-\nvance, answer faithfulness, and answer relevance—assess the\nRAG model’s efficiency from various angles throughout the\ninformation retrieval and generation process [Eset al. , 2023,\nSaad-Falcon et al. , 2023, Jarvis and Allard, 2023 ].\nContext Relevance evaluates the precision and specificity\nof the retrieved context, ensuring relevance and minimizing\nprocessing costs associated with extraneous content.\nAnswer Faithfulness ensures that the generated answers re-\nmain true to the retrieved context, maintaining consistency']","Directly updating the retrieval knowledge base ensures that the information remains current without the need for frequent retraining, making it well-suited for dynamic data environments.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 16, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What is the role of knowledge updates in the RAG model?,"['Table 1: Comparison between RAG and Fine-Tuning\nFeature Comparison RAG Fine-Tuning\nKnowledge UpdatesDirectly updating the retrieval knowledge\nbase ensures that the information remains\ncurrent without the need for frequent retrain-\ning, making it well-suited for dynamic data\nenvironments.Stores static data, requiring retraining for\nknowledge and data updates.\nExternal KnowledgeProficient in leveraging external resources,\nparticularly suitable for accessing documents\nor other structured/unstructured databases.Can be utilized to align the externally ac-\nquired knowledge from pretraining with large\nlanguage models, but may be less practical\nfor frequently changing data sources.\nData ProcessingInvolves minimal data processing and han-\ndling.Depends on the creation of high-quality\ndatasets, and limited datasets may not result\nin significant performance improvements.\nModel CustomizationFocuses on information retrieval and inte-\ngrating external knowledge but may not fully\ncustomize model behavior or writing style.Allows adjustments of LLM behavior, writ-\ning style, or specific domain knowledge\nbased on specific tones or terms.\nInterpretabilityResponses can be traced back to specific data\nsources, providing higher interpretability and\ntraceability.Similar to a black box, it is not always clear\nwhy the model reacts a certain way, resulting\nin relatively lower interpretability.\nComputational ResourcesDepends on computational resources to sup-\nport retrieval strategies and technologies re-\nlated to databases. Additionally, it requires\nthe maintenance of external data source inte-\ngration and updates.The preparation and curation of high-quality\ntraining datasets, defining fine-tuning objec-\ntives, and providing corresponding computa-\ntional resources are necessary.\nLatency RequirementsInvolves data retrieval, which may lead to\nhigher latency.LLM after fine-tuning can respond without\nretrieval, resulting in lower latency.\nReducing HallucinationsInherently less prone to hallucinations as\neach answer is grounded in retrieved evi-\ndence.Can help reduce hallucinations by training\nthe model based on specific domain data but\nmay still exhibit hallucinations when faced\nwith unfamiliar input.\nEthical and Privacy IssuesEthical and privacy concerns arise from the\nstorage and retrieval of text from external\ndatabases.Ethical and privacy concerns may arise due\nto sensitive content in the training data.\nmodel [Liu, 2023 ]. Additionally, both retrieval and genera-\ntion quality assessments can be conducted through manual\nor automatic evaluation methods [Liu, 2023, Lan et al. , 2022,\nLeng et al. , 2023 ].\n7.2 Evaluation Aspects\nContemporary evaluation practices of RAG models empha-\nsize three primary quality scores and four essential abilities,\nwhich collectively inform the evaluation of the two principal\ntargets of the RAG model: retrieval and generation.\nQuality Scores\nQuality scores include context relevance, answer faith-\nfulness, and answer relevance. These quality scoresevaluate the efficiency of the RAG model from differ-\nent perspectives in the process of information retrieval\nand generation [Eset al. , 2023, Saad-Falcon et al. , 2023,\nJarvis and Allard, 2023 ]. The quality scores—context rele-\nvance, answer faithfulness, and answer relevance—assess the\nRAG model’s efficiency from various angles throughout the\ninformation retrieval and generation process [Eset al. , 2023,\nSaad-Falcon et al. , 2023, Jarvis and Allard, 2023 ].\nContext Relevance evaluates the precision and specificity\nof the retrieved context, ensuring relevance and minimizing\nprocessing costs associated with extraneous content.\nAnswer Faithfulness ensures that the generated answers re-\nmain true to the retrieved context, maintaining consistency']","Directly updating the retrieval knowledge base ensures that the information remains current without the need for frequent retraining, making it well-suited for dynamic data environments.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 16, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the consequences of not maintaining good academic standing?,"['Academic Probation\nIt is important that you remain in good academic standing ( https://catalog.usf.edu/content.php?\ncatoid=18&navoid=2820#in-good-standing  (https://catalog.usf.edu/content.php?\ncatoid=18&navoid=2820#in-good-standing) ).  Essentially , this means that you need to maintain an overall\nGPA of at least 3.0.\nIf your GP A drops below 3.0, you are placed on academic probation at the end of the semester in which your\nGPA fell below 3.0.  It is important that you address the situation as soon as the next semester .  If you do\nnot, there is a chance that you will be dismissed from the program.  You also will not be able to complete an\ninternship.  The process for academic probation is described at\nhttps://www .usf.edu/graduate-studies/documents/usf-graduate-studies-academic-probation-\nprocedures.pdf  (https://www.usf.edu/graduate-studies/documents/usf-graduate-studies-academic-\nprobation-procedures.pdf)  \nIn order to help you get of f academic probation, the School has decided to restrict you to three courses in the\nsemester after you were placed on academic probation.']","If you do not maintain good academic standing, the consequences include being placed on academic probation, the possibility of being dismissed from the program, and being unable to complete an internship.",simple,"[{'source': 'data/pdfs/Academic Probation_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Academic Probation_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What are the selection criteria for GA/T A positions in the School of Information Systems & Management (SISM)?,"[""Graduate/T eaching Assistantships and On\nCampus Jobs\nWho can apply for GA/T A positions? Can I apply for GA/T A positions outside the School of\nInformation Systems & Management (SISM)?\nAny full-time student who is registered for at least 9 credit hours can apply for GA/T A positions.\nYou do not have to restrict your GA/T A search to the SISM department. Many other departments and centers\nsuch as Center for Urban Transportation Research (CUTR), INT O USF , USF IT , USF Provost's Of fice, USF\nLibrary , etc. provide GA/T A opportunities for technically qualified students. Since programming skills are\noften valued for many of these positions, our BAIS students often find on-campus employment opportunities\nat many of these departments.\n \nWhat are the job requirements of these positions?\nIn TA positions, you are typically helping a professor with a certain class (e.g., statistics). So you need a\nstrong background in that content to qualify for a TA in that class. For example, if Dr . Bhattacherjee needs a\nTA for his Statistical Data Modeling class, he will require that you take that class and perform well in the\nclass to be considered as his TA for that class.\nIn GA  positions, you are helping a center/lab with research, data collection, or other ef forts. There may be\nspecial skills (e.g., programming) required for these positions that will be listed in the job announcement.\n \nWhere can I find GA/T A openings in SISM and in other departments?\nVisit USF Careers  (https://gems.usf.edu:4440/psc/gemspro-\ntam/EMPLOYEE/HRMS/c/HRS_HRAM_FL.HRS_CG_SEARCH_FL.GBL?FOCUS=Applicant) to get a real-time list\nof all on-campus job opportunities across USF , and use that system to apply for GA/T A positions.  Please do\nnot write to individual professors or of fice staf f asking them for GA/T A positions.  W e will count it against you\nif you do.\n \nDo GA/T A positions come with tuition waiver?  \nGA/T A positions may come with tuition waivers for the out-of-state portion of your tuition, meaning that you\nwill still have to pay the in-state portion of your tuition (approximately one-third of out-of-state tuition).\n \nWhat is/are the selection criteria for GA/T A positions in SISM?\nSISM traditionally has 4 types of GA  positions available:\n1. Department undergraduate teaching assistant: Selection based on GRE/GMA T scores,\nTOEIC/T OEFL/IEL TS speak scores (international students), strength in the teaching area and interviews.""]","Selection for GA/T A positions in the School of Information Systems & Management (SISM) is based on GRE/GMA T scores, TOEIC/T OEFL/IEL TS speak scores (for international students), strength in the teaching area, and interviews.",simple,"[{'source': 'data/pdfs/Graduate_Teaching Assistantships and On Campus Jobs_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Graduate_Teaching Assistantships and On Campus Jobs_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What is the purpose of Retrieval-Augmented Generation in refining the capabilities of chat?,"['Retrieval-Augmented Generation for Large Language Models: A Survey\nYunfan Gao1,Yun Xiong2,Xinyu Gao2,Kangxiang Jia2,Jinliu Pan2,Yuxi Bi3,Yi\nDai1,Jiawei Sun1,Qianyu Guo4,Meng Wang3and Haofen Wang1,3∗\n1Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University\n2Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n3College of Design and Innovation, Tongji University\n4School of Computer Science, Fudan University\nAbstract\nLarge Language Models (LLMs) demonstrate\nsignificant capabilities but face challenges such\nas hallucination, outdated knowledge, and non-\ntransparent, untraceable reasoning processes.\nRetrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating\nknowledge from external databases. This enhances\nthe accuracy and credibility of the models, particu-\nlarly for knowledge-intensive tasks, and allows for\ncontinuous knowledge updates and integration of\ndomain-specific information. RAG synergistically\nmerges LLMs’ intrinsic knowledge with the vast,\ndynamic repositories of external databases. This\ncomprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms,\nencompassing the Naive RAG, the Advanced RAG,\nand the Modular RAG. It meticulously scrutinizes\nthe tripartite foundation of RAG frameworks,\nwhich includes the retrieval , the generation and\nthe augmentation techniques. The paper highlights\nthe state-of-the-art technologies embedded in\neach of these critical components, providing a\nprofound understanding of the advancements in\nRAG systems. Furthermore, this paper introduces\nthe metrics and benchmarks for assessing RAG\nmodels, along with the most up-to-date evaluation\nframework. In conclusion, the paper delineates\nprospective avenues for research, including the\nidentification of challenges, the expansion of\nmulti-modalities, and the progression of the RAG\ninfrastructure and its ecosystem.1.\n1 Introduction\nLarge language models (LLMs) such as the GPT se-\nries[Brown et al. , 2020, OpenAI, 2023 ]and the LLama se-\nries [Touvron et al. , 2023 ], along with other models like\nGemini [Google, 2023 ], have achieved remarkable suc-\ncess in natural language processing, demonstrating supe-\n∗Corresponding Author.Email:haofen.wang@tongji.edu.cn\n1Resources are available at https://github.com/Tongji-KGLLM/\nRAG-Surveyrior performance on various benchmarks including Super-\nGLUE [Wang et al. , 2019 ], MMLU [Hendrycks et al. , 2020 ],\nand BIG-bench [Srivastava et al. , 2022 ]. Despite these\nadvancements, LLMs exhibit notable limitations, par-\nticularly in handling domain-specific or highly special-\nized queries [Kandpal et al. , 2023 ]. A common issue is\nthe generation of incorrect information, or ”hallucina-\ntions” [Zhang et al. , 2023b ], especially when queries extend\nbeyond the model’s training data or necessitate up-to-date in-\nformation. These shortcomings underscore the impractical-\nity of deploying LLMs as black-box solutions in real-world\nproduction environments without additional safeguards. One\npromising approach to mitigate these limitations is Retrieval-\nAugmented Generation (RAG), which integrates external\ndata retrieval into the generative process, thereby enhancing\nthe model’s ability to provide accurate and relevant responses.\nRAG, introduced by Lewis et al. [Lewis et al. , 2020 ]in\nmid-2020, stands as a paradigm within the realm of LLMs,\nenhancing generative tasks. Specifically, RAG involves an\ninitial retrieval step where the LLMs query an external data\nsource to obtain relevant information before proceeding to an-\nswer questions or generate text. This process not only informs\nthe subsequent generation phase but also ensures that the re-\nsponses are grounded in retrieved evidence, thereby signif-\nicantly enhancing the accuracy and relevance of the output.\nThe dynamic retrieval of information from knowledge bases\nduring the inference phase allows RAG to address issues such\nas the generation of factually incorrect content, commonly\nreferred to as “hallucinations.” The integration of RAG into\nLLMs has seen rapid adoption and has become a pivotal tech-\nnology in refining the capabilities of chat']","Retrieval-Augmented Generation (RAG) is integrated into Large Language Models (LLMs) to enhance their capabilities in chat. RAG involves an initial retrieval step where LLMs query an external data source to obtain relevant information, ensuring that the responses are grounded in retrieved evidence. This significantly enhances the accuracy and relevance of the output, addressing issues such as the generation of factually incorrect content or 'hallucinations'. Therefore, the purpose of RAG is to improve the accuracy and quality of chat responses by incorporating external knowledge.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 0, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
Why is answer relevance important in evaluating RAG models?,"['Figure 6: RAG compared with other model optimization methods\nand avoiding contradictions.\nAnswer Relevance requires that the generated answers are\ndirectly pertinent to the posed questions, effectively address-\ning the core inquiry.\nRequired Abilities\nRAG evaluation also encompasses four abilities indicative of\nits adaptability and efficiency: noise robustness, negative re-\njection, information integration, and counterfactual robust-\nness [Chen et al. , 2023b, Liu et al. , 2023b ]. These abilities\nare critical for the model’s performance under various chal-\nlenges and complex scenarios, impacting the quality scores.\nNoise Robustness appraises the model’s capability to man-\nage noise documents that are question-related but lack sub-\nstantive information.\nNegative Rejection assesses the model’s discernment in re-\nfraining from responding when the retrieved documents do\nnot contain the necessary knowledge to answer a question.\nInformation Integration evaluates the model’s proficiency\nin synthesizing information from multiple documents to ad-\ndress complex questions.\nCounterfactual Robustness tests the model’s ability to rec-\nognize and disregard known inaccuracies within documents,\neven when instructed about potential misinformation.\nContext relevance and noise robustness are important for\nevaluating the quality of retrieval, while answer faithfulness,\nanswer relevance, negative rejection, information integration,\nand counterfactual robustness are important for evaluating thequality of generation.\nThe specific metrics for each evaluation aspect are summa-\nrized in Table 2. It is essential to recognize that these metrics,\nderived from related work, are traditional measures and do\nnot yet represent a mature or standardized approach for quan-\ntifying RAG evaluation aspects. Custom metrics tailored to\nthe nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\n7.3 Evaluation Benchmarks and Tools\nThis section delineates the evaluation framework for RAG\nmodels, comprising benchmark tests and automated eval-\nuation tools. These instruments furnish quantitative met-\nrics that not only gauge RAG model performance but also\nenhance comprehension of the model’s capabilities across\nvarious evaluation aspects. Prominent benchmarks such as\nRGB and RECALL [Chen et al. , 2023b, Liu et al. , 2023b ]\nfocus on appraising the essential abilities of RAG mod-\nels. Concurrently, state-of-the-art automated tools like RA-\nGAS [Eset al. , 2023 ], ARES [Saad-Falcon et al. , 2023 ], and\nTruLens8employ LLMs to adjudicate the quality scores.\nThese tools and benchmarks collectively form a robust frame-\nwork for the systematic evaluation of RAG models, as sum-\nmarized in Table 3.\n8https://www.trulens.org/trulens eval/core concepts ragtriad/']",Answer relevance is important in evaluating RAG models because it ensures that the generated answers are directly pertinent to the posed questions and effectively address the core inquiry. It is one of the important aspects that impacts the quality scores of RAG models.,simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 17, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the challenges faced by the Naive RAG process?,"['Figure 2: A representative instance of the RAG process applied to question answering\nthe input into a vector representation. It then proceeds to\ncompute the similarity scores between the query vector and\nthe vectorized chunks within the indexed corpus. The system\nprioritizes and retrieves the top K chunks that demonstrate\nthe greatest similarity to the query. These chunks are subse-\nquently used as the expanded contextual basis for addressing\nthe user’s request.\nGeneration\nThe posed query and selected documents are synthesized into\na coherent prompt to which a large language model is tasked\nwith formulating a response. The model’s approach to an-\nswering may vary depending on task-specific criteria, allow-\ning it to either draw upon its inherent parametric knowledge\nor restrict its responses to the information contained within\nthe provided documents. In cases of ongoing dialogues,\nany existing conversational history can be integrated into the\nprompt, enabling the model to engage in multi-turn dialogue\ninteractions effectively.\nDrawbacks in Naive RAG\nNaive RAG faces significant challenges in three key areas:\n“Retrieval,” “Generation,” and “Augmentation”.\nRetrieval quality poses diverse challenges, including low\nprecision, leading to misaligned retrieved chunks and po-\ntential issues like hallucination or mid-air drop. Low recall\nalso occurs, resulting in the failure to retrieve all relevant\nchunks, thereby hindering the LLMs’ ability to craft compre-hensive responses. Outdated information further compounds\nthe problem, potentially yielding inaccurate retrieval results.\nResponse generation quality presents hallucination chal-\nlenge, where the model generates answers not grounded in\nthe provided context, as well as issues of irrelevant context\nand potential toxicity or bias in the model’s output.\nThe augmentation process presents its own challenges in\neffectively integrating context from retrieved passages with\nthe current generation task, potentially leading to disjointed\nor incoherent output. Redundancy and repetition are also\nconcerns, especially when multiple retrieved passages con-\ntain similar information, resulting in repetitive content in the\ngenerated response.\nDiscerning the importance and relevance of multiple re-\ntrieved passages to the generation task is another challenge,\nrequiring the proper balance of each passage’s value. Addi-\ntionally, reconciling differences in writing styles and tones to\nensure consistency in the output is crucial.\nLastly, there’s a risk of generation models overly depend-\ning on augmented information, potentially resulting in out-\nputs that merely reiterate the retrieved content without pro-\nviding new value or synthesized information.\n3.2 Advanced RAG\nAdvanced RAG has been developed with targeted enhance-\nments to address the shortcomings of Naive RAG. In terms\nof retrieval quality, Advanced RAG implements pre-retrieval', 'Figure 2: A representative instance of the RAG process applied to question answering\nthe input into a vector representation. It then proceeds to\ncompute the similarity scores between the query vector and\nthe vectorized chunks within the indexed corpus. The system\nprioritizes and retrieves the top K chunks that demonstrate\nthe greatest similarity to the query. These chunks are subse-\nquently used as the expanded contextual basis for addressing\nthe user’s request.\nGeneration\nThe posed query and selected documents are synthesized into\na coherent prompt to which a large language model is tasked\nwith formulating a response. The model’s approach to an-\nswering may vary depending on task-specific criteria, allow-\ning it to either draw upon its inherent parametric knowledge\nor restrict its responses to the information contained within\nthe provided documents. In cases of ongoing dialogues,\nany existing conversational history can be integrated into the\nprompt, enabling the model to engage in multi-turn dialogue\ninteractions effectively.\nDrawbacks in Naive RAG\nNaive RAG faces significant challenges in three key areas:\n“Retrieval,” “Generation,” and “Augmentation”.\nRetrieval quality poses diverse challenges, including low\nprecision, leading to misaligned retrieved chunks and po-\ntential issues like hallucination or mid-air drop. Low recall\nalso occurs, resulting in the failure to retrieve all relevant\nchunks, thereby hindering the LLMs’ ability to craft compre-hensive responses. Outdated information further compounds\nthe problem, potentially yielding inaccurate retrieval results.\nResponse generation quality presents hallucination chal-\nlenge, where the model generates answers not grounded in\nthe provided context, as well as issues of irrelevant context\nand potential toxicity or bias in the model’s output.\nThe augmentation process presents its own challenges in\neffectively integrating context from retrieved passages with\nthe current generation task, potentially leading to disjointed\nor incoherent output. Redundancy and repetition are also\nconcerns, especially when multiple retrieved passages con-\ntain similar information, resulting in repetitive content in the\ngenerated response.\nDiscerning the importance and relevance of multiple re-\ntrieved passages to the generation task is another challenge,\nrequiring the proper balance of each passage’s value. Addi-\ntionally, reconciling differences in writing styles and tones to\nensure consistency in the output is crucial.\nLastly, there’s a risk of generation models overly depend-\ning on augmented information, potentially resulting in out-\nputs that merely reiterate the retrieved content without pro-\nviding new value or synthesized information.\n3.2 Advanced RAG\nAdvanced RAG has been developed with targeted enhance-\nments to address the shortcomings of Naive RAG. In terms\nof retrieval quality, Advanced RAG implements pre-retrieval']","Naive RAG faces significant challenges in three key areas: ""Retrieval,"" ""Generation,"" and ""Augmentation."" Retrieval quality poses diverse challenges, including low precision, leading to misaligned retrieved chunks and potential issues like hallucination or mid-air drop. Low recall also occurs, resulting in the failure to retrieve all relevant chunks, thereby hindering the LLMs’ ability to craft comprehensive responses. Outdated information further compounds the problem, potentially yielding inaccurate retrieval results. Response generation quality presents hallucination challenge, where the model generates answers not grounded in the provided context, as well as issues of irrelevant context and potential toxicity or bias in the model’s output. The augmentation process presents its own challenges in effectively integrating context from retrieved passages with the current generation task, potentially leading to disjointed or incoherent output. Redundancy and repetition are also concerns, especially when multiple retrieved passages contain similar information, resulting in repetitive content in the generated response. Discerning the importance and relevance of multiple retrieved passages to the generation task is another challenge, requiring the proper balance of each passage’s value. Additionally, reconciling differences in writing styles and tones to ensure consistency in the output is crucial. Lastly, there’s a risk of generation models overly depending on augmented information, potentially resulting in outputs that merely reiterate the retrieved content without providing new value or synthesized information.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 3, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 3, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the advantages and challenges of retrieval-enhanced models in language generation?,"['training of autoregressive language models constitutes a\npromising avenue, marrying sophisticated retrieval tech-\nniques with expansive language models to yield more precise\nand efficient language generation.\nThe benefits of augmented pre-training include a robust\nfoundational model that outperforms standard GPT models\nin perplexity, text generation quality, and task-specific per-\nformance, all while utilizing fewer parameters. This method\nis particularly adept at handling knowledge-intensive tasks\nand facilitates the development of domain-specific models\nthrough training on specialized corpora.\nNonetheless, this approach faces challenges such as the\nnecessity for extensive pre-training datasets and resources,\nas well as diminished update frequencies with increasing\nmodel sizes. Despite these hurdles, the approach offers\nsignificant advantages in model resilience. Once trained,\nretrieval-enhanced models can operate independently of ex-\nternal libraries, enhancing generation speed and operational\nefficiency. The potential gains identified render this method-\nology a compelling subject for ongoing investigation and in-\nnovation in artificial intelligence and machine learning.\nFine-tuning Stage\nRAG and Fine-tuning are powerful tools for enhancing\nLLMs, and combining the two can meet the needs of more\nspecific scenarios. On one hand, fine-tuning allows for the\nretrieval of documents with a unique style, achieving bet-\nter semantic expression and aligning the differences between\nqueries and documents. This ensures that the output of the\nretriever is more aptly suited to the scenario at hand. On\nthe other hand, fine-tuning can fulfill the generation needs of\nmaking stylized and targeted adjustments. Furthermore, fine-\ntuning can also be used to align the retriever and generator for\nimproved model synergy.\nThe main goal of fine-tuning the retriever is to improve\nthe quality of semantic representations, achieved by directly\nfine-tuning the Embedding model using a corpus [Liu, 2023 ].\nBy aligning the retriever’s capabilities with the prefer-\nences of the LLMs through feedback signals, both can\nbe better coordinated [Yuet al. , 2023b, Izacard et al. , 2022,\nYang et al. , 2023b, Shi et al. , 2023 ]. Fine-tuning the retriever\nfor specific downstream tasks can lead to improved adapt-\nability [cite]. The introduction of task-agnostic fine-tuning\naims to enhance the retriever’s versatility in multi-task sce-\nnarios [Cheng et al. , 2023a ].\nFine-tuning generator can result in outputs that are\nmore stylized and customized. On one hand, it allows\nfor specialized adaptation to different input data formats.\nFor example, fine-tuning LLMs to fit the structure of\nknowledge graphs [Kang et al. , 2023 ], the structure of text\npairs [Kang et al. , 2023, Cheng et al. , 2023b ], and other spe-\ncific structures [Liet al. , 2023d ]. On the other hand, by con-\nstructing directive datasets, one can demand LLMs to gen-\nerate specific formats content. For instance, in adaptive or\niterative retrieval scenarios, LLMs are fine-tuned to generate\ncontent that will help determine the timing for the next step\nof action [Jiang et al. , 2023b, Asai et al. , 2023 ].\nBy synergistically fine-tuning both the retriever and the\ngenerator, we can enhance the model’s generalization capa-bilities and avoid overfitting that may arise from training them\nseparately. However, joint fine-tuning also leads to increased\nresource consumption. RA-DIT [Linet al. , 2023 ]presents\na lightweight, dual-instruction tuning framework that can\neffectively add retrieval capabilities to any LLMs. The\nretrieval-enhanced directive fine-tuning updates the LLM,\nguiding it to make more efficient use of the information re-\ntrieved and to disregard distracting content.\nDespite its advantages, fine-tuning has limitations, includ-\ning the need for specialized datasets for RAG fine-tuning\nand the requirement for significant computational resources.\nHowever, this stage allows for customizing models to specific\nneeds and data formats, potentially reducing resource usage\ncompared to the pre-training phase while still being able to\nfine-tune the model’s output style.\nIn summary, the fine-tuning stage is essential for the adap-\ntation of RAG models to specific tasks, enabling the refine-\nment of both retrievers and generators. This stage enhances\nthe model’s versatility and adaptability to various tasks, de-\n']","The advantages of retrieval-enhanced models in language generation include a robust foundational model that outperforms standard models in perplexity, text generation quality, and task-specific performance. It also allows for the development of domain-specific models through training on specialized corpora. Additionally, retrieval-enhanced models can operate independently of external libraries, enhancing generation speed and operational efficiency. However, the challenges include the necessity for extensive pre-training datasets and resources, as well as diminished update frequencies with increasing model sizes.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 12, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the eligibility requirements for CPT?,"[""BACK TO OIS HOME Please watch this overview presentation of CPT, its regulations, and\nthe application process.\nCPT ELIGIBILITY REQUIREMENTS\nTo be eligible for CPT, the following must be met:\nStudent must be in valid F-1 status.\nStudent must be enrolled in a Bachelor's, Master's, or Doctoral\ndegree program.\nStudent must have been enrolled for one academic year in a\ncurrent degree program at USF. Academic year is de\x00ned as a fall\nand spring semester (Summer not included). Time in Academic\nEnglish or Pathway programs does not count towards this\nrequirement.\nStudent must be making normal progress toward degree\ncompletion.\nCurricular Practical Training must be an integral part of the\nstudent’s degree program.\nStudent must have applied for and received a work authorization\non their I-20 prior to starting CPT.\nCPT COURSE REQUIREMENTS\nYour CPT course must be credit-bearing – Minimum of 1 credit. The\nnumber of credit hours for the CPT-related course is determined by\nthe department and o\x00cial course catalog.\xa0\nExamples of Courses acceptable for CPT Authorization:\nInternship course\nCooperative education course\nPracticum or \x00eld experience courseCPT  Overview CPT  Overview""]","To be eligible for CPT, the student must be in valid F-1 status, enrolled in a Bachelor's, Master's, or Doctoral degree program, have been enrolled for one academic year in a current degree program at USF, be making normal progress toward degree completion, have CPT as an integral part of their degree program, and have applied for and received work authorization on their I-20 prior to starting CPT.",simple,"[{'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 1, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}]",True
What are the expectations for students in the Master of Business Analytics and Information Systems program after they are accepted?,"['Pre-Application Phase\n\nUnderstanding Program Fit and Outcomes\n\nQ01: ""How do I know if the Master of Business Analytics and Information Systems program is right for me?""\n\nA01: ""This program is ideal for individuals who have a strong interest in data analysis, technology, and business decision-making. If you\'re passionate about leveraging data to solve complex business problems and drive strategic decisions, this program can provide the skills and knowledge you need. We recommend reviewing our curriculum and speaking with current students or alumni to gauge how well the program aligns with your career goals.""\n\nQ02: ""What specializations are available in the Master of Business Analytics and Information Systems program?""\n\nA1: ""Our program offers several specializations, including Data Analytics, Information Systems Management, Business Intelligence, and more. Each path is designed to equip students with in-demand skills and knowledge relevant to the current job market.""\n\nApplication Strategy\n\nQ01: ""What can I do to strengthen my application?""\n\nA01: ""To strengthen your application, focus on highlighting your quantitative and analytical skills, any relevant work experience, and your passion for the field of business analytics. Letters of recommendation should come from individuals who can speak to your academic and professional abilities. A well-crafted statement of purpose that clearly articulates your career goals and how the program can help you achieve them is also crucial.""\n\nQ02: ""What are the prerequisites for applying to this program?""\n\nA02: ""Applicants are expected to have a bachelor\'s degree from an accredited institution, a fundamental understanding of statistics and computer programming, and a competitive GPA. Additional requirements include letters of recommendation, a statement of purpose, and a resume.""\n\nQ03: ""How can I apply as an international student?""\n\nA03: ""International students can apply through our online application portal. You\'ll need to submit your academic transcripts, proof of English language proficiency (TOEFL/IELTS), financial support documents, and a copy of your passport, among other requirements.""\n\nProgram Differentiators\n\n\n\nQ01: ""What sets your Master of Business Analytics and Information Systems program apart from others?""\n\nA01: ""Our program stands out due to its strong emphasis on practical, hands-on experience, its integration with the latest technologies and industry practices, and the extensive network of alumni and industry partners. Additionally, our faculty includes leading experts in business analytics and information systems, who bring real-world insights and research into the classroom.""\n\nFinancial Planning\n\nQ01: ""What kind of financial aid is available for students?""\n\nA01: ""Our institution offers a variety of financial aid options for students, including scholarships, grants, work-study opportunities, and loans. We recommend prospective students apply for financial aid early to maximize their chances of receiving support. Our financial aid office is available to help you navigate the process and identify the best options for your situation.""\n\nPreparing for the Program\n\nQ01: ""How can I prepare academically for the program?""\n\nA01: ""To prepare academically, we recommend brushing up on your quantitative skills, particularly in statistics and mathematics. Familiarity with programming languages such as Python or R, and database management systems, will also be beneficial. Engaging in online courses or workshops that cover these areas can be a great way to prepare.""\n\nApplication Timing and Deadlines\n\nQ01: ""Is there an advantage to applying early to the program?""\n\nA01: ""Applying early can have several advantages, including receiving an earlier decision, having more time to plan for relocation and financing, and in some cases, being considered for early scholarship awards. We encourage applicants to submit their materials as soon as they are ready to take advantage of these benefits.""\n\nProgram Expectations\n\nQ01: ""What is expected from students in the Master of Business Analytics and Information Systems program?""\n\nA01: ""We expect our students to demonstrate a strong commitment to their studies, a willingness to engage in collaborative and individual projects, and an eagerness to learn and apply new concepts and technologies. Successful students typically possess strong analytical skills, effective communication abilities, and the capacity to think critically and solve complex problems.""\n\nApplication Process\n\n\n\nQ01: ""What documents do I need for the student visa application?""\n\nA01: ""You\'ll need a valid passport, the acceptance letter from our institution, proof of financial support, completed visa application forms, and a passport-sized photograph. Depending on your country, additional documents may be required.""\n\nQ02: ""Is there a deadline for applying to the Master\'s program?""\n\nA02: ""Yes, our application deadlines are as follows: Fall semester - May 1st, Spring semester - October 1st. We recommend applying early to ensure sufficient time for visa processing.""\n\nPost-Acceptance and Pre-Arrival\n\nQ01', ' global community that provides a platform for networking, mentorship, and professional growth. As a graduate, you\'ll have access to alumni events, webinars, and other resources to stay connected with your peers and the institution.""\n\nTechnical Requirements and Resources\n\nQ01: ""What are the computing requirements for the program?""\n\nA01: ""Our program requires students to have a laptop with specific hardware configurations to handle data analytics and business intelligence software efficiently. Recommended specifications include a modern multi-core processor, at least 16GB of RAM, and a solid-state drive (SSD). Detailed requirements are available on our program\'s website.""\n\nQ02: ""Are there any software licenses provided for students in this program?""\n\nA02: ""Yes, enrolled students receive access to various professional software tools and platforms necessary for coursework, including statistical analysis, data visualization, and business intelligence software, at no additional cost. This is part of our commitment to ensure students have the necessary resources for their studies.""\n\nAdjusting to a New Environment\n\nQ01: ""How does the university assist international students in adjusting to life in a new country?""\n\n\n\nA01: ""Our international student office offers a range of services designed to help you adjust, including cultural orientation sessions, social events, and workshops on local customs and lifestyle. We also have student mentors who can provide guidance and support as you navigate your new surroundings.""\n\nQ02: ""What kind of health services are available on campus?""\n\nA02: ""Our campus health center provides a range of medical services, including general consultations, mental health support, and emergency care. We also offer health insurance plans suitable for international students, ensuring you have access to comprehensive healthcare during your stay.""\n\nProgram Structure and Content\n\nQ01: ""Can students customize their curriculum within the Master\'s program?""\n\nA01: ""Absolutely. While there are core courses that all students must complete, our program offers elective courses allowing you to tailor your studies to your interests and career goals. Additionally, students can engage in independent study projects or research under faculty supervision for a more customized academic experience.""\n\nQ02: ""Is there an opportunity to study abroad or participate in international projects?""\n\nA02: ""Yes, our program includes opportunities for international study and collaboration through exchange programs, global consulting projects, and internships. These experiences are designed to enhance your global perspective and understanding of international business practices.""\n\nNetworking and Professional Development\n\nQ01: ""How does the program facilitate networking opportunities with industry professionals?""\n\nA01: ""Our program hosts regular networking events, guest lectures, and industry panels featuring alumni and professionals from the fields of business analytics and information systems. These events are excellent opportunities to build connections, gain insights into industry trends, and explore potential career paths.""\n\nQ02: ""Does the university offer career fairs or recruitment events for business analytics students?""\n\nA02: ""Yes, we organize career fairs and recruitment events specifically tailored to business analytics and information systems students. These events attract top employers in the industry looking to hire for internships and full-time positions. We also provide support in preparing for these events, including resume reviews and interview coaching.""\n\nSupport Systems\n\nQ01: ""What kind of academic support is available for students who may struggle with advanced coursework?""\n\n\n\nA01: ""We provide a comprehensive academic support system that includes tutoring services, study groups, and workshops on advanced topics in business analytics and information systems. Faculty members are also available for office hours to provide additional assistance and guidance.""\n\nQ02: ""Are there any mentorship programs available for new students?""\n\nA02: ""Yes, we offer a mentorship program that pairs new students with upperclassmen or alumni who can provide guidance, share their experiences, and offer advice on navigating both the academic and social aspects of the program. This program is designed to help new students transition smoothly into their graduate studies.""\n\nCertainly, Dr. Smith. Further expanding the range of inquiries, the following set of questions and answers delves into more specific and practical aspects that students might consider when applying for and participating in a Master of Business Analytics and Information Systems program.\n\nPractical Experience and Application\n\nQ01: ""Are there opportunities for practical experience within the program?""\n\nA01: ""Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience.""\n\nQ02: ""How does the program incorporate the latest industry trends and technologies?""\n\nA02: ""Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on']","We expect our students to demonstrate a strong commitment to their studies, a willingness to engage in collaborative and individual projects, and an eagerness to learn and apply new concepts and technologies. Successful students typically possess strong analytical skills, effective communication abilities, and the capacity to think critically and solve complex problems.",simple,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}, {'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
How can I access the staff schedule search for course registration?,"[""Course Registration BAIS\nSearching for classes and current enrollment:\nYou can search on Oasis, but the staff schedule search  is an easier interface to use.\nVisit http://www .registrar .usf.edu/ssearch/staff/staff.php\n(https://usfweb.usf.edu/DSS/StaffScheduleSearch) (http://www.registrar.usf.edu/ssearch/staff/staff.php) Please\nmake sure that you read the description of the course carefully .  Some courses are only available to students\nwho are enrolled in specific programs, such as the Global BAIS or the Online MBA, and if you are not\nenrolled in these programs, you will not be eligible to register for these courses.\nIf you need to register for an alternate calendar course , you can use the alternate calendar link:\n https://www .usf.edu/registrar/register/altcalendar .aspx\n(https://www.usf.edu/registrar/register/altcalendar.aspx) (https://www.usf.edu/registrar/register/altcalendar.aspx)\n.  If this doesn’t work, email Dr . Reichgelt ( muma-msbais@usf.edu  (mailto:muma-msbais@usf.edu,) ) or\ncontact the Registrar ’s office at 974-2000.\n \nCourse sequencing & prerequisite checks:\nAs described in the catalog  (https://catalog.usf.edu/preview_program.php?\ncatoid=18&poid=7726&hl=%22BAIS%22&returnto=searchhttps://catalog.usf.edu/preview_program.php?\ncatoid=18&poid=7726&hl=%22BAIS%22&returnto=search) , certain classes have course prerequisites (e.g.,\nISM 6124 Advanced Systems Analysis and Design and ISM 6218 Advanced Database Systems  are both\nprerequisites for ISM 6155 Enterprise Information Systems Management ).  In general, you cannot directly\nregister for the advanced classes without completing the prerequisites in a prior semester . Note that\nconcurrent enrollment in prerequisite and advanced classes is not allowed.  \nIn addition, certain core MS-BAIS classes like Advanced Database Management have pre-program\nprerequisites such as a database prerequisite, which can be met by virtue of a prior course in database\nmanagement from your previous university or adequate working experience with databases in a corporate\nenvironment. Similarly , there are prerequisites for Advanced Systems Analysis & Design and Distributed\nInformation Systems. If you don't meet these core prerequisites, you will have to register for basic courses in\nthese areas at USF and these courses will NOT  count toward the 33-credit MS-BAIS degree requirement. If\nyou are unsure which prerequisites you need, email Dr . Reichgelt ( muma-msbais@usf.edu  (mailto:muma-\nmsbais@usf.edu,) ) with your U# and USF email address and request a prerequisite check.  Every new\nstudent must have their prerequisites checked and any outstanding prerequisites should be completed by\nthe end of your first semester .\nThe following are the required pre-program prerequisites:\nDatabase prerequisite  >> prerequisite for >> ISM 6218 Advanced Database Management.\nSystems analysis & design prerequisite  >> prerequisite for >>  ISM 6124 Advanced Systems Analysis &\nDesign \nOOP  prerequisite  >> prerequisite for  >> ISM 6225 Distributed Information Systems \nStats prerequisite  >> prerequisite for > QMB 6304 Analytical Methods for Business""]",You can access the staff schedule search for course registration by visiting the website http://www.registrar.usf.edu/ssearch/staff/staff.php,simple,"[{'source': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What are some methodologies for addressing the limitations of external auxiliary information in RAG models?,"['various question-answering tasks.\nIn essence, these inference-stage enhancements provide\nlightweight, cost-effective alternatives that leverage the ca-\npabilities of pre-trained models without necessitating further\ntraining. The principal advantage is maintaining static LLM\nparameters while supplying contextually relevant information\nto meet specific task demands. Nevertheless, this approach is\nnot without limitations, as it requires meticulous data pro-\ncessing and optimization, and is bound by the foundational\nmodel’s intrinsic capabilities. To address diverse task require-\nments effectively, this method is often paired with procedural\noptimization techniques such as step-wise reasoning, iterative\nretrieval, and adaptive retrieval strategies.\n6.2 Augmentation Source\nThe effectiveness of RAG models is heavily impacted by the\nselection of data sources for augmentation. Different levels of\nknowledge and dimensions require distinct processing tech-\nniques. They are categorized as unstructured data, structured\ndata, and content generated by LLMs. The technology tree\nof representative RAG research with different augmentation\naspects is depicted in Figure 5. The leaves, colored in three\ndifferent shades, represent enhancements using various types\nof data: unstructured data, structured data, and content gener-\nated by LLMs. The diagram clearly shows that initially, aug-\nmentation was mainly achieved through unstructured data,\nsuch as pure text. This approach later expanded to include\nthe use of structured data (e.g. knowledge graph) for further\nimprovement. More recently, there has been a growing trend\nin research that utilizes content generated by the LLMs them-\nselves for retrieval and augmentation purposes.\nAugmented with Unstructured Data\nUnstructured text, is gathered from corpora, such as prompt\ndata for fine-tuning large models [Cheng et al. , 2023a ]and\ncross-lingual data [Liet al. , 2023b ]. Retrieval units vary from\ntokens (e.g., kNN-LM [Khandelwal et al. , 2019 ]) to phrases\n(e.g., NPM, COG [Leeet al. , 2020, Lan et al. , 2022 ]) and\ndocument paragraphs, with finer granularities offering pre-\ncision at the cost of increased retrieval complexity.\nFLARE [Jiang et al. , 2023b ]introduces an active re-\ntrieval approach, triggered by the LM’s generation of low-\nprobability words. It creates a temporary sentence for doc-\nument retrieval, then regenerates the sentence with the re-\ntrieved context to predict subsequent sentences. RETRO uses\nthe previous chunk to retrieve the nearest neighbor at the\nchunk level, combined with the previous chunk’s context, it\nguides the generation of the next chunk. To preserve causal-\nity, the generation of the next block Cionly utilizes the near-\nest neighbor of the previous block N(Ci−1)and not N(Ci).\nAugmented with Structured Data\nStructured data, such as knowledge graphs (KGs), pro-\nvide high-quality context and mitigate model hallucina-\ntions. RET-LLMs [Modarressi et al. , 2023 ]constructs a\nknowledge graph memory from past dialogues for future ref-\nerence. SUGRE [Kang et al. , 2023 ]employs Graph Neu-\nral Networks (GNNs) to encode relevant KG subgraphs,\nensuring consistency between retrieved facts and gener-\nated text through multi-modal contrastive learning. Knowl-edGPT [Wang et al. , 2023d ]generates KB search queries and\nstores knowledge in a personalized base, enhancing the RAG\nmodel’s knowledge richness and contextuality.\nLLMs-Generated Content in RAG\nAddressing the limitations of external auxiliary information\nin RAG, some research has focused on exploiting LLMs’ in-\nternal knowledge. SKR [Wang et al. , 2023e ]classifies ques-\ntions as known or unknown, applying retrieval enhancement\nselectively. GenRead [Yuet al. , 2022 ]replaces the retriever\nwith an LLM generator, finding that LLM-generated con-\ntexts often contain more accurate answers due to better align-\nment with the pre-training objectives of causal language mod-\neling. Selfmem [Cheng et al. , 2023b ]iteratively creates an\nunbounded memory pool with a retrieval-enhanced genera-\ntor, using a memory selector to choose outputs that serve as\ndual problems to the original question, thus self-enhancing\nthe generative model.\nThese methodologies']","Some methodologies for addressing the limitations of external auxiliary information in RAG models include exploiting LLMs' internal knowledge, using structured data such as knowledge graphs, and augmenting with unstructured data like text corpora.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 13, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What is the proposed paradigm that combines Small Language Models (SLMs) and Large Language Models (LLMs) in the study mentioned?,"['ing process is designed to minimize the difference between\nCextracted and the actual context Ctruth .\nSimilarly, RECOMP adopts a comparable approach by\ntraining an information condenser using contrastive learn-\ning[Xuet al. , 2023a ]. Each training data point consists of\none positive sample and five negative samples, and the en-\ncoder undergoes training using contrastive loss throughout\nthis process [Karpukhin et al. , 2020 ].\nAnother study has taken a different approach by aim-\ning to reduce the number of documents in order to im-\nprove the accuracy of the model’s answers. In the study\nby[Maet al. , 2023b ], they propose the “Filter-Reranker”\nparadigm, which combines the strengths of LLMs and Small\nLanguage Models (SLMs). In this paradigm, SLMs serve as\nfilters, while LLMs function as reordering agents. The re-\nsearch shows that instructing LLMs to rearrange challeng-\ning samples identified by SLMs leads to significant improve-\nments in various Information Extraction (IE) tasks.\nReranking\nThe re-ranking model is pivotal in optimizing the document\nset retrieved from the retriever. Language models often face\nperformance declines when additional context is introduced,\nand re-ranking effectively addresses this issue. The core con-\ncept involves rearranging document records to prioritize the\nmost relevant items at the top, thereby limiting the total num-\nber of documents. This not only resolves the challenge of\ncontext window expansion during retrieval but also enhances\nretrieval efficiency and responsiveness.\nThe re-ranking model assumes a dual role throughout\nthe information retrieval process, functioning as both an']","The proposed paradigm that combines Small Language Models (SLMs) and Large Language Models (LLMs) in the study mentioned is the ""Filter-Reranker"" paradigm.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 9, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the consequences of violations of academic integrity at USF?,"['Academic Integrity\nThe MS-BAIS program follow USF\'s of ficial policies on academic integrity , which are described in detail at\nhttps://www .usf.edu/undergrad/students/ethics-integrity .aspx\n(https://www.usf.edu/undergrad/students/ethics-integrity.aspx) . We encourage you to read through this page\nto familiarize yourself of our of ficial policy and consequences for violations. Students are routinely expelled\nfrom USF (without degree) every year for violations of our of ficial academic integrity policies. ""I did not know""\nor ""This is not considered plagiarism in the culture where I\'m from"" will not be considered an acceptable\nexcuse if you happen to be involved in any of these transgressions. \n \nWhat are violations of academic integrity?\nCheating : Cheating is using or attempting to use materials, information, notes, study aids, or other\nassistance in any assignment, group work, examination, or evaluation that have not been authorized by the\ninstructor .\nPlagiarism : Plagiarism is representing someone else\'s work as your own. For example, you download\nmaterials from the internet for your class project and did not cite or give credit to the original source where\nwe took the material from. Whether intentional or not, plagiarism is an of fense liable under USF academic\nintegrity policies.\n \nWhy is this a big deal?\nThe job of a university is not only to teach, but build responsible and productive members of our society . We\ndon\'t believe we can accomplish the second goal if we allow or overlook ethical transgressions in the\nconduct of our academic and extracurricular activities. W e understand that students don\'t start with an\nintention to cheat, but are forced to do so because of circumstances such as taking too many courses in one\nsemester , try to work full-time while also taking a full academic load, and trying to be perfect for their friends\nand family . These things can put a good person in a bad situation. Before soon, ""I would never cheat""\nbecomes ""W ell, just this once"" which turns into repeated instances of cheating. It is a slippery slope from\nwhere you can\'t get out. W e must intervene to arrest the moral and intellectual slide, and hence, we\nrigorously enforce our academic integrity policies.\n \nWhat are the consequences of academic integrity violations?\nFirst, both cheating and plagiarism have the same penalty and are cumulative throughout your stay at USF ,\nmeaning they accrue over your dif ferent classes with dif ferent professors. The USF of ficial policy for\ntransgressions can be found at https://usf.app.box.com/v/usfregulation3027\n(https://usf.app.box.com/v/usfregulation3027)\nIn general, we follow the following rules:\nFirst of fense:\nZero in the concerned assignment or exam.']","The consequences of violations of academic integrity at USF include receiving a zero in the concerned assignment or exam for a first offense. The penalties for cheating and plagiarism are cumulative throughout a student's stay at USF, meaning they accrue over different classes with different professors. More information can be found in the USF official policy for transgressions.",simple,"[{'source': 'data/pdfs/Academic Integrity_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Academic Integrity_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What are the three developmental paradigms within the RAG framework?,"['Figure 7: Summary of RAG ecosystem\n9 Conclusion\nThe summary of this paper, as depicted in Figure 7, high-\nlights RAG’s significant advancement in enhancing the ca-\npabilities of LLMs through the integration of parameter-\nized knowledge from language models with extensive non-\nparameterized data from external knowledge bases. Our sur-\nvey illustrates the evolution of RAG technologies and their\nimpact on knowledge-intensive tasks. Our analysis delin-\neates three developmental paradigms within the RAG frame-\nwork: Naive, Advanced, and Modular RAG, each marking\na progressive enhancement over its predecessors. The Ad-\nvanced RAG paradigm extends beyond the Naive approach\nby incorporating sophisticated architectural elements, includ-\ning query rewriting, chunk reranking, and prompt summariza-\ntion. These innovations have led to a more nuanced and mod-\nular architecture that enhances both the performance and the\ninterpretability of LLMs. RAG’s technical integration with\nother AI methodologies, such as fine-tuning and reinforce-\nment learning, has further expanded its capabilities. In con-\ntent retrieval, a hybrid methodology that leverages both struc-\ntured and unstructured data sources is emerging as a trend,\nproviding a more enriched retrieval process. Cutting-edge re-\nsearch within the RAG framework is exploring novel con-\ncepts such as self-retrieval from LLMs and the dynamic tim-\ning of information retrieval.\nDespite the strides made in RAG technology, research op-\nportunities abound in improving its robustness and its abil-\nity to manage extended contexts. RAG’s application scope is\nalso widening into multimodal domains, adapting its princi-ples to interpret and process diverse data forms such as im-\nages, videos, and code. This expansion underscores RAG’s\nsignificant practical implications for AI deployment, attract-\ning interest from both academic and industrial sectors. The\ngrowing ecosystem of RAG is underscored by an increase in\nRAG-centric AI applications and the ongoing development\nof supportive tools. However, as RAG’s application land-\nscape expands, there is an imperative need to refine evaluation\nmethodologies to keep pace with its evolution. Ensuring that\nperformance assessments remain accurate and representative\nis crucial for capturing the full extent of RAG’s contributions\nto the AI research and development community.\nReferences\n[Alon et al. , 2022 ]Uri Alon, Frank Xu, Junxian He, Sudipta\nSengupta, Dan Roth, and Graham Neubig. Neuro-\nsymbolic language modeling with automaton-augmented\nretrieval. In International Conference on Machine Learn-\ning, pages 468–485. PMLR, 2022.\n[Anderson et al. , 2022 ]Nathan Anderson, Caleb Wilson,\nand Stephen D. Richardson. Lingua: Addressing scenar-\nios for live interpretation and automatic dubbing. In Jan-\nice Campbell, Stephen Larocca, Jay Marciano, Konstantin\nSavenkov, and Alex Yanishevsky, editors, Proceedings of\nthe 15th Biennial Conference of the Association for Ma-\nchine Translation in the Americas (Volume 2: Users and\nProviders Track and Government Track) , pages 202–209,']","Naive, Advanced, and Modular RAG",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 20, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
How can I determine which classes will be offered online next semester?,"['link and complete the form that comes up.  Please do NOT  email the professor for the course.  They cannot\nissue permits.\n \nWhat delivery modes are courses of fered in, and how can I find out the delivery mode of a course?\nWe offer courses in three dif ferent modes:\nFace-to-face\nAsynchronously online\nSynchronously online\nThe dif ference between the latter two is that the latter will require synchronous meetings via Teams, whereas\nthe former does not.   \nIf a course section in https://usfweb.usf.edu/DSS/StaffScheduleSearch\n(https://usfweb.usf.edu/DSS/StaffScheduleSearch) has both a time associated with it and a classroom, it is a\nface-to-face course.  Online courses will always have Of f-Campus in the Campus field.  Synchronous online\ncourses will contain a note that gives the dates on which the classes meet.  If there is no such note, the\nclass is asynchronous, even though the Time field will say TBA.  The system will not allow us not to put a\ntime in that field.  \nNotes:\n1. The Off-Campus  note is likely to be followed by the name of a campus (e.g., Off-Campus - T ampa , or\nOff-Campus - Sarasota-Manatee ).  Ignore the name of the campus.  This is included for internal financial\npurposes and does not af fect how the course is delivered.\n2. Online courses are a little more expensive than face-to-face courses.  USF charges an additional fee for\nonline courses.  At the moment, the charge is $30.\n3. If you are an international student, you must take the majority of your courses on your home campus,\nwhich is Tampa.  Since the face-to-face classes are in general Tampa classes, this is not a problem for\nmost semesters, but it may become an issue for your last semester .  More details are provided in the\nRCL module.\n \nHow do registration wait-lists work at USF?  \nPlease see:  http://www .usf.edu/registrar/resources/waitlist\n(http://www.usf.edu/registrar/resources/waitlist/)  Please do not place yourself on more than one waitlist for\nthe same course. If you do, we will remove you from all waitlists for that course.\n \nCan I take all my classes online?  \nFrom Fall 2023 onwards, international students can take at most one course online, and must take all their\nother courses on campus.  For the summer term ONL Y, you are able to take more than one online course.\n CPT internships and independent study courses count as on-campus courses.  \nHow do I know which classes will be of fered next semester?  ']",nan,simple,"[{'source': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 2, 'filename': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How can the retriever's output be aligned with the preferences of the Large Language Model?,"['can align the semantic spaces of queries and documents? 3)\nHow can the retriever’s output be aligned with the preferences\nof the Large Language Model?\n4.1 Enhancing Semantic Representations\nIn RAG, the semantic space is essential as it involves the mul-\ntidimensional mapping of queries and documents. Retrieval\naccuracy in this semantic space significantly impacts RAG\noutcomes. This section will present two methods for building\naccurate semantic spaces.\nChunk optimization\nWhen managing external documents, the initial step involves\nbreaking them down into smaller chunks to extract fine-\ngrained features, which are then embedded to represent their\nsemantics. However, embedding overly large or excessively\nsmall text chunks may lead to sub-optimal outcomes. There-\nfore, identifying the optimal chunk size for documents within\nthe corpus is crucial to ensuring the accuracy and relevance\nof the retrieved results.\nChoosing an appropriate chunking strategy requires care-\nful consideration of several vital factors, such as the nature\nof the indexed content, the embedding model and its opti-\nmal block size, the expected length and complexity of user\nqueries, and the specific application’s utilization of the re-\ntrieved results. For instance, the selection of a chunking\nmodel should be based on the content’s length—whether it\nis longer or shorter. Additionally, different embedding mod-\nels demonstrate distinct performance characteristics at vary-\ning block sizes. For example, sentence-transformer performs\nbetter with single sentences, while text-embedding-ada-002\nexcels with blocks containing 256 or 512 tokens.\nAdditionally, factors like the length and complexity of user\ninput questions, and the specific needs of the application (e.g.,\nsemantic search or question answering), have effect on the\nchoice of a chunking strategy. This choice can be directly in-\nfluenced by the token limits of the selected LLMs, requiring\nadjustments to the block size. In reality, getting precise query\nresults involves flexibly applying different chunking strate-\ngies. There is no one-size-fits-all ”best” strategy, only the\nmost appropriate one for a particular context.\nCurrent research in RAG explores various block optimiza-\ntion techniques aimed at improving both retrieval efficiency\nand accuracy. One such approach involves the use of slid-\ning window technology, enabling layered retrieval by merg-\ning globally related information across multiple retrieval pro-\ncesses. Another strategy, known as the “small2big” method,\nutilizes small text blocks during the initial search phase and\nsubsequently provides larger related text blocks to the lan-\nguage model for processing.\nThe abstract embedding technique prioritizes top K re-\ntrieval based on document abstracts (or summaries), offering\na comprehensive understanding of the entire document con-\ntext. Additionally, the metadata filtering technique leverages\ndocument metadata to enhance the filtering process. An in-\nnovative approach, the graph indexing technique, transforms\nentities and relationships into nodes and connections, sig-\nnificantly improving relevance, particularly in the context of\nmulti-hop problems.The combination of these diverse methods has led to no-\ntable advancements, resulting in enhanced retrieval outcomes\nand improved performance for RAG.\nFine-tuning Embedding Models\nOnce the appropriate size of chunks is determined, the\nnext crucial step involves embedding these chunks and the\nquery into the semantic space using an embedding model.\nThe effectiveness of the embedding is critical as it impacts\nthe model’s ability to represent the corpus. Recent re-\nsearch has introduced prominent embedding models such as\nAngIE, V oyage, BGE,etc [Li and Li, 2023, V oyageAI, 2023,\nBAAI, 2023 ]. These models have undergone pre-training on\nextensive corpora. However, their capability to accurately\ncapture domain-specific information may be limited when ap-\nplied to specialized domains.\nMoreover, task-specific fine-tuning of embedding models\nis essential to ensure that the model comprehends the user\nquery in terms of content relevance. A model without fine-\ntuning may not adequately address the requirements of a spe-\ncific task. Consequently, fine-tuning an embedding model be-\ncomes crucial for downstream applications. There are two\nprimary paradigms in embedding fine-tuning methods.\nDomain Knowledge Fine-tuning . To ensure that an embed-\nding model accurately captures domain-specific information,\nit is imperative to utilize domain-specific datasets for fine-\ntuning. This process diverges from standard language model\nfine-tuning, chiefly in the nature of the datasets involved.']",The retriever's output can be aligned with the preferences of the Large Language Model through fine-tuning of the embedding models. Fine-tuning ensures that the model comprehends the user query in terms of content relevance and adequately addresses the requirements of a specific task. Domain-specific datasets are utilized for fine-tuning to accurately capture domain-specific information.,simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 7, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are some of the core components in the taxonomy of RAG?,"['Figure 4: Taxonomy of RAG’s core components\nretrieval-based strategies. The REALM model adopts a struc-\ntured, interpretable method for knowledge embedding, fram-\ning pre-training, and fine-tuning as a retrieve-then-predict\nworkflow within the masked language model (MLM) frame-\nwork [Arora et al. , 2023 ].\nRETRO [Borgeaud et al. , 2022 ]leverages retrieval aug-\nmentation for large-scale pre-training from scratch, achieving\na reduction in model parameters while surpassing standard\nGPT models in terms of perplexity. RETRO distinguishes it-\nself with an additional encoder designed to process features\nof entities retrieved from an external knowledge base, build-\ning on the foundational structure of GPT models.\nAtlas [Izacard et al. , 2022 ]also incorporates a retrieval\nmechanism into the T5 architecture [Raffel et al. , 2020 ]in\nboth the pre-training and fine-tuning stages. It uses a pre-\ntrained T5 to initialize the encoder-decoder language model\nand a pre-trained Contriever for the dense retriever, improv-\ning its efficiency for complex language modeling tasks.Furthermore, COG [Lanet al. , 2022 ]introduces a novel\ntext generation methodology that emulates copying text frag-\nments from pre-existing collections. Utilizing efficient vector\nsearch tools, COG computes and indexes contextually mean-\ningful representations of text fragments, demonstrating supe-\nrior performance in domains such as question-answering and\ndomain adaptation when compared to RETRO.\nThe advent of scaling laws has catalyzed the growth of\nmodel parameters, propelling autoregressive models into the\nmainstream. Researchers are expanding the RAG approach to\npretrained larger models, with RETRO++ exemplifying this\ntrend by scaling up the model parameters while preserving or\nenhancing performance [Wang et al. , 2023b ].\nEmpirical evidence underscores marked improvements in\ntext generation quality, factual accuracy, reduced toxicity,\nand downstream task proficiency, especially in knowledge-\nintensive applications like open-domain QA. These results\nimply that integrating retrieval mechanisms into the pre-']","The core components in the taxonomy of RAG include REALM, RETRO, Atlas, and COG.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 11, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What financial aid options are available for accepted students?,"['Pre-Application Phase\n\nUnderstanding Program Fit and Outcomes\n\nQ01: ""How do I know if the Master of Business Analytics and Information Systems program is right for me?""\n\nA01: ""This program is ideal for individuals who have a strong interest in data analysis, technology, and business decision-making. If you\'re passionate about leveraging data to solve complex business problems and drive strategic decisions, this program can provide the skills and knowledge you need. We recommend reviewing our curriculum and speaking with current students or alumni to gauge how well the program aligns with your career goals.""\n\nQ02: ""What specializations are available in the Master of Business Analytics and Information Systems program?""\n\nA1: ""Our program offers several specializations, including Data Analytics, Information Systems Management, Business Intelligence, and more. Each path is designed to equip students with in-demand skills and knowledge relevant to the current job market.""\n\nApplication Strategy\n\nQ01: ""What can I do to strengthen my application?""\n\nA01: ""To strengthen your application, focus on highlighting your quantitative and analytical skills, any relevant work experience, and your passion for the field of business analytics. Letters of recommendation should come from individuals who can speak to your academic and professional abilities. A well-crafted statement of purpose that clearly articulates your career goals and how the program can help you achieve them is also crucial.""\n\nQ02: ""What are the prerequisites for applying to this program?""\n\nA02: ""Applicants are expected to have a bachelor\'s degree from an accredited institution, a fundamental understanding of statistics and computer programming, and a competitive GPA. Additional requirements include letters of recommendation, a statement of purpose, and a resume.""\n\nQ03: ""How can I apply as an international student?""\n\nA03: ""International students can apply through our online application portal. You\'ll need to submit your academic transcripts, proof of English language proficiency (TOEFL/IELTS), financial support documents, and a copy of your passport, among other requirements.""\n\nProgram Differentiators\n\n\n\nQ01: ""What sets your Master of Business Analytics and Information Systems program apart from others?""\n\nA01: ""Our program stands out due to its strong emphasis on practical, hands-on experience, its integration with the latest technologies and industry practices, and the extensive network of alumni and industry partners. Additionally, our faculty includes leading experts in business analytics and information systems, who bring real-world insights and research into the classroom.""\n\nFinancial Planning\n\nQ01: ""What kind of financial aid is available for students?""\n\nA01: ""Our institution offers a variety of financial aid options for students, including scholarships, grants, work-study opportunities, and loans. We recommend prospective students apply for financial aid early to maximize their chances of receiving support. Our financial aid office is available to help you navigate the process and identify the best options for your situation.""\n\nPreparing for the Program\n\nQ01: ""How can I prepare academically for the program?""\n\nA01: ""To prepare academically, we recommend brushing up on your quantitative skills, particularly in statistics and mathematics. Familiarity with programming languages such as Python or R, and database management systems, will also be beneficial. Engaging in online courses or workshops that cover these areas can be a great way to prepare.""\n\nApplication Timing and Deadlines\n\nQ01: ""Is there an advantage to applying early to the program?""\n\nA01: ""Applying early can have several advantages, including receiving an earlier decision, having more time to plan for relocation and financing, and in some cases, being considered for early scholarship awards. We encourage applicants to submit their materials as soon as they are ready to take advantage of these benefits.""\n\nProgram Expectations\n\nQ01: ""What is expected from students in the Master of Business Analytics and Information Systems program?""\n\nA01: ""We expect our students to demonstrate a strong commitment to their studies, a willingness to engage in collaborative and individual projects, and an eagerness to learn and apply new concepts and technologies. Successful students typically possess strong analytical skills, effective communication abilities, and the capacity to think critically and solve complex problems.""\n\nApplication Process\n\n\n\nQ01: ""What documents do I need for the student visa application?""\n\nA01: ""You\'ll need a valid passport, the acceptance letter from our institution, proof of financial support, completed visa application forms, and a passport-sized photograph. Depending on your country, additional documents may be required.""\n\nQ02: ""Is there a deadline for applying to the Master\'s program?""\n\nA02: ""Yes, our application deadlines are as follows: Fall semester - May 1st, Spring semester - October 1st. We recommend applying early to ensure sufficient time for visa processing.""\n\nPost-Acceptance and Pre-Arrival\n\nQ01']","Our institution offers a variety of financial aid options for students, including scholarships, grants, work-study opportunities, and loans. We recommend prospective students apply for financial aid early to maximize their chances of receiving support. Our financial aid office is available to help you navigate the process and identify the best options for your situation.",simple,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
How can we find out what courses are offered in future semesters at USF?,"[""You can see courses of fered in future semesters by using USF staff search\n(http://usfweb.usf.edu/DSS/StaffScheduleSearch) , but keep in mind that this is a tentative schedule that is\nsubject to change. The final course schedule will be available 1-2 months before the start of the semester .\n \nWhat courses are of fered in summer?\nMost of our students do internships in summer . Hence, we have relatively few course of ferings in the\nsummer . Most elective classes, and well as many core classes, are not of fered in summer . We may also\ncancel classes that have very few students. Hence, if you plan to graduate in summer , plan your coursework\ncarefully to ensure that you can register for the classes you need to graduate in summer . \n \nHow do we register for the GEB 6527 Lean Six Sigma class?  \nThe Lean Six Sigma class is usually of fered the week before the start of the Fall semester but is considered\nan alternate calendar fall class.  It's also frequently of fered in the spring, during the week of spring break.  A\npermit is needed to register (see the link in the schedule search) and tuition waivers don't cover this class. \nNOTE: W e do not control the permits for this course and you should therefore not email us asking for a\npermit.\n ""]","You can see courses offered in future semesters by using USF staff search (http://usfweb.usf.edu/DSS/StaffScheduleSearch), but keep in mind that this is a tentative schedule that is subject to change. The final course schedule will be available 1-2 months before the start of the semester.",simple,"[{'source': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 3, 'filename': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What are the different types of CPT options available at USF?,"['TYPES OF CPT\nWhen you apply for CPT, you must select a type. USF has three types\nof CPT:\nNECESSARY FOR COURSE – Work experience ful\x00lls a requirement of\na course as speci\x00ed by the o\x00cial course description available to the\npublic in a university catalog or website department course listings.\nThe work experience must be directly related to the major/program\nlisted on the \x00rst page of the student’s I-20 and commensurate with\nthe current educational level.\nUSF CENTER FOR CAREER & PROFESSIONAL DEVELOPMENT CO-OP\nOR INTERNSHIP (For Undergraduate Students Only) – The work\nexperience is assigned and monitored by USF’s Career Services. \xa0The\nwork experience must be directly related to the program (major) and\ncommensurate with the current educational level.\nDISSERTATION AND THESIS – The work experience must be\nnecessary and contribute to the production of the \x00nal thesis or\ndissertation. \xa0The student must be in candidacy and enrolled in\ndissertation hours OR already in thesis track and enrolled in thesis\nhours. \xa0\nPlease watch the video below to learn more about the CPT options at\nUSF.\xa0How t o Apply for CPT How t o Apply for CPT']","USF has three types of CPT: Necessary for Course, USF Center for Career & Professional Development Co-op or Internship (For Undergraduate Students Only), and Dissertation and Thesis.",simple,"[{'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 3, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}]",True
What is the importance of meeting prerequisites for courses in the MS-BAIS program?,"['In addition, we strongly suggest that you take courses in a specific sequence.  Past experience has shown\nthat students who have not taken the courses in the suggested sequence are less successful.\nTake ISM 6124 Advanced Systems Analysis & Design  before you take ISM 6208 Data W arehousing . \nTake ISM 6225 Distributed Information Systems  before you take  ISM 6562 Big Data for Business\nApplications. \nTake QMB 6304 Analytical Methods for Business  before you take  ISM 6137 Statistical Data Mining . \nTake ISM 6136 Data Mining  before you take  ISM 6251 Data Science Programming  before you take ISM\n6564 T ext Analytics or ISM 6930 T echnical Foundations of AI\nNOTE 1: We have been a bit lax in enforcing prerequisites.  Starting in the Fall of 2023, we will strictly\nenforce prerequisites and remove students from courses if they have not met the prerequisites.\nNOTE 2 : With the increase in enrollment in the program, we cannot guarantee that we can of fer the core\ncourses (see next page) in every semester .  You should therefore take a core course whenever it is available\nand you are eligible to take it.  If you do not, you may not be able to graduate on time.\n \nElectives:\nWe have a wide range of departmental and non-departmental electives for you to choose from to enrich your\nlearning experience at USF . Note that you must complete 9 credits of departmental (BAIS) electives and\nanother 9 credits of BAIS and/or non-BAIS electives for your MS-BAIS degree. Non-departmental electives\nmust be pre-approved by Dr . Reichgelt before you register in those courses, and may require a permit from\nthe corresponding department. Departmental electives must satisfy prerequisites as described above.\nAny USF class may not count as ""electives"" for your 33-credit MS-BAIS degree. Classes that won\'t count\ninclude any undergraduate class, most 2 or 3-credit MBA  courses such as  ISM 6930 (Data Analytics for\nBusiness), QMB 6305, QMB 6358, QMB 6603, ISM 6021, ISM 6123, ISM 6436, ISM 6217, ISM 6565 and\nmany other Muma College of Business classes.\nAny classes out of our program MUST  be pre-approved by the SISM department before you can register for\nit and expect it to count toward your degree requirement. Contact Dr . Reichgelt ( muma-msbais@usf.edu\n(mailto:muma-msbais@usf.edu) ) for assistance with selecting electives to determine whether they will count\ntoward your degree.  The following non-BAIS course have already been pre-approved:\nEEL 6787: Data Networks, Systems and Security\n \nFIN 6406 Financial Management\nFIN 6246 The Financial System and FinT ech Innovation\nFIN 6416 Advanced Financial Management\nFIN 6455 Financial Modeling and Analytics\nFIN 6465 Financial Statement Analysis\nFIN 6515 Quantitative Investments\nFIN 6605 International Financial Management\nFIN 6778 Quantitative Analytics for Finance\nFIN 6779 FinT ech and Payment Technologies\n ']","Meeting prerequisites for courses in the MS-BAIS program is important because past experience has shown that students who have not taken the courses in the suggested sequence are less successful. Starting in the Fall of 2023, prerequisites will be strictly enforced and students who have not met the prerequisites will be removed from courses. Additionally, with the increase in enrollment, there is no guarantee that core courses will be offered in every semester, so it is important to take them whenever they are available and the student is eligible. Failure to do so may result in delayed graduation.",simple,"[{'source': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What is the course enrollment requirement for a full-time internship during Fall and Spring semesters?,"['For Summer semesters, there is no course enrollment requirement for full-time or part-time internship,\nexcept the 1 credit ISM 6945 course needed for that internship.  You do not need to register for any other\ncourses but you can register for at most one other course.\nFor Fall and Spring semesters, full-time internship is viewed as equivalent of full-time on-campus\nenrollment. But you still have to register for at least 2 credits to maintain student status. One of these\ncredits is the 1-credit ISM 6945 (BAIS Internship) course, and the second credit (or more) can be an\nindependent study or an online or in-person course. Note that we have very limited independent study\nprojects, and even if you want to register for a full-time internship and a 1-credit internship in one\nsemester , we may not be able to place you in an independent study course. In that case, you may have\nto register for a 3-credit course to fulfill the minimum 2-credit requirement. W e have also made a decision\nto limit your course enrollment to a maximum of 6 credit hours if you are doing a full-time internship that\nsemester .\nIf you are doing a part-time internship in Fall or Spring semesters, international students must register for\nat least 9 credit hours of coursework (including the internship) to maintain full-time student status. This\nrule is relaxed for your last (graduating) semester , when you are allowed to register for less than 9 credit\nhours, to meet the 33 credit hour requirement for the MS-BAIS degree. If you wish to pursue this option,\nyou will have to complete a Reduced Course Load (RCL)  application with the Of fice of International\nServices before the start of the semester . The RCL  rule does not apply for domestic students. See the\nRCL module in this course for further details.\n \nWhat process should be followed to do a CPT internship?\n1. Get an internship of fer letter from a US company . This letter must state the name of the company , name of\nyour supervisor , company location, your position/title, whether you will work on-site or remote, your assigned\nresponsibilities, start and end dates of the internship, hours per week, and hourly wage rate that will be paid\nto you. \n2. Complete the relevant  internship form that is available from this module.\nMake sure you select Yes or No as to whether you are graduating that semester .\nChoose the course section that most closely aligns with your employment dates.\nBe sure to complete all parts, including the Nature of Study section. \nUse DocuSign  to create an envelope\n(https://usflearn.instructure.com/courses/1794296/files/155500614/download?wrap=1) including your CPT\ninternship form as the first page followed by your of fer letter and set up the signatures and signing order in\nthis order;\n1. yourself (must sign),\n2. BAIS Academic Director Dr . Anol Bhattacherjee ( abhatt@usf.edu)  (mailto:abhatt@usf.edu) (must sign),\n3. BAIS Graduate Coordinator and advisors at muma-msbais@usf.edu  (mailto:muma-msbais@usf.edu)\n(receive a cc)\nSign AND DA TE the document. Once you upload the form, it will automatically go to Dr . Bhattacherjee for\napproval. Incomplete forms (e.g., missing dates) will be declined and missing or wrong CC: fields, or forms\nthat are not routed in the correct order will stall your application even after it is approved by Dr .\nBhattacherjee. ']","For Fall and Spring semesters, full-time internship is viewed as equivalent of full-time on-campus enrollment. But you still have to register for at least 2 credits to maintain student status. One of these credits is the 1-credit ISM 6945 (BAIS Internship) course, and the second credit (or more) can be an independent study or an online or in-person course.",simple,"[{'source': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 2, 'filename': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What are the core classes required for the MS-BAIS degree?,"['MS-BAIS Advising F AQ\nHow does the MS-BAIS program work?\nThe program requires a minimum of 33 credits, which must include 5 core classes, 3 MS-BAIS electives and\n3 additional electives from our department or other departments if they are 6000 level courses relevant to the\nmajor . Most of these classes are 3 credits each. In addition, you can also take MS-BAIS internships and\nindependent study , which are 1-2 credit courses and those courses will also count toward your 33 credit\ndegree requirements.\nBefore registering for any out-of-department electives, please consult Dr . Johannes Reichgelt to make sure\nthat this course would count toward your degree requirement. For non-departmental courses, you will need a\npermit from that department.\n \nWhat are the dif ferent core and elective course options that I have for my MS-BAIS degree?\nMS-BAIS core classes:\n1. ISM 6124: Advanced Systems Analysis & Design (Prerequisite: Systems Analysis & Design or equivalent\nprofessional knowledge)\n2. ISM 6218: Advanced Database Management (Prerequisite: Database Design/Management or equivalent\nprofessional knowledge)\n3. ISM 6225: Distributed Information Systems (Prerequisite: Object-Oriented Programming or equivalent\nprofessional knowledge)\n4. QMB 6304: Analytical Methods for Business (Prerequisite: One prior course on inferential statistics at\nundergraduate or graduate level)\n5. ISM 6155: Enterprise Information Systems Management (MS-BAIS capstone)\nNOTE : In order not to jeopardize your chances to graduate on time, it is crucial that you complete the core\ncourses as early as possible.  W e have had a number students who did not take core courses when they\nwere available, and then had to postpone their graduation.  This is particularly problematic for international\nstudents who have to maintain a full course load and therefore may have to take more courses than is\nstrictly necessary to complete their program.  While we can ensure that there are suf ficient seats in the core\ncourses overall, we cannot guarantee that you will be able to take a core course in the semester that you\nwant.\nMS-BAIS electives:  \nWe have many electives. This is a partial list of approved electives in no particular order . Refer to our course\ncatalog for a complete list.\n1. ISM 6136: Data Mining\n2. ISM 6419: Data V isualization\n3. ISM 6137: Statistical Data Mining (Prerequisite: QMB 6304)\n4. ISM 6251: Data Science Programming (Prerequisite: ISM 6136)\n5. ISM 6208: Data W arehousing (Prerequisite: ISM 6218)\n6. ISM 6562: Big Data for Business (Prerequisite: ISM 6225)\n7. ISM 6328: Information Security & Risk Management']","The core classes required for the MS-BAIS degree are: 
1. ISM 6124: Advanced Systems Analysis & Design
2. ISM 6218: Advanced Database Management
3. ISM 6225: Distributed Information Systems
4. QMB 6304: Analytical Methods for Business
5. ISM 6155: Enterprise Information Systems Management",simple,"[{'source': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
Where can I find a list of on-campus job opportunities at USF?,"[""Graduate/T eaching Assistantships and On\nCampus Jobs\nWho can apply for GA/T A positions? Can I apply for GA/T A positions outside the School of\nInformation Systems & Management (SISM)?\nAny full-time student who is registered for at least 9 credit hours can apply for GA/T A positions.\nYou do not have to restrict your GA/T A search to the SISM department. Many other departments and centers\nsuch as Center for Urban Transportation Research (CUTR), INT O USF , USF IT , USF Provost's Of fice, USF\nLibrary , etc. provide GA/T A opportunities for technically qualified students. Since programming skills are\noften valued for many of these positions, our BAIS students often find on-campus employment opportunities\nat many of these departments.\n \nWhat are the job requirements of these positions?\nIn TA positions, you are typically helping a professor with a certain class (e.g., statistics). So you need a\nstrong background in that content to qualify for a TA in that class. For example, if Dr . Bhattacherjee needs a\nTA for his Statistical Data Modeling class, he will require that you take that class and perform well in the\nclass to be considered as his TA for that class.\nIn GA  positions, you are helping a center/lab with research, data collection, or other ef forts. There may be\nspecial skills (e.g., programming) required for these positions that will be listed in the job announcement.\n \nWhere can I find GA/T A openings in SISM and in other departments?\nVisit USF Careers  (https://gems.usf.edu:4440/psc/gemspro-\ntam/EMPLOYEE/HRMS/c/HRS_HRAM_FL.HRS_CG_SEARCH_FL.GBL?FOCUS=Applicant) to get a real-time list\nof all on-campus job opportunities across USF , and use that system to apply for GA/T A positions.  Please do\nnot write to individual professors or of fice staf f asking them for GA/T A positions.  W e will count it against you\nif you do.\n \nDo GA/T A positions come with tuition waiver?  \nGA/T A positions may come with tuition waivers for the out-of-state portion of your tuition, meaning that you\nwill still have to pay the in-state portion of your tuition (approximately one-third of out-of-state tuition).\n \nWhat is/are the selection criteria for GA/T A positions in SISM?\nSISM traditionally has 4 types of GA  positions available:\n1. Department undergraduate teaching assistant: Selection based on GRE/GMA T scores,\nTOEIC/T OEFL/IEL TS speak scores (international students), strength in the teaching area and interviews.""]","Visit USF Careers (https://gems.usf.edu:4440/psc/gemspro-tam/EMPLOYEE/HRMS/c/HRS_HRAM_FL.HRS_CG_SEARCH_FL.GBL?FOCUS=Applicant) to get a real-time list of all on-campus job opportunities across USF, and use that system to apply for GA/TA positions.",simple,"[{'source': 'data/pdfs/Graduate_Teaching Assistantships and On Campus Jobs_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Graduate_Teaching Assistantships and On Campus Jobs_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What is the purpose of CPT internships in a professional workplace?,"[""CPT Internships\nWhat are CPT internships?\nCurricular Practical Training (CPT) are training/learning opportunities related to your curriculum (business\nanalytics & information systems) in real-world businesses. These internships may be paid or unpaid, on-site\nor remote, full-time (more than 20 hours/week) or part-time (20 hours or less  per week), and can be done in\nany semester of the year (Summer , Fall, or Spring). There are dif ferent course registration requirements for\nfull-time vs. part-time internships, so read on below . Note that we do not authorize unpaid internships, and\nwe also do not approve internships that are unrelated to your curriculum (e.g., internships in finance or\nmarketing).\nCPT internships are not required to graduate from the BAIS program, but are strongly encouraged, as they\nare an opportunity for you to showcase your skills in a professional workplace and build domain knowledge,\nwhich are both invaluable in securing employment after graduation, and they provide you with an additional\nsource of income. W e have seen numerous instances where internship employers of fered their interns full-\ntime positions upon graduation.\nAlso note that CPT  internship is NOT  a job; it's a learning opportunity related to your curriculum outside of\ntraditional class lectures, or in other words, it is a practicum course (ISM 6945: BAIS Internship; 1 credit).\nHence, we must certify your internship as part of your curriculum and must ensure that you learned some\ncurriculum-related practical knowledge/experience from that internship. For this reason, CPT  internships will\nalso require you to sign up for the BAIS internship course (ISM 6945), specify which other BAIS courses\nhelped you build the skills needed for this internship, and meet the requirements of this course (e.g., first day\nattendance, end-of-term project report, etc.). At the end of the semester , you will get a\nSatisfactory/Unsatisfactory (S/U) grade in the course. You need a satisfactory grade to receive credit for this\ncourse as part of the 33-credit requirement for the BAIS degree. Note that both full-time and part-time\ninternships are 1-credit per semester .\n \nWho is eligible for CPT internships?\nCPT internships at USF are now administered by the student's major department, which in your case, is the\nSchool of Information Systems & Management (SISM). Any student who meets the following criteria is\neligible to do a BAIS internship.\n1. Complete two semesters  (Fall and Spring) of full-time coursework in residence. Students entering in Fall\nare eligible for internship in their first summer . However , students entering in Spring who have completed\nonly one semester of coursework in Spring are NOT  eligible for summer internship in their first summer at\nUSF (sorry , but this is a USCIS ruling over which we have no control).\n2. Complete the following two courses before applying for an internship: (a) QMB 6304  (Analytical Methods\nin Business) and (b) ISM 6218  (Advanced Database Management). Most students take these classes in their\nfirst semester in the BAIS program. However you still have to complete the two-semester residency\nrequirement before you are eligible for CPT  internships.\n3. Maintain a  GPA of 3.0 or higher . If your GP A falls below this level, then you are on academic probation.\nWe will need to work with you to create an action plan to improve your grades so that you can graduate on""]","The purpose of CPT internships in a professional workplace is to showcase your skills, build domain knowledge, and secure employment after graduation. It is a learning opportunity related to your curriculum outside of traditional class lectures and provides an additional source of income. Internship employers may offer full-time positions upon graduation.",simple,"[{'source': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What is the purpose of the two-step retrieval method in the RAG process?,"[' of the process. This two-step re-\ntrieval method helps to strike a balance between efficiency\nand the delivery of contextually rich responses.\nStepBack-prompt approach encourages the LLM to move\naway from specific instances and engage in reasoning around\nbroader concepts and principles [Zheng et al. , 2023 ]. Experi-\nmental results demonstrate a significant performance increase\nin various challenging, inference-based tasks when backward\nprompts are used, highlighting their natural adaptability to the\nRAG process. These retrieval-enhancing steps can be applied\nboth in generating responses to backward prompts and in the\nfinal question-answering process.\nSub-Queries . Depending on the scenario, various query\nstrategies can be employed, such as using query engines\nprovided by frameworks like LlamaIndex, leveraging tree\nqueries, utilizing vector queries, or executing simple sequen-\ntial querying of chunks.\nHypothetical Document Embeddings . HyDE operates on\nthe belief that the answers generated might be closer in the\nembedding space than a direct query. Using the LLM, HyDE\ncreates a hypothetical document (answer) in response to a\nquery, embeds this document, and uses the resulting em-\nbedding to retrieve real documents similar to the hypotheti-\ncal one. Instead of seeking embedding similarity based on\nthe query, this approach focuses on the embedding similar-\nity from one answer to another [Gao et al. , 2022 ]. However,\nit might not consistently produce desirable outcomes, espe-\ncially when the language model is unfamiliar with the subject\nmatter, potentially leading to more instances with errors.\n4 Retrieval\nIn the context of RAG, it is crucial to efficiently retrieve rel-\nevant documents from the data source. However, creating a\nproficient retriever presents significant challenges. This sec-\ntionelves into three fundamental questions: 1) How can we\nachieve accurate semantic representations? 2) What methods']","The purpose of the two-step retrieval method in the RAG process is to strike a balance between efficiency and the delivery of contextually rich responses. It helps the language model engage in reasoning around broader concepts and principles, leading to a significant performance increase in various challenging, inference-based tasks.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 6, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What is the difference between a Practice Center Project (PCP) and a CPT internship?,"[""Practice Center Projects\nWhat is a Practice Center Project?\nPractice Center Projects (PCP) are corporate projects of a predefined scope that recruit two students to work\ncollaboratively on one project aided by a corporate sponsor and a BAIS professor . This is a paid\nengagement, and if selected, you will be paid for up to 20 hours/week by the corporate employer .\n \nHow is PCP  different from CPT internship?\n1. Internship is an individual project and an arrangement between you and the employer . PCP  is a\ncollaborative project, involving two students and one professor , and is an arrangement between the School\nof Information Systems and Management (SISM), that of fers the BAIS degree, and the employer . The\nemployer pays SISM and SISM pays you for your work.\n2. In internships, you are working alone, but in a PCP , you are working with another student and you are\nhelped by a professor .\n3. Another dif ference between PCP  and CPT  internship is that you must complete one academic year of\nstudy to qualify for CPT  internship, but you can get a PCP  in your first year . Whether you are selected\ndepends on what skill set the corporate employer is looking for and whether that fits with your skill set.\nHowever , like internships, PCP  also spans one semester (typically Fall or Spring, but not summer).\n \nHow can you sign up for PCP?\nUnlike internships, where you have to get your own internship, PCP  is arranged by SISM. Corporate\nemployers approach SISM with their projects every semester . Anna sends out e-mails to students indicating\nthese projects usually before the start of Fall and Spring semesters. You can send in your resumes to Anna,\nindicating which PCPs you are interest it. The corporate sponsor will review all resumes and shortlist\ncandidates for interview . Following your interviews, candidates will be notified of their interview results. Make\nsure that you are on Anna's e-mail list to receive these PCP  e-mails.""]","The difference between a Practice Center Project (PCP) and a CPT internship is that PCP is a collaborative project involving two students and one professor, while an internship is an individual project between the student and the employer. Additionally, PCP can be obtained in the first year of study, whereas CPT internship requires completion of one academic year. PCP is arranged by SISM, while internships require the student to find their own opportunity.",simple,"[{'source': 'data/pdfs/Practice Center Projects_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Practice Center Projects_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How does the training regimen in the model acknowledge the critical role of entity semantics in representation learning of textual data for retrieval?,"[' and\nsemantic nuances. The initial phase focuses on the retriever,\nwhere contrastive learning is harnessed to refine the query\nand document embeddings.\nSubsequently, the generator’s preliminary training stage\nemploys contrastive learning to align the structured data with\nits unstructured document descriptions. In a further stage of\ngenerator training, the model acknowledges the critical role\nof entity semantics in the representation learning of textual\ndata for retrieval, as highlighted by [Sciavolino et al. , 2021,\nZhang et al. , 2019 ]. This process commences with the identi-\nfication of entities within the structured data, followed by the\napplication of masks over these entities within the generator’s\ninput data, thus setting the stage for the model to anticipate\nand predict these masked elements.\nThe training regimen progresses with the model learning\nto reconstruct the masked entities by leveraging contextual\ninformation. This exercise cultivates the model’s comprehen-\nsion of the textual data’s structural semantics and facilitates\nthe alignment of pertinent entities within the structured data.\nThe overarching optimization goal is to train the language\nmodel to accurately restore the obscured spans, thereby en-\nriching its understanding of entity semantics [Yeet al. , 2020 ].\n6 Augmentation in RAG\nThis section is structured around three key aspects: the aug-\nmentation stage, sources of augmentation data, and the aug-\nmentation process. These facets elucidate the critical tech-\nnologies pivotal to RAG’s development. A taxonomy of\nRAG’s core components is presented in Figure 4.\n6.1 RAG in Augmentation Stages\nRAG, a knowledge-intensive endeavor, incorporates a vari-\nety of technical methodologies across the pre-training, fine-\ntuning, and inference stages of language model training.\nPre-training Stage\nDuring the pre-training stage, researchers have investigated\nmethods to bolster PTMs for open-domain QA through']","The training regimen in the model acknowledges the critical role of entity semantics in the representation learning of textual data for retrieval by identifying entities within the structured data, applying masks over these entities in the generator's input data, and training the model to reconstruct the masked entities using contextual information. This helps the model understand the structural semantics of the textual data and align pertinent entities within the structured data.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 10, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
How does direct supervision using feedback from LLMs improve the alignment between retrievers and LLMs?,"['While these methods improve semantic representation\nby incorporating domain knowledge and task-specific fine-\ntuning, retrievers may not always exhibit optimal compatibil-\nity with certain LLMs. To address this, some researchers have\nexplored direct supervision of the fine-tuning process using\nfeedback from LLMs. This direct supervision seeks to align\nthe retriever more closely with the LLM, thereby improving\nperformance on downstream tasks. A more comprehensive\ndiscussion on this topic is presented in Section 4.3.\n4.2 Aligning Queries and Documents\nIn the context of RAG applications, retrievers may utilize\na single embedding model for encoding both the query and\nthe documents, or employ separate models for each. Addi-\ntionally, the user’s original query may suffer from imprecise\nphrasing and lack of semantic information. Therefore, it is\ncrucial to align the semantic space of the user’s query with\nthose of the documents. This section introduces two funda-\nmental techniques aimed at achieving this alignment.\nQuery Rewriting\nQuery rewriting is a fundamental approach for aligning\nthe semantics of a query and a document. Methods\nsuch as Query2Doc and ITER-RETGEN leverage LLMs\nto create a pseudo-document by combining the origi-\nnal query with additional guidance [Wang et al. , 2023c,\nShao et al. , 2023 ]. HyDE constructs query vectors using\ntextual cues to generate a “hypothetical” document captur-\ning essential patterns [Gao et al. , 2022 ]. RRR introduces a\nframework that reverses the traditional retrieval and read-\ning order, focusing on query rewriting [Maet al. , 2023a ].\nSTEP-BACKPROMPTING enables LLMs to perform ab-\nstract reasoning and retrieval based on high-level con-\ncepts [Zheng et al. , 2023 ]. Additionally, the multi-query re-\ntrieval method utilizes LLMs to generate and execute multiple\nsearch queries simultaneously, advantageous for addressing\ncomplex problems with multiple sub-problems.\nEmbedding Transformation\nBeyond broad strategies such as query rewriting, there exist\nmore granular techniques specifically designed for embed-\nding transformations. LlamaIndex [Liu, 2023 ]exemplifies\nthis by introducing an adapter module that can be integrated\nfollowing the query encoder. This adapter facilitates fine-\ntuning, thereby optimizing the representation of query em-\nbeddings to map them into a latent space that is more closely\naligned with the intended tasks.\nThe challenge of aligning queries with structured exter-\nnal documents, particularly when addressing the incongruity\nbetween structured and unstructured data, is addressed by\nSANTA [Liet al. , 2023d ]. It enhances the retriever’s sen-\nsitivity to structured information through two pre-training\nstrategies: first, by leveraging the intrinsic alignment between\nstructured and unstructured data to inform contrastive learn-\ning in a structured-aware pre-training scheme; and second, by\nimplementing Masked Entity Prediction. The latter utilizes\nan entity-centric masking strategy that encourages language\nmodels to predict and fill in the masked entities, thereby fos-\ntering a deeper understanding of structured data.The issue of aligning queries with structured exter-\nnal documents, especially when dealing with the dispar-\nity between structured and unstructured data, is tackled by\nSANTA [Liet al. , 2023d ]. This approach improves the re-\ntriever’s ability to recognize structured information through\ntwo pre-training strategies: firstly, by utilizing the inher-\nent alignment between structured and unstructured data to\nguide contrastive learning in a structured-aware pre-training\nscheme; and secondly, by employing Masked Entity Predic-\ntion. The latter uses an entity-centric masking strategy to\nprompt language models to predict and complete the masked\nentities, thus promoting a more profound comprehension of\nstructured data.\n4.3 Aligning Retriever and LLM\nIn the RAG pipeline, enhancing retrieval hit rate through var-\nious techniques may not necessarily improve the final out-\ncome, as the retrieved documents may not align with the spe-\ncific requirements of the LLMs. Therefore, this section in-\ntroduces two methods aimed at aligning the retriever outputs\nwith the preferences of the LLMs.\nFine-tuning Retrievers\nSeveral studies utilize feedback signals from LLMs to refine\nretrieval models. For instance, AAR [Yuet al. , 2023b ]intro-\nduces supervisory signals for a pre-trained retriever']","Direct supervision using feedback from LLMs improves the alignment between retrievers and LLMs by aligning the retriever more closely with the LLM, thereby improving performance on downstream tasks.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 8, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the rules and restrictions for Department graduate teaching assistant positions?,"['2. Department graduate teaching assistant: Selection based on class performance, faculty\nrecommendation.\n3. Department skills based positions: Selection based on project scope and technical skills required.\n4. Pre-approved positions outside the department: Selection based on position responsibilities and\ntechnical skills required. \nIncoming international students will have to submit a copy of their visa along with their application in order to\nbe considered for any positions.  \n \nWhat are the rules and restrictions for GA/T A positions?   \nGAs/T As have to be on campus as a full-time student (or can have a reduced course load during the final\nsemester).\nGA/T A positions begin one week before classes start and finish at the end of the semester/ending\ncontract date. \nGAs/T As are not eligible for full-time internships or practice center projects in the same semester . If you\ndid a CPT  internship in a previous semester , that job must end before your GA/T A start date. \nGA/T A positions are semester-wide contracts, and you are not allowed to discontinue the position for an\ninternship later on in the same semester . Though we understand that internships are more beneficial for\nyou than the GA  position, once you start the GA  position at the school, discontinuing it in the middle of\nthe semester af fects the school and professors’  planning. Thus, no internship for a GA/T A will be\napproved once the semester starts . The only exception will be if you have a 20 hours internship and a\nmaximum of one class take in the semester . Your 20 hours GA  + 20 hours internship are a full-time\nengagement. You will not have the time to take more than 1 class along with both 20 hrs GA  and 20 hrs\ninternship.\nOther on-campus jobs\nThere are other on campus jobs that you can apply for to support yourself financially , such as jobs in food\nservices or in the book store.  If you are interested in any of those jobs, look for them in and apply through\nHandshake at https://usf.joinhandshake.com/login.  (https://usf.joinhandshake.com/login)']","GAs/TAs have to be on campus as a full-time student (or can have a reduced course load during the final semester). GA/TA positions begin one week before classes start and finish at the end of the semester/ending contract date. GAs/TAs are not eligible for full-time internships or practice center projects in the same semester. If you did a CPT internship in a previous semester, that job must end before your GA/TA start date. GA/TA positions are semester-wide contracts, and you are not allowed to discontinue the position for an internship later on in the same semester. Though we understand that internships are more beneficial for you than the GA position, once you start the GA position at the school, discontinuing it in the middle of the semester affects the school and professors’ planning. Thus, no internship for a GA/TA will be approved once the semester starts. The only exception will be if you have a 20 hours internship and a maximum of one class take in the semester. Your 20 hours GA + 20 hours internship are a full-time engagement. You will not have the time to take more than 1 class along with both 20 hrs GA and 20 hrs internship.",simple,"[{'source': 'data/pdfs/Graduate_Teaching Assistantships and On Campus Jobs_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/Graduate_Teaching Assistantships and On Campus Jobs_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What are some future challenges of RAG technology?,"['Table 2: Summary of metrics applicable for evaluation aspects of RAG\nContext\nRelevanceFaithfulnessAnswer\nRelevanceNoise\nRobustnessNegative\nRejectionInformation\nIntegrationCounterfactual\nRobustness\nAccuracy ✓ ✓ ✓ ✓ ✓ ✓ ✓\nEM ✓\nRecall ✓\nPrecision ✓ ✓\nR-Rate ✓\nCosine Similarity ✓\nHit Rate ✓\nMRR ✓\nNDCG ✓\nTable 3: Summary of evaluation frameworks\nEvaluation Framework Evaluation Targets Evaluation Aspects Quantitative Metrics\nRGB† Retrieval Quality\nGeneration QualityNoise Robustness\nNegative Rejection\nInformation Integration\nCounterfactual RobustnessAccuracy\nEM\nAccuracy\nAccuracy\nRECALL†Generation Quality Counterfactual Robustness R-Rate (Reappearance Rate)\nRAGAS‡ Retrieval Quality\nGeneration QualityContext Relevance\nFaithfulness\nAnswer Relevance*\n*\nCosine Similarity\nARES‡ Retrieval Quality\nGeneration QualityContext Relevance\nFaithfulness\nAnswer RelevanceAccuracy\nAccuracy\nAccuracy\nTruLens‡ Retrieval Quality\nGeneration QualityContext Relevance\nFaithfulness\nAnswer Relevance*\n*\n*\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional\nmetrics. Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these\nmetrics, as required.\n8 Future Prospects\nThis section explores three future prospects for RAG: future\nchallenges, modality expansion, and the RAG ecosystem.\n8.1 Future Challenges of RAG\nDespite the considerable progress in RAG technology, several\nchallenges persist that warrant in-depth research:\nContext Length . RAG’s efficacy is limited by the context\nwindow size of Large Language Models (LLMs). Balancing\nthe trade-off between a window that is too short, risking insuf-\nficient information, and one that is too long, risking informa-\ntion dilution, is crucial. With ongoing efforts to expand LLM\ncontext windows to virtually unlimited sizes, the adaptation\nof RAG to these changes presents a significant research ques-\ntion[Xuet al. , 2023c, Packer et al. , 2023, Xiao et al. , 2023 ].\nRobustness . The presence of noise or contradictory infor-\nmation during retrieval can detrimentally affect RAG’s out-put quality. This situation is figuratively referred to as “Mis-\ninformation can be worse than no information at all”. Im-\nproving RAG’s resistance to such adversarial or counterfac-\ntual inputs is gaining research momentum and has become a\nkey performance metric [Yuet al. , 2023a, Glass et al. , 2021,\nBaek et al. , 2023 ].\nHybrid Approaches (RAG+FT) . Combining RAG with\nfine-tuning is emerging as a leading strategy. Determining the\noptimal integration of RAG and fine-tuning whether sequen-\ntial, alternating, or through end-to-end joint training—and\nhow to harness both parameterized and non-parameterized\nadvantages are areas ripe for exploration [Linet al. , 2023 ].\nExpanding LLM Roles . Beyond generating final answers,\nLLMs are leveraged for retrieval and evaluation within RAG\nframeworks. Identifying ways to further unlock LLMs poten-\ntial in RAG systems is a growing research direction.\nScaling Laws . While scaling laws [Kaplan et al. , 2020 ]are\nestablished for LLMs, their applicability to RAG remains un-']","Despite the considerable progress in RAG technology, several challenges persist that warrant in-depth research: Context Length, Robustness, Hybrid Approaches (RAG+FT), Expanding LLM Roles, and Scaling Laws.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 18, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What is the primary objective of evaluating RAG models in the field of Natural Language Processing (NLP)?,"['Zhang, 2023 ]. Graph-Toolformer, for instance, divides its re-\ntrieval process into distinct steps where LLMs proactively use\nretrievers, apply Self-Ask techniques, and employ few-shot\nprompts to initiate search queries. This proactive stance al-\nlows LLMs to decide when to search for necessary informa-\ntion, akin to how an agent utilizes tools.\nWebGPT [Nakano et al. , 2021 ]integrates a reinforcement\nlearning framework to train the GPT-3 model in au-\ntonomously using a search engine during text generation.\nIt navigates this process using special tokens that facili-\ntate actions such as search engine queries, browsing results,\nand citing references, thereby expanding GPT-3’s capabilities\nthrough the use of external search engines.\nFlare automates timing retrieval by monitoring the confi-\ndence of the generation process, as indicated by the probabil-\nity of generated terms [Jiang et al. , 2023b ]. When the prob-\nability falls below a certain threshold would activates the re-\ntrieval system to collect relevant information, thus optimizing\nthe retrieval cycle.\nSelf-RAG [Asai et al. , 2023 ]introduces “reflection to-\nkens” that allow the model to introspect its outputs. These\ntokens come in two varieties: “retrieve” and “critic”. The\nmodel autonomously decides when to activate retrieval, or\nalternatively, a predefined threshold may trigger the pro-\ncess. During retrieval, the generator conducts a fragment-\nlevel beam search across multiple paragraphs to derive the\nmost coherent sequence. Critic scores are used to update the\nsubdivision scores, with the flexibility to adjust these weights\nduring inference, tailoring the model’s behavior. Self-RAG’s\ndesign obviates the need for additional classifiers or reliance\non Natural Language Inference (NLI) models, thus stream-\nlining the decision-making process for when to engage re-\ntrieval mechanisms and improving the model’s autonomous\njudgment capabilities in generating accurate responses.\nLLM optimization has received significant attention due to\nits increasing prevalence. Techniques such as prompt engi-\nneering, Fine-Tuning (FT), and RAG each have distinct char-\nacteristics, visually represented in Figure 6. While prompt\nengineering leverages a model’s inherent capabilities, opti-\nmizing LLMs often requires the application of both RAG and\nFT methods. The choice between RAG and FT should be\nbased on the specific requirements of the scenario and the in-\nherent properties of each approach. A detailed comparison of\nRAG and FT is presented in Table 1.\n6.4 RAG vs Fine-Tuning\nRAG is like giving a model a textbook for tailored informa-\ntion retrieval, perfect for specific queries. On the other hand,\nFT is like a student internalizing knowledge over time, bet-\nter for replicating specific structures, styles, or formats. FT\ncan improve model performance and efficiency by reinforc-\ning base model knowledge, adjusting outputs, and teaching\ncomplex instructions. However, it is not as good for integrat-\ning new knowledge or rapidly iterating new use cases.\nThe two methods, RAG and FT, are not mutually exclusive\nand can be complementary, augmenting a model’s capabil-\nities at different levels. In some cases, their combined use\nmay yield optimal performance. The optimization processinvolving RAG and FT can necessitate multiple iterations to\nachieve satisfactory results.\n7 RAG Evaluation\nThe rapid advancement and growing adoption of RAG in the\nfield of Natural Language Processing (NLP) have propelled\nthe evaluation of RAG models to the forefront of research in\nthe LLMs community. The primary objective of this evalua-\ntion is to comprehend and optimize the performance of RAG\nmodels across diverse application scenarios.\nHistorically, RAG models assessments have centered\non their execution in specific downstream tasks. These\nevaluations employ established metrics suitable to the tasks\nat hand. For instance, question answering evaluations\nmight rely on EM and F1 scores [Wang et al. , 2023a,\nShiet al. , 2023, Feng et al. , 2023, Ma et al. , 2023a ], whereas\nfact-checking tasks often hinge on accuracy as the pri-\nmary metric [Lewis et al. , 2020, Izacard et al. , 2022,\nShao et al. , 2023 ]. Tools like RALLE, designed for the auto-\nmatic evaluation of RAG applications, similarly base their as-\nsessments on these task-']",The primary objective of evaluating RAG models in the field of Natural Language Processing (NLP) is to comprehend and optimize their performance across diverse application scenarios.,simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 15, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the enrollment requirements for students participating in a CPT experience?,"['There is no mechanism for expedited processing. If the student\nsubmits the CPT request with not enough time to be processed, the\nCPT start date will be changed to the date the CPT application is\napproved.\nCPT AND FULL-TIME ENROLLMENT\nREQUIREMENTS\nUndergraduate students must be enrolled for at least 12 credit hours\nin a semester. Graduate students must be enrolled for at least 9 credit\nhours. In addition, graduate students need to be enrolled at least 2\ncredit hours during their \x00nal semester (summer included).\nIf you are doing a full-time CPT.\xa0\nIf full-time CPT lasts 12 weeks or more during a Fall or Spring\nSemester, the student may* be eligible to enroll in less than a full\ncourse load.\nIf full-time CPT lasts less than 12 weeks of a Fall or Spring\nSemester, the student is required to be enrolled in a full-time\ncourse load** (including the CPT course)\nDuring summer, students can enroll for the CPT-related course\nonly. No additional registration is required for immigration\npurposes.\xa0\nPart-time CPT:\xa0\nStudents authorized for part-time CPT during a Fall or Spring\nSemester must be enrolled in full-time course load** (including\nthe CPT course) no matter the duration of the CPT experience\nDuring summer, students can enroll for the CPT-related course\nonly. No additional registration is required for immigration\npurposes.\n*Approval of full-time CPT that will last 12 weeks or more does NOT\nautomatically authorize a student to drop below full-time. This will be']","Undergraduate students must be enrolled for at least 12 credit hours in a semester. Graduate students must be enrolled for at least 9 credit hours. In addition, graduate students need to be enrolled at least 2 credit hours during their final semester (summer included).",simple,"[{'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 5, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}]",True
How can I obtain a permit for ISM 6577: Business Continuity and Recovery Planning?,"[""8. ISM 6156: ERP  & BPM\n9. ISM 6316: Project Management\n10. ISM 6930: Text Analytics (Prerequisite: ISM 6251)\n11. ISM 6577: Business Continuity and Recovery Planning\n12. ISM 6945: BAIS Internship (1 credit for both full-time and part-time internships, max 3 credits for 3\nsemesters)\n13. ISM 6905: Independent Study (1 or 2 credits)\nPrerequisites for any class must be completed in a PREVIOUS semester . Concurrent enrollment in a class\nAND its prerequisite in the same semester is not allowed. If you need help with prerequisites, please e-mail\nDr. Reichgelt.\n \nAre there any ISM/QMB classes that can't be used towards graduation?  \nYes. Classes that can't be used as MS BAIS electives include a ny undergraduate class, most 2 or 3 credit\nMBA  courses or MBA  sections of MS-BAIS courses such as ISM 6930-Data Analytics for Business,  QMB\n6305, QMB 6358, QMB 6603,  ISM 6021, ISM 6123 (Fund of Data Mgmt & Analysis),  ISM 6436,  ISM\n6217.  Some other graduate College of Business classes may be ineligible.  Please contact Dr . Johannes\nReichgelt if you plan to register for any of these courses or have any questions in this regard.\n \nHow many credits can I register for?  \nThere is a limit to the number of courses you can register for .  In the regular semesters, i.e. Fall and Spring,\nyou can register for at most 4 courses (12 credits).  In the Summer , you can register for at most 2 courses (6\ncredits).  There are additional rules that apply when you have a full-time internship and these rules are\nexplained in the CPT  module.  USF insists that you enroll for at least 2 credits in your graduating semester . \nThis includes the Summer semester .\nThe Lean Six Sigma course counts towards the 12 credits if you take in the Spring, but not if you take it in\nthe Fall.  The Spring course is in the middle of the semester; the fall course is of fered before the Fall\nsemester starts.\n \nHow can I register for alternate calendar classes?  \nUse this link: https://www .usf.edu/registrar/register/altcalendar .aspx\n(https://www.usf.edu/registrar/register/altcalendar.aspx)  \nContact the registrar's of fice at 974-2000 for if you have concerns about late add fees.  You should be able to\ndrop alternate classes during the first scheduled week without penalty , but again - this is the registrar's\ndomain, so always check with them to confirm.\n \nSome courses require a permit.   How do I get one?  \nIf you look up the course on https://usfweb.usf.edu/DSS/StaffScheduleSearch\n(https://usfweb.usf.edu/DSS/StaffScheduleSearch) , you will see link in the description of the course.  Click that""]","If you look up the course on https://usfweb.usf.edu/DSS/StaffScheduleSearch, you will see a link in the description of the course. Click that link to obtain a permit for ISM 6577: Business Continuity and Recovery Planning.",simple,"[{'source': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How can the retriever's output be aligned with the preferences of the Large Language Model using semantic spaces?,"['can align the semantic spaces of queries and documents? 3)\nHow can the retriever’s output be aligned with the preferences\nof the Large Language Model?\n4.1 Enhancing Semantic Representations\nIn RAG, the semantic space is essential as it involves the mul-\ntidimensional mapping of queries and documents. Retrieval\naccuracy in this semantic space significantly impacts RAG\noutcomes. This section will present two methods for building\naccurate semantic spaces.\nChunk optimization\nWhen managing external documents, the initial step involves\nbreaking them down into smaller chunks to extract fine-\ngrained features, which are then embedded to represent their\nsemantics. However, embedding overly large or excessively\nsmall text chunks may lead to sub-optimal outcomes. There-\nfore, identifying the optimal chunk size for documents within\nthe corpus is crucial to ensuring the accuracy and relevance\nof the retrieved results.\nChoosing an appropriate chunking strategy requires care-\nful consideration of several vital factors, such as the nature\nof the indexed content, the embedding model and its opti-\nmal block size, the expected length and complexity of user\nqueries, and the specific application’s utilization of the re-\ntrieved results. For instance, the selection of a chunking\nmodel should be based on the content’s length—whether it\nis longer or shorter. Additionally, different embedding mod-\nels demonstrate distinct performance characteristics at vary-\ning block sizes. For example, sentence-transformer performs\nbetter with single sentences, while text-embedding-ada-002\nexcels with blocks containing 256 or 512 tokens.\nAdditionally, factors like the length and complexity of user\ninput questions, and the specific needs of the application (e.g.,\nsemantic search or question answering), have effect on the\nchoice of a chunking strategy. This choice can be directly in-\nfluenced by the token limits of the selected LLMs, requiring\nadjustments to the block size. In reality, getting precise query\nresults involves flexibly applying different chunking strate-\ngies. There is no one-size-fits-all ”best” strategy, only the\nmost appropriate one for a particular context.\nCurrent research in RAG explores various block optimiza-\ntion techniques aimed at improving both retrieval efficiency\nand accuracy. One such approach involves the use of slid-\ning window technology, enabling layered retrieval by merg-\ning globally related information across multiple retrieval pro-\ncesses. Another strategy, known as the “small2big” method,\nutilizes small text blocks during the initial search phase and\nsubsequently provides larger related text blocks to the lan-\nguage model for processing.\nThe abstract embedding technique prioritizes top K re-\ntrieval based on document abstracts (or summaries), offering\na comprehensive understanding of the entire document con-\ntext. Additionally, the metadata filtering technique leverages\ndocument metadata to enhance the filtering process. An in-\nnovative approach, the graph indexing technique, transforms\nentities and relationships into nodes and connections, sig-\nnificantly improving relevance, particularly in the context of\nmulti-hop problems.The combination of these diverse methods has led to no-\ntable advancements, resulting in enhanced retrieval outcomes\nand improved performance for RAG.\nFine-tuning Embedding Models\nOnce the appropriate size of chunks is determined, the\nnext crucial step involves embedding these chunks and the\nquery into the semantic space using an embedding model.\nThe effectiveness of the embedding is critical as it impacts\nthe model’s ability to represent the corpus. Recent re-\nsearch has introduced prominent embedding models such as\nAngIE, V oyage, BGE,etc [Li and Li, 2023, V oyageAI, 2023,\nBAAI, 2023 ]. These models have undergone pre-training on\nextensive corpora. However, their capability to accurately\ncapture domain-specific information may be limited when ap-\nplied to specialized domains.\nMoreover, task-specific fine-tuning of embedding models\nis essential to ensure that the model comprehends the user\nquery in terms of content relevance. A model without fine-\ntuning may not adequately address the requirements of a spe-\ncific task. Consequently, fine-tuning an embedding model be-\ncomes crucial for downstream applications. There are two\nprimary paradigms in embedding fine-tuning methods.\nDomain Knowledge Fine-tuning . To ensure that an embed-\nding model accurately captures domain-specific information,\nit is imperative to utilize domain-specific datasets for fine-\ntuning. This process diverges from standard language model\nfine-tuning, chiefly in the nature of the datasets involved.']","The retriever's output can be aligned with the preferences of the Large Language Model by using semantic spaces. Semantic spaces involve the multidimensional mapping of queries and documents, and retrieval accuracy in this space significantly impacts the outcomes. Two methods for building accurate semantic spaces are chunk optimization and fine-tuning embedding models. Chunk optimization involves breaking down external documents into smaller chunks to extract fine-grained features, while fine-tuning embedding models ensures that the model comprehends the user query in terms of content relevance. These methods, along with other techniques like sliding window technology and abstract embedding, enhance retrieval outcomes and improve performance for the Large Language Model.",simple,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 7, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the prerequisites for ISM 6930: Text Analytics?,"[""8. ISM 6156: ERP  & BPM\n9. ISM 6316: Project Management\n10. ISM 6930: Text Analytics (Prerequisite: ISM 6251)\n11. ISM 6577: Business Continuity and Recovery Planning\n12. ISM 6945: BAIS Internship (1 credit for both full-time and part-time internships, max 3 credits for 3\nsemesters)\n13. ISM 6905: Independent Study (1 or 2 credits)\nPrerequisites for any class must be completed in a PREVIOUS semester . Concurrent enrollment in a class\nAND its prerequisite in the same semester is not allowed. If you need help with prerequisites, please e-mail\nDr. Reichgelt.\n \nAre there any ISM/QMB classes that can't be used towards graduation?  \nYes. Classes that can't be used as MS BAIS electives include a ny undergraduate class, most 2 or 3 credit\nMBA  courses or MBA  sections of MS-BAIS courses such as ISM 6930-Data Analytics for Business,  QMB\n6305, QMB 6358, QMB 6603,  ISM 6021, ISM 6123 (Fund of Data Mgmt & Analysis),  ISM 6436,  ISM\n6217.  Some other graduate College of Business classes may be ineligible.  Please contact Dr . Johannes\nReichgelt if you plan to register for any of these courses or have any questions in this regard.\n \nHow many credits can I register for?  \nThere is a limit to the number of courses you can register for .  In the regular semesters, i.e. Fall and Spring,\nyou can register for at most 4 courses (12 credits).  In the Summer , you can register for at most 2 courses (6\ncredits).  There are additional rules that apply when you have a full-time internship and these rules are\nexplained in the CPT  module.  USF insists that you enroll for at least 2 credits in your graduating semester . \nThis includes the Summer semester .\nThe Lean Six Sigma course counts towards the 12 credits if you take in the Spring, but not if you take it in\nthe Fall.  The Spring course is in the middle of the semester; the fall course is of fered before the Fall\nsemester starts.\n \nHow can I register for alternate calendar classes?  \nUse this link: https://www .usf.edu/registrar/register/altcalendar .aspx\n(https://www.usf.edu/registrar/register/altcalendar.aspx)  \nContact the registrar's of fice at 974-2000 for if you have concerns about late add fees.  You should be able to\ndrop alternate classes during the first scheduled week without penalty , but again - this is the registrar's\ndomain, so always check with them to confirm.\n \nSome courses require a permit.   How do I get one?  \nIf you look up the course on https://usfweb.usf.edu/DSS/StaffScheduleSearch\n(https://usfweb.usf.edu/DSS/StaffScheduleSearch) , you will see link in the description of the course.  Click that""]",Prerequisite for ISM 6930: Text Analytics is ISM 6251.,simple,"[{'source': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How does structured data enhance RAG models compared to unstructured data and LLM-generated content?,"['various question-answering tasks.\nIn essence, these inference-stage enhancements provide\nlightweight, cost-effective alternatives that leverage the ca-\npabilities of pre-trained models without necessitating further\ntraining. The principal advantage is maintaining static LLM\nparameters while supplying contextually relevant information\nto meet specific task demands. Nevertheless, this approach is\nnot without limitations, as it requires meticulous data pro-\ncessing and optimization, and is bound by the foundational\nmodel’s intrinsic capabilities. To address diverse task require-\nments effectively, this method is often paired with procedural\noptimization techniques such as step-wise reasoning, iterative\nretrieval, and adaptive retrieval strategies.\n6.2 Augmentation Source\nThe effectiveness of RAG models is heavily impacted by the\nselection of data sources for augmentation. Different levels of\nknowledge and dimensions require distinct processing tech-\nniques. They are categorized as unstructured data, structured\ndata, and content generated by LLMs. The technology tree\nof representative RAG research with different augmentation\naspects is depicted in Figure 5. The leaves, colored in three\ndifferent shades, represent enhancements using various types\nof data: unstructured data, structured data, and content gener-\nated by LLMs. The diagram clearly shows that initially, aug-\nmentation was mainly achieved through unstructured data,\nsuch as pure text. This approach later expanded to include\nthe use of structured data (e.g. knowledge graph) for further\nimprovement. More recently, there has been a growing trend\nin research that utilizes content generated by the LLMs them-\nselves for retrieval and augmentation purposes.\nAugmented with Unstructured Data\nUnstructured text, is gathered from corpora, such as prompt\ndata for fine-tuning large models [Cheng et al. , 2023a ]and\ncross-lingual data [Liet al. , 2023b ]. Retrieval units vary from\ntokens (e.g., kNN-LM [Khandelwal et al. , 2019 ]) to phrases\n(e.g., NPM, COG [Leeet al. , 2020, Lan et al. , 2022 ]) and\ndocument paragraphs, with finer granularities offering pre-\ncision at the cost of increased retrieval complexity.\nFLARE [Jiang et al. , 2023b ]introduces an active re-\ntrieval approach, triggered by the LM’s generation of low-\nprobability words. It creates a temporary sentence for doc-\nument retrieval, then regenerates the sentence with the re-\ntrieved context to predict subsequent sentences. RETRO uses\nthe previous chunk to retrieve the nearest neighbor at the\nchunk level, combined with the previous chunk’s context, it\nguides the generation of the next chunk. To preserve causal-\nity, the generation of the next block Cionly utilizes the near-\nest neighbor of the previous block N(Ci−1)and not N(Ci).\nAugmented with Structured Data\nStructured data, such as knowledge graphs (KGs), pro-\nvide high-quality context and mitigate model hallucina-\ntions. RET-LLMs [Modarressi et al. , 2023 ]constructs a\nknowledge graph memory from past dialogues for future ref-\nerence. SUGRE [Kang et al. , 2023 ]employs Graph Neu-\nral Networks (GNNs) to encode relevant KG subgraphs,\nensuring consistency between retrieved facts and gener-\nated text through multi-modal contrastive learning. Knowl-edGPT [Wang et al. , 2023d ]generates KB search queries and\nstores knowledge in a personalized base, enhancing the RAG\nmodel’s knowledge richness and contextuality.\nLLMs-Generated Content in RAG\nAddressing the limitations of external auxiliary information\nin RAG, some research has focused on exploiting LLMs’ in-\nternal knowledge. SKR [Wang et al. , 2023e ]classifies ques-\ntions as known or unknown, applying retrieval enhancement\nselectively. GenRead [Yuet al. , 2022 ]replaces the retriever\nwith an LLM generator, finding that LLM-generated con-\ntexts often contain more accurate answers due to better align-\nment with the pre-training objectives of causal language mod-\neling. Selfmem [Cheng et al. , 2023b ]iteratively creates an\nunbounded memory pool with a retrieval-enhanced genera-\ntor, using a memory selector to choose outputs that serve as\ndual problems to the original question, thus self-enhancing\nthe generative model.\nThese methodologies']","Structured data enhances RAG models by providing high-quality context and mitigating model hallucinations. It ensures consistency between retrieved facts and generated text through multi-modal contrastive learning. On the other hand, unstructured data, such as pure text, offers precision at the cost of increased retrieval complexity. LLM-generated content often contains more accurate answers due to better alignment with the pre-training objectives of causal language modeling. However, structured data provides a more reliable and consistent source of information for RAG models compared to unstructured data and LLM-generated content.",reasoning,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 13, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What is the term for applying theoretical knowledge in a practical work environment?,"['O\x00ce of International Services/Student Employment/O\x00-Campus Employment (Internships)\n/Curricular Practical Training (CPT)- InternshipsOf f-Campu s Employment (Internships)\nOVE RVIEW\nCURRICULAR\nPRACTICAL TR AINING\n(CPT) INTE RNSHIPS\nOPTIONAL PRACTICAL\nTR AINING (OPT)\nSTE M OPT\nACADEMIC TR AINING\n(AT)\nJ-2\xa0DEPENDENT\nEMPLOYMENT\nOUTS IDE US\nOTH ER VISA TY PES\nBACK TO STU DENT\nEMPLOYMENTCU RRICU LAR PR ACTI CAL TRAINING\n(CPT )- INT ERNSH IPS\nWHAT IS CURRICULAR PRACTICAL TRAINING?\nCPT is an academic learning experience that allows a student to apply\ntheoretical knowledge and skills gained through coursework in a\npractical work environment. CPT can be used during the fall, spring, or\nsummer semesters.\nCPT is de\x00ned as employment, which is an integral part of an\nestablished curriculum, including: “alternate work/study, internship,\ncooperative education, or any other type of required internship or\npracticum which is o\x00ered by sponsoring employers through\ncooperative agreements with the school.” Source: [8 CFR 214.2(f)(10)\n(i)].\xa0\nCPT is available only prior to the completion of your degree program\nand you must have a job o\x00er at the time of application. CPT\nemployment may not delay completion of the academic program.OFFICE OF INTERNATIONAL\nSERVICES\nUSF WORLDGIVE NOW\nABOUT USINCOMING\nSTUDENTSIMMIGRATIONSTUDENT\nEMPLOYMENT\nSCHOLARSEMPLOYEESMyUSFDirectory UNIVERSITY OF SOUTH FLORIDA']",Curricular Practical Training (CPT),reasoning,"[{'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 0, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}]",True
Is there a network for graduates to connect with alumni?,"[': ""What are the next steps after receiving my acceptance letter?""\n\nA01: ""Congratulations on your acceptance! The next steps include securing your student visa, arranging for housing, registering for classes, and attending the international student orientation. Detailed information will be provided in your acceptance package.""\n\nQ02: ""How do I find accommodation?""\n\nA02: ""Our institution offers on-campus housing options, including dormitories and apartments. Alternatively, you can opt for off-campus housing. Our student services office provides resources and assistance to help you find suitable accommodation.""\n\nOrientation and First Semester\n\nQ01: ""What should I expect during the orientation week?""\n\nA01: ""Orientation week includes campus tours, registration assistance, workshops on academic success, and social events to meet fellow students and faculty. It\'s a great opportunity to get acclimated to the campus and the community.""\n\nQ02: ""How can I register for courses?""\n\nA02: ""Course registration can be completed online through the student portal. If you need guidance on selecting courses relevant to your specialization, academic advisors are available to assist you.""\n\nContinuous Support\n\nQ01: ""Where can I get help if I\'m struggling with my coursework?""\n\nA01: ""We offer a range of support services, including tutoring, study groups, and academic advising. Don\'t hesitate to reach out for help; our goal is to ensure your success.""\n\n\n\nFinancial Information and Scholarships\n\nQ01: ""Are there scholarship opportunities for international students in the Master\'s program?""\n\nA01: ""Yes, our institution offers a range of scholarships for international students based on academic merit, financial need, and leadership qualities. We encourage you to apply early and visit our financial aid website for detailed information on eligibility and application procedures.""\n\nQ02: ""What is the estimated cost of attendance for the Master\'s program?""\n\nA02: ""The estimated cost of attendance includes tuition fees, accommodation, books and supplies, and living expenses. For the upcoming academic year, the total estimated cost is approximately $XX,XXX. Please note, this figure is subject to change and varies based on personal spending habits and accommodation choices.""\n\nVisa and Immigration\n\nQ01: ""What should I do if my student visa gets denied?""\n\nA01: ""In the event of a visa denial, it\'s important to understand the reason for the denial. You may reapply if you believe that your circumstances have changed or if you can provide additional information that was not presented in the initial application. Our international student office can provide guidance on the reapplication process.""\n\nQ02: ""Can I work while studying in the program?""\n\nA02: ""International students on a student visa are allowed to work on-campus for up to 20 hours per week during the academic term and full-time during breaks. Off-campus employment opportunities are subject to specific visa regulations and typically require authorization.""\n\nAcademic Life\n\nQ01: ""How can I get involved in research projects or internships during my studies?""\n\nA01: ""Our program encourages practical experience through research projects and internships. You can express your interest to faculty members, visit the career services office, or attend job fairs and networking events to explore opportunities.""\n\nQ02: ""What kind of support services are available for international students?""\n\nA02: ""We offer a wide range of support services including academic advising, career services, counseling, health services, and an international student office dedicated to assisting with visa issues, cultural adjustment, and other specific needs.""\n\nCampus Life and Community\n\nQ01: ""Are there any clubs or organizations I can join as an international student?""\n\n\n\nA01: ""Yes, our campus has a vibrant community with various clubs and organizations, including cultural associations, professional societies, and interest-based clubs. Joining these groups is a great way to meet people, develop new skills, and integrate into the campus community.""\n\nQ02: ""What resources are available to help me improve my English language skills?""\n\nA02: ""Our institution offers English language support services including ESL (English as a Second Language) courses, tutoring, writing workshops, and conversation practice sessions. These resources are designed to help non-native speakers enhance their academic and social communication skills.""\n\nAfter Graduation\n\nQ01: ""What are the career prospects after completing this Master\'s program?""\n\nA01: ""Graduates of our program have gone on to successful careers in data analysis, IT management, consulting, business intelligence, and more. Our career services office provides career counseling, resume workshops, interview preparation, and job placement assistance to support your professional development.""\n\nQ02: ""Is there an alumni network I can join after graduation?""\n\nA02: ""Absolutely. Our alumni network is a']","Absolutely. Our alumni network is a vibrant community of professionals who have graduated from our program. It offers opportunities for networking, mentorship, and career advancement. You can join the alumni network to stay connected with fellow graduates and benefit from their experiences and connections.",reasoning,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
What happens if course prerequisites in the BAIS program are not completed?,"[""Course Registration BAIS\nSearching for classes and current enrollment:\nYou can search on Oasis, but the staff schedule search  is an easier interface to use.\nVisit http://www .registrar .usf.edu/ssearch/staff/staff.php\n(https://usfweb.usf.edu/DSS/StaffScheduleSearch) (http://www.registrar.usf.edu/ssearch/staff/staff.php) Please\nmake sure that you read the description of the course carefully .  Some courses are only available to students\nwho are enrolled in specific programs, such as the Global BAIS or the Online MBA, and if you are not\nenrolled in these programs, you will not be eligible to register for these courses.\nIf you need to register for an alternate calendar course , you can use the alternate calendar link:\n https://www .usf.edu/registrar/register/altcalendar .aspx\n(https://www.usf.edu/registrar/register/altcalendar.aspx) (https://www.usf.edu/registrar/register/altcalendar.aspx)\n.  If this doesn’t work, email Dr . Reichgelt ( muma-msbais@usf.edu  (mailto:muma-msbais@usf.edu,) ) or\ncontact the Registrar ’s office at 974-2000.\n \nCourse sequencing & prerequisite checks:\nAs described in the catalog  (https://catalog.usf.edu/preview_program.php?\ncatoid=18&poid=7726&hl=%22BAIS%22&returnto=searchhttps://catalog.usf.edu/preview_program.php?\ncatoid=18&poid=7726&hl=%22BAIS%22&returnto=search) , certain classes have course prerequisites (e.g.,\nISM 6124 Advanced Systems Analysis and Design and ISM 6218 Advanced Database Systems  are both\nprerequisites for ISM 6155 Enterprise Information Systems Management ).  In general, you cannot directly\nregister for the advanced classes without completing the prerequisites in a prior semester . Note that\nconcurrent enrollment in prerequisite and advanced classes is not allowed.  \nIn addition, certain core MS-BAIS classes like Advanced Database Management have pre-program\nprerequisites such as a database prerequisite, which can be met by virtue of a prior course in database\nmanagement from your previous university or adequate working experience with databases in a corporate\nenvironment. Similarly , there are prerequisites for Advanced Systems Analysis & Design and Distributed\nInformation Systems. If you don't meet these core prerequisites, you will have to register for basic courses in\nthese areas at USF and these courses will NOT  count toward the 33-credit MS-BAIS degree requirement. If\nyou are unsure which prerequisites you need, email Dr . Reichgelt ( muma-msbais@usf.edu  (mailto:muma-\nmsbais@usf.edu,) ) with your U# and USF email address and request a prerequisite check.  Every new\nstudent must have their prerequisites checked and any outstanding prerequisites should be completed by\nthe end of your first semester .\nThe following are the required pre-program prerequisites:\nDatabase prerequisite  >> prerequisite for >> ISM 6218 Advanced Database Management.\nSystems analysis & design prerequisite  >> prerequisite for >>  ISM 6124 Advanced Systems Analysis &\nDesign \nOOP  prerequisite  >> prerequisite for  >> ISM 6225 Distributed Information Systems \nStats prerequisite  >> prerequisite for > QMB 6304 Analytical Methods for Business""]","If course prerequisites in the BAIS program are not completed, students will have to register for basic courses in those areas at USF, and those courses will not count toward the 33-credit MS-BAIS degree requirement.",reasoning,"[{'source': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How does the program keep students updated on industry trends and technologies in business analytics and information systems?,"[': ""What are the next steps after receiving my acceptance letter?""\n\nA01: ""Congratulations on your acceptance! The next steps include securing your student visa, arranging for housing, registering for classes, and attending the international student orientation. Detailed information will be provided in your acceptance package.""\n\nQ02: ""How do I find accommodation?""\n\nA02: ""Our institution offers on-campus housing options, including dormitories and apartments. Alternatively, you can opt for off-campus housing. Our student services office provides resources and assistance to help you find suitable accommodation.""\n\nOrientation and First Semester\n\nQ01: ""What should I expect during the orientation week?""\n\nA01: ""Orientation week includes campus tours, registration assistance, workshops on academic success, and social events to meet fellow students and faculty. It\'s a great opportunity to get acclimated to the campus and the community.""\n\nQ02: ""How can I register for courses?""\n\nA02: ""Course registration can be completed online through the student portal. If you need guidance on selecting courses relevant to your specialization, academic advisors are available to assist you.""\n\nContinuous Support\n\nQ01: ""Where can I get help if I\'m struggling with my coursework?""\n\nA01: ""We offer a range of support services, including tutoring, study groups, and academic advising. Don\'t hesitate to reach out for help; our goal is to ensure your success.""\n\n\n\nFinancial Information and Scholarships\n\nQ01: ""Are there scholarship opportunities for international students in the Master\'s program?""\n\nA01: ""Yes, our institution offers a range of scholarships for international students based on academic merit, financial need, and leadership qualities. We encourage you to apply early and visit our financial aid website for detailed information on eligibility and application procedures.""\n\nQ02: ""What is the estimated cost of attendance for the Master\'s program?""\n\nA02: ""The estimated cost of attendance includes tuition fees, accommodation, books and supplies, and living expenses. For the upcoming academic year, the total estimated cost is approximately $XX,XXX. Please note, this figure is subject to change and varies based on personal spending habits and accommodation choices.""\n\nVisa and Immigration\n\nQ01: ""What should I do if my student visa gets denied?""\n\nA01: ""In the event of a visa denial, it\'s important to understand the reason for the denial. You may reapply if you believe that your circumstances have changed or if you can provide additional information that was not presented in the initial application. Our international student office can provide guidance on the reapplication process.""\n\nQ02: ""Can I work while studying in the program?""\n\nA02: ""International students on a student visa are allowed to work on-campus for up to 20 hours per week during the academic term and full-time during breaks. Off-campus employment opportunities are subject to specific visa regulations and typically require authorization.""\n\nAcademic Life\n\nQ01: ""How can I get involved in research projects or internships during my studies?""\n\nA01: ""Our program encourages practical experience through research projects and internships. You can express your interest to faculty members, visit the career services office, or attend job fairs and networking events to explore opportunities.""\n\nQ02: ""What kind of support services are available for international students?""\n\nA02: ""We offer a wide range of support services including academic advising, career services, counseling, health services, and an international student office dedicated to assisting with visa issues, cultural adjustment, and other specific needs.""\n\nCampus Life and Community\n\nQ01: ""Are there any clubs or organizations I can join as an international student?""\n\n\n\nA01: ""Yes, our campus has a vibrant community with various clubs and organizations, including cultural associations, professional societies, and interest-based clubs. Joining these groups is a great way to meet people, develop new skills, and integrate into the campus community.""\n\nQ02: ""What resources are available to help me improve my English language skills?""\n\nA02: ""Our institution offers English language support services including ESL (English as a Second Language) courses, tutoring, writing workshops, and conversation practice sessions. These resources are designed to help non-native speakers enhance their academic and social communication skills.""\n\nAfter Graduation\n\nQ01: ""What are the career prospects after completing this Master\'s program?""\n\nA01: ""Graduates of our program have gone on to successful careers in data analysis, IT management, consulting, business intelligence, and more. Our career services office provides career counseling, resume workshops, interview preparation, and job placement assistance to support your professional development.""\n\nQ02: ""Is there an alumni network I can join after graduation?""\n\nA02: ""Absolutely. Our alumni network is a', ' global community that provides a platform for networking, mentorship, and professional growth. As a graduate, you\'ll have access to alumni events, webinars, and other resources to stay connected with your peers and the institution.""\n\nTechnical Requirements and Resources\n\nQ01: ""What are the computing requirements for the program?""\n\nA01: ""Our program requires students to have a laptop with specific hardware configurations to handle data analytics and business intelligence software efficiently. Recommended specifications include a modern multi-core processor, at least 16GB of RAM, and a solid-state drive (SSD). Detailed requirements are available on our program\'s website.""\n\nQ02: ""Are there any software licenses provided for students in this program?""\n\nA02: ""Yes, enrolled students receive access to various professional software tools and platforms necessary for coursework, including statistical analysis, data visualization, and business intelligence software, at no additional cost. This is part of our commitment to ensure students have the necessary resources for their studies.""\n\nAdjusting to a New Environment\n\nQ01: ""How does the university assist international students in adjusting to life in a new country?""\n\n\n\nA01: ""Our international student office offers a range of services designed to help you adjust, including cultural orientation sessions, social events, and workshops on local customs and lifestyle. We also have student mentors who can provide guidance and support as you navigate your new surroundings.""\n\nQ02: ""What kind of health services are available on campus?""\n\nA02: ""Our campus health center provides a range of medical services, including general consultations, mental health support, and emergency care. We also offer health insurance plans suitable for international students, ensuring you have access to comprehensive healthcare during your stay.""\n\nProgram Structure and Content\n\nQ01: ""Can students customize their curriculum within the Master\'s program?""\n\nA01: ""Absolutely. While there are core courses that all students must complete, our program offers elective courses allowing you to tailor your studies to your interests and career goals. Additionally, students can engage in independent study projects or research under faculty supervision for a more customized academic experience.""\n\nQ02: ""Is there an opportunity to study abroad or participate in international projects?""\n\nA02: ""Yes, our program includes opportunities for international study and collaboration through exchange programs, global consulting projects, and internships. These experiences are designed to enhance your global perspective and understanding of international business practices.""\n\nNetworking and Professional Development\n\nQ01: ""How does the program facilitate networking opportunities with industry professionals?""\n\nA01: ""Our program hosts regular networking events, guest lectures, and industry panels featuring alumni and professionals from the fields of business analytics and information systems. These events are excellent opportunities to build connections, gain insights into industry trends, and explore potential career paths.""\n\nQ02: ""Does the university offer career fairs or recruitment events for business analytics students?""\n\nA02: ""Yes, we organize career fairs and recruitment events specifically tailored to business analytics and information systems students. These events attract top employers in the industry looking to hire for internships and full-time positions. We also provide support in preparing for these events, including resume reviews and interview coaching.""\n\nSupport Systems\n\nQ01: ""What kind of academic support is available for students who may struggle with advanced coursework?""\n\n\n\nA01: ""We provide a comprehensive academic support system that includes tutoring services, study groups, and workshops on advanced topics in business analytics and information systems. Faculty members are also available for office hours to provide additional assistance and guidance.""\n\nQ02: ""Are there any mentorship programs available for new students?""\n\nA02: ""Yes, we offer a mentorship program that pairs new students with upperclassmen or alumni who can provide guidance, share their experiences, and offer advice on navigating both the academic and social aspects of the program. This program is designed to help new students transition smoothly into their graduate studies.""\n\nCertainly, Dr. Smith. Further expanding the range of inquiries, the following set of questions and answers delves into more specific and practical aspects that students might consider when applying for and participating in a Master of Business Analytics and Information Systems program.\n\nPractical Experience and Application\n\nQ01: ""Are there opportunities for practical experience within the program?""\n\nA01: ""Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience.""\n\nQ02: ""How does the program incorporate the latest industry trends and technologies?""\n\nA02: ""Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on']","Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on emerging trends and technologies. Additionally, our faculty members are actively engaged in research and industry projects, bringing their expertise and insights into the classroom.",reasoning,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}, {'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
What prerequisites are there for ISM 6137 Statistical Data Mining for the MS-BAIS degree?,"['In addition, we strongly suggest that you take courses in a specific sequence.  Past experience has shown\nthat students who have not taken the courses in the suggested sequence are less successful.\nTake ISM 6124 Advanced Systems Analysis & Design  before you take ISM 6208 Data W arehousing . \nTake ISM 6225 Distributed Information Systems  before you take  ISM 6562 Big Data for Business\nApplications. \nTake QMB 6304 Analytical Methods for Business  before you take  ISM 6137 Statistical Data Mining . \nTake ISM 6136 Data Mining  before you take  ISM 6251 Data Science Programming  before you take ISM\n6564 T ext Analytics or ISM 6930 T echnical Foundations of AI\nNOTE 1: We have been a bit lax in enforcing prerequisites.  Starting in the Fall of 2023, we will strictly\nenforce prerequisites and remove students from courses if they have not met the prerequisites.\nNOTE 2 : With the increase in enrollment in the program, we cannot guarantee that we can of fer the core\ncourses (see next page) in every semester .  You should therefore take a core course whenever it is available\nand you are eligible to take it.  If you do not, you may not be able to graduate on time.\n \nElectives:\nWe have a wide range of departmental and non-departmental electives for you to choose from to enrich your\nlearning experience at USF . Note that you must complete 9 credits of departmental (BAIS) electives and\nanother 9 credits of BAIS and/or non-BAIS electives for your MS-BAIS degree. Non-departmental electives\nmust be pre-approved by Dr . Reichgelt before you register in those courses, and may require a permit from\nthe corresponding department. Departmental electives must satisfy prerequisites as described above.\nAny USF class may not count as ""electives"" for your 33-credit MS-BAIS degree. Classes that won\'t count\ninclude any undergraduate class, most 2 or 3-credit MBA  courses such as  ISM 6930 (Data Analytics for\nBusiness), QMB 6305, QMB 6358, QMB 6603, ISM 6021, ISM 6123, ISM 6436, ISM 6217, ISM 6565 and\nmany other Muma College of Business classes.\nAny classes out of our program MUST  be pre-approved by the SISM department before you can register for\nit and expect it to count toward your degree requirement. Contact Dr . Reichgelt ( muma-msbais@usf.edu\n(mailto:muma-msbais@usf.edu) ) for assistance with selecting electives to determine whether they will count\ntoward your degree.  The following non-BAIS course have already been pre-approved:\nEEL 6787: Data Networks, Systems and Security\n \nFIN 6406 Financial Management\nFIN 6246 The Financial System and FinT ech Innovation\nFIN 6416 Advanced Financial Management\nFIN 6455 Financial Modeling and Analytics\nFIN 6465 Financial Statement Analysis\nFIN 6515 Quantitative Investments\nFIN 6605 International Financial Management\nFIN 6778 Quantitative Analytics for Finance\nFIN 6779 FinT ech and Payment Technologies\n ']",nan,reasoning,"[{'source': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What employment services does the Office of International Services provide for international students?,"['O\x00ce of International Services/Student Employment/Hiring An International StudentStudent Employment\nOVERVIEW\nON-CAMPUS\nEMPLOYMENT\nOFF-CAMPUS\nEMPLOYMENT\nWORK AFTER\nGRADUATION\nSOCIAL SECURITY\nSEVERE ECONOMIC\nHARDSHIP\nSPECIAL STUDENT\nRELIEF (SSR)\nVOLUNTEERING\nHIRING AN\nINTERNATIONAL\nSTUDENTHIRING AN INTERNATIONAL STUDENT\nHIRING A USF INTERNATIONAL STUDENT TO\nWORK FOR\xa0USF\nBefore Graduation\nInternational students, with F-1 and J-1 visas, who are full-time\nenrolled are allowed to accept on campus employment for 20 hours\nper week during the regular semester. They can be employed on-\ncampus 40 hours per week during o\x00cial breaks, such as the winter\nbreak and summer.\nAfter Graduation\nUpon the date of graduation, F-1 and J-1 students may no longer work\nanywhere without special authorization. F-1 students must have a\nvalid Employment Authorization Document (EAD Card) and J-1\nstudents must have work authorization noted on page 1 of their DS-\n2019 to be eligible to work anywhere.\xa0\nHIRING AN INTERNATIONAL STUDENT FOR A JOB\nOUTSIDE\xa0USFOFFICE OF INTERNATIONAL\nSERVICES\nUSF WORLDGIVE NOW\nABOUT USINCOMING\nSTUDENTSIMMIGRATIONSTUDENT\nEMPLOYMENT\nSCHOLARSEMPLOYEESMyUSFDirectory UNIVERSITY OF SOUTH FLORIDA']","The Office of International Services provides employment services for international students, including on-campus employment during the regular semester and official breaks. After graduation, students must have special authorization, such as a valid Employment Authorization Document (EAD Card) or work authorization noted on their DS-2019, to work anywhere.",reasoning,"[{'source': 'data/pdfs/International Services _ Hiring An International Student.pdf', 'page': 0, 'filename': 'data/pdfs/International Services _ Hiring An International Student.pdf'}]",True
What are the minimum credit hour requirements for CPT?,"['There is no mechanism for expedited processing. If the student\nsubmits the CPT request with not enough time to be processed, the\nCPT start date will be changed to the date the CPT application is\napproved.\nCPT AND FULL-TIME ENROLLMENT\nREQUIREMENTS\nUndergraduate students must be enrolled for at least 12 credit hours\nin a semester. Graduate students must be enrolled for at least 9 credit\nhours. In addition, graduate students need to be enrolled at least 2\ncredit hours during their \x00nal semester (summer included).\nIf you are doing a full-time CPT.\xa0\nIf full-time CPT lasts 12 weeks or more during a Fall or Spring\nSemester, the student may* be eligible to enroll in less than a full\ncourse load.\nIf full-time CPT lasts less than 12 weeks of a Fall or Spring\nSemester, the student is required to be enrolled in a full-time\ncourse load** (including the CPT course)\nDuring summer, students can enroll for the CPT-related course\nonly. No additional registration is required for immigration\npurposes.\xa0\nPart-time CPT:\xa0\nStudents authorized for part-time CPT during a Fall or Spring\nSemester must be enrolled in full-time course load** (including\nthe CPT course) no matter the duration of the CPT experience\nDuring summer, students can enroll for the CPT-related course\nonly. No additional registration is required for immigration\npurposes.\n*Approval of full-time CPT that will last 12 weeks or more does NOT\nautomatically authorize a student to drop below full-time. This will be']","Undergraduate students must be enrolled for at least 12 credit hours in a semester. Graduate students must be enrolled for at least 9 credit hours. In addition, graduate students need to be enrolled at least 2 credit hours during their final semester (summer included).",reasoning,"[{'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 5, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}]",True
Which multimodal model excels in small-scale learning tasks and integrates RAG concepts with code?,"['certain. Initial studies [Wang et al. , 2023b ]have begun to ad-\ndress this, yet the parameter count in RAG models still lags\nbehind that of LLMs. The possibility of an Inverse Scaling\nLaw9, where smaller models outperform larger ones, is par-\nticularly intriguing and merits further investigation.\nProduction-Ready RAG . RAG’s practicality and alignment\nwith engineering requirements have facilitated its adoption.\nHowever, enhancing retrieval efficiency, improving document\nrecall in large knowledge bases, and ensuring data secu-\nrity—such as preventing inadvertent disclosure of document\nsources or metadata by LLMs—are critical engineering chal-\nlenges that remain to be addressed [Alon et al. , 2022 ].\nModality Extension of RAG\nRAG has transcended its initial text-based question-\nanswering confines, embracing a diverse array of modal data.\nThis expansion has spawned innovative multimodal models\nthat integrate RAG concepts across various domains:\nImage . RA-CM3 [Yasunaga et al. , 2022 ]stands as a pio-\nneering multimodal model of both retrieving and generating\ntext and images. BLIP-2 [Liet al. , 2023a ]leverages frozen\nimage encoders alongside LLMs for efficient visual language\npre-training, enabling zero-shot image-to-text conversions.\nThe “Visualize Before You Write” method [Zhuet al. , 2022 ]\nemploys image generation to steer the LM’s text generation,\nshowing promise in open-ended text generation tasks.\nAudio and Video . The GSS method retrieves and stitches\ntogether audio clips to convert machine-translated data into\nspeech-translated data [Zhao et al. , 2022 ]. UEOP marks\na significant advancement in end-to-end automatic speech\nrecognition by incorporating external, offline strategies for\nvoice-to-text conversion [Chan et al. , 2023 ]. Additionally,\nKNN-based attention fusion leverages audio embeddings and\nsemantically related text embeddings to refine ASR, thereby\naccelerating domain adaptation. Vid2Seq augments language\nmodels with specialized temporal markers, facilitating the\nprediction of event boundaries and textual descriptions within\na unified output sequence [Yang et al. , 2023a ].\nCode . RBPS [Nashid et al. , 2023 ]excels in small-scale\nlearning tasks by retrieving code examples that align with de-\nvelopers’ objectives through encoding and frequency analy-\nsis. This approach has demonstrated efficacy in tasks such as\ntest assertion generation and program repair. For structured\nknowledge, the CoK method [Liet al. , 2023c ]first extracts\nfacts pertinent to the input query from a knowledge graph,\nthen integrates these facts as hints within the input, enhancing\nperformance in knowledge graph question-answering tasks.\n8.2 Ecosystem of RAG\nDownstream Tasks and Evaluation\nRAG has shown considerable promise in enriching language\nmodels with the capacity to handle intricate queries and pro-\nduce detailed responses by leveraging extensive knowledge\nbases. Empirical evidence suggests that RAG excels in a\nvariety of downstream tasks, including open-ended question\nanswering and fact verification. The integration of RAG not\nonly bolsters the precision and relevance of responses but also\ntheir diversity and depth.\n9https://github.com/inverse-scaling/prizeThe scalability and versatility of RAG across multiple do-\nmains warrant further investigation, particularly in special-\nized fields such as medicine, law, and education. In these ar-\neas, RAG could potentially reduce training costs and enhance\nperformance compared to traditional fine-tuning approaches\nin professional domain knowledge question answering.\nConcurrently, refining the evaluation framework for RAG\nis essential to maximize its efficacy and utility across different\ntasks. This entails the development of nuanced metrics and\nassessment tools that can gauge aspects such as contextual\nrelevance, creativity of content, and non-maleficence.\nFurthermore, improving the interpretability of RAG-driven\nmodels continues to be a key goal. Doing so would allow\nusers to understand the reasoning behind the responses gener-\nated by the model, thereby promoting trust and transparency\nin the use of RAG applications.\nTechnical Stack\nThe development of the RAG ecosystem is greatly impacted\nby the progression of its technical stack. Key tools like\nLangChain and LLamaIndex have quickly gained popularity\nwith the emergence of ChatGPT, providing extensive RAG-\nrelated APIs and becoming essential in the realm of LLMs.\nEmerging technical stacks, while not as feature-rich']",RBPS,reasoning,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 19, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the three types of CPT experiences at USF?,"['TYPES OF CPT\nWhen you apply for CPT, you must select a type. USF has three types\nof CPT:\nNECESSARY FOR COURSE – Work experience ful\x00lls a requirement of\na course as speci\x00ed by the o\x00cial course description available to the\npublic in a university catalog or website department course listings.\nThe work experience must be directly related to the major/program\nlisted on the \x00rst page of the student’s I-20 and commensurate with\nthe current educational level.\nUSF CENTER FOR CAREER & PROFESSIONAL DEVELOPMENT CO-OP\nOR INTERNSHIP (For Undergraduate Students Only) – The work\nexperience is assigned and monitored by USF’s Career Services. \xa0The\nwork experience must be directly related to the program (major) and\ncommensurate with the current educational level.\nDISSERTATION AND THESIS – The work experience must be\nnecessary and contribute to the production of the \x00nal thesis or\ndissertation. \xa0The student must be in candidacy and enrolled in\ndissertation hours OR already in thesis track and enrolled in thesis\nhours. \xa0\nPlease watch the video below to learn more about the CPT options at\nUSF.\xa0How t o Apply for CPT How t o Apply for CPT']","NECESSARY FOR COURSE, USF CENTER FOR CAREER & PROFESSIONAL DEVELOPMENT CO-OP OR INTERNSHIP, DISSERTATION AND THESIS",reasoning,"[{'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 3, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}]",True
What are the benefits of a two-step retrieval method in the RAG process and how does it balance efficiency and contextually rich responses?,"[' of the process. This two-step re-\ntrieval method helps to strike a balance between efficiency\nand the delivery of contextually rich responses.\nStepBack-prompt approach encourages the LLM to move\naway from specific instances and engage in reasoning around\nbroader concepts and principles [Zheng et al. , 2023 ]. Experi-\nmental results demonstrate a significant performance increase\nin various challenging, inference-based tasks when backward\nprompts are used, highlighting their natural adaptability to the\nRAG process. These retrieval-enhancing steps can be applied\nboth in generating responses to backward prompts and in the\nfinal question-answering process.\nSub-Queries . Depending on the scenario, various query\nstrategies can be employed, such as using query engines\nprovided by frameworks like LlamaIndex, leveraging tree\nqueries, utilizing vector queries, or executing simple sequen-\ntial querying of chunks.\nHypothetical Document Embeddings . HyDE operates on\nthe belief that the answers generated might be closer in the\nembedding space than a direct query. Using the LLM, HyDE\ncreates a hypothetical document (answer) in response to a\nquery, embeds this document, and uses the resulting em-\nbedding to retrieve real documents similar to the hypotheti-\ncal one. Instead of seeking embedding similarity based on\nthe query, this approach focuses on the embedding similar-\nity from one answer to another [Gao et al. , 2022 ]. However,\nit might not consistently produce desirable outcomes, espe-\ncially when the language model is unfamiliar with the subject\nmatter, potentially leading to more instances with errors.\n4 Retrieval\nIn the context of RAG, it is crucial to efficiently retrieve rel-\nevant documents from the data source. However, creating a\nproficient retriever presents significant challenges. This sec-\ntionelves into three fundamental questions: 1) How can we\nachieve accurate semantic representations? 2) What methods']","The two-step retrieval method in the RAG process helps to strike a balance between efficiency and the delivery of contextually rich responses. It achieves this by using a StepBack-prompt approach that encourages the language model to reason around broader concepts and principles. This approach enhances performance in challenging, inference-based tasks. Additionally, the retrieval-enhancing steps can be applied both in generating responses to backward prompts and in the final question-answering process. Overall, the two-step retrieval method improves efficiency while still providing contextually rich responses.",reasoning,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 6, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
"What challenges does Naive RAG face in achieving high generation quality in RAG systems, and how does Advanced RAG address them?","['and post-retrieval strategies. To address the indexing chal-\nlenges experienced by Naive RAG, Advanced RAG has re-\nfined its indexing approach using techniques such as slid-\ning window, fine-grained segmentation, and metadata. It has\nalso introduced various methods to optimize the retrieval pro-\ncess [ILIN, 2023 ].\nPre-Retrieval Process\nOptimizing Data Indexing .The goal of optimizing data index-\ning is to enhance the quality of the content being indexed.\nThis involves five primary strategies: enhancing data gran-\nularity, optimizing index structures, adding metadata, align-\nment optimization, and mixed retrieval.\nEnhancing data granularity aims to elevate text standard-\nization, consistency, factual accuracy, and rich context to im-\nprove the RAG system’s performance. This includes remov-\ning irrelevant information, dispelling ambiguity in entities\nand terms, confirming factual accuracy, maintaining context,\nand updating outdated documents.\nOptimizing index structures involves adjusting the size of\nchunks to capture relevant context, querying across multiple\nindex paths, and incorporating information from the graph\nstructure to capture relevant context by leveraging relation-\nships between nodes in a graph data index.\nAdding metadata information involves integrating refer-\nenced metadata, such as dates and purposes, into chunks for\nfiltering purposes, and incorporating metadata like chapters\nand subsections of references to improve retrieval efficiency.\nAlignment optimization addresses alignment issues and\ndisparities between documents by introducing “hypothetical\nquestions” [Liet al. , 2023d ]into documents to rectify align-\nment issues and differences.\nRetrieval\nDuring the retrieval stage, the primary focus is on identifying\nthe appropriate context by calculating the similarity between\nthe query and chunks. The embedding model is central to\nthis process. In the advanced RAG, there is potential for op-\ntimization of the embedding models.\nFine-tuning Embedding . Fine-tuning embedding models\nsignificantly impact the relevance of retrieved content in RAG\nsystems. This process involves customizing embedding mod-\nels to enhance retrieval relevance in domain-specific contexts,\nespecially for professional domains dealing with evolving or\nrare terms. The BGE embedding model [BAAI, 2023 ], such\nas BGE-large-EN developed by BAAI2, is an example of a\nhigh-performance embedding model that can be fine-tuned\nto optimize retrieval relevance. Training data for fine-tuning\ncan be generated using language models like GPT-3.5-turbo\nto formulate questions grounded on document chunks, which\nare then used as fine-tuning pairs.\nDynamic Embedding adapts to the context in which words\nare used, unlike static embedding, which uses a single vec-\ntor for each word [Karpukhin et al. , 2020 ]. For example,\nin transformer models like BERT, the same word can have\nvaried embeddings depending on surrounding words. Ope-\nnAI’s embeddings-ada-02 model3, built upon the principles\n2https://huggingface.co/BAAI/bge-large-en\n3https://platform.openai.com/docs/guides/embeddingsof LLMs like GPT, is a sophisticated dynamic embedding\nmodel that captures contextual understanding. However, it\nmay not exhibit the same sensitivity to context as the latest\nfull-size language models like GPT-4.\nPost-Retrieval Process\nAfter retrieving valuable context from the database, it is es-\nsential to merge it with the query as an input into LLMs while\naddressing challenges posed by context window limits. Sim-\nply presenting all relevant documents to the LLM at once may\nexceed the context window limit, introduce noise, and hinder\nthe focus on crucial information. Additional processing of the\nretrieved content is necessary to address these issues.\nRe-Ranking . Re-ranking the retrieved information to re-\nlocate the most relevant content to the edges of the prompt\nis a key strategy. This concept has been implemented\nin frameworks such as LlamaIndex4, LangChain5, and\nHayStack [Blagojevi, 2023 ]. For example, Diversity Ranker6\nprioritizes reordering based on document diversity, while\nLostInTheMiddleRanker alternates placing the best docu-\nment at the beginning and end of the context window. Ad-\nditionally, approaches like cohereAI rerank [Cohere, 2023 ],\nbge-rerank7, and LongLLMLingua [Jiang et al. , 20', 'Figure 2: A representative instance of the RAG process applied to question answering\nthe input into a vector representation. It then proceeds to\ncompute the similarity scores between the query vector and\nthe vectorized chunks within the indexed corpus. The system\nprioritizes and retrieves the top K chunks that demonstrate\nthe greatest similarity to the query. These chunks are subse-\nquently used as the expanded contextual basis for addressing\nthe user’s request.\nGeneration\nThe posed query and selected documents are synthesized into\na coherent prompt to which a large language model is tasked\nwith formulating a response. The model’s approach to an-\nswering may vary depending on task-specific criteria, allow-\ning it to either draw upon its inherent parametric knowledge\nor restrict its responses to the information contained within\nthe provided documents. In cases of ongoing dialogues,\nany existing conversational history can be integrated into the\nprompt, enabling the model to engage in multi-turn dialogue\ninteractions effectively.\nDrawbacks in Naive RAG\nNaive RAG faces significant challenges in three key areas:\n“Retrieval,” “Generation,” and “Augmentation”.\nRetrieval quality poses diverse challenges, including low\nprecision, leading to misaligned retrieved chunks and po-\ntential issues like hallucination or mid-air drop. Low recall\nalso occurs, resulting in the failure to retrieve all relevant\nchunks, thereby hindering the LLMs’ ability to craft compre-hensive responses. Outdated information further compounds\nthe problem, potentially yielding inaccurate retrieval results.\nResponse generation quality presents hallucination chal-\nlenge, where the model generates answers not grounded in\nthe provided context, as well as issues of irrelevant context\nand potential toxicity or bias in the model’s output.\nThe augmentation process presents its own challenges in\neffectively integrating context from retrieved passages with\nthe current generation task, potentially leading to disjointed\nor incoherent output. Redundancy and repetition are also\nconcerns, especially when multiple retrieved passages con-\ntain similar information, resulting in repetitive content in the\ngenerated response.\nDiscerning the importance and relevance of multiple re-\ntrieved passages to the generation task is another challenge,\nrequiring the proper balance of each passage’s value. Addi-\ntionally, reconciling differences in writing styles and tones to\nensure consistency in the output is crucial.\nLastly, there’s a risk of generation models overly depend-\ning on augmented information, potentially resulting in out-\nputs that merely reiterate the retrieved content without pro-\nviding new value or synthesized information.\n3.2 Advanced RAG\nAdvanced RAG has been developed with targeted enhance-\nments to address the shortcomings of Naive RAG. In terms\nof retrieval quality, Advanced RAG implements pre-retrieval']","Naive RAG faces challenges in achieving high generation quality in RAG systems, including hallucination, irrelevant context, potential toxicity or bias in output, and disjointed or incoherent output. Advanced RAG addresses these challenges by implementing targeted enhancements such as re-ranking the retrieved information, integrating context effectively, balancing the value of multiple retrieved passages, ensuring consistency in output, and avoiding over-dependence on augmented information.",reasoning,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 4, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 3, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What is the course load for a student in a short full-time CPT during Fall or Spring Semester?,"['There is no mechanism for expedited processing. If the student\nsubmits the CPT request with not enough time to be processed, the\nCPT start date will be changed to the date the CPT application is\napproved.\nCPT AND FULL-TIME ENROLLMENT\nREQUIREMENTS\nUndergraduate students must be enrolled for at least 12 credit hours\nin a semester. Graduate students must be enrolled for at least 9 credit\nhours. In addition, graduate students need to be enrolled at least 2\ncredit hours during their \x00nal semester (summer included).\nIf you are doing a full-time CPT.\xa0\nIf full-time CPT lasts 12 weeks or more during a Fall or Spring\nSemester, the student may* be eligible to enroll in less than a full\ncourse load.\nIf full-time CPT lasts less than 12 weeks of a Fall or Spring\nSemester, the student is required to be enrolled in a full-time\ncourse load** (including the CPT course)\nDuring summer, students can enroll for the CPT-related course\nonly. No additional registration is required for immigration\npurposes.\xa0\nPart-time CPT:\xa0\nStudents authorized for part-time CPT during a Fall or Spring\nSemester must be enrolled in full-time course load** (including\nthe CPT course) no matter the duration of the CPT experience\nDuring summer, students can enroll for the CPT-related course\nonly. No additional registration is required for immigration\npurposes.\n*Approval of full-time CPT that will last 12 weeks or more does NOT\nautomatically authorize a student to drop below full-time. This will be']",The student is required to be enrolled in a full-time course load (including the CPT course) for a short full-time CPT during Fall or Spring Semester.,reasoning,"[{'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 5, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}]",True
What are the prerequisites for ISM 6137 Statistical Data Mining for the MS-BAIS degree?,"['In addition, we strongly suggest that you take courses in a specific sequence.  Past experience has shown\nthat students who have not taken the courses in the suggested sequence are less successful.\nTake ISM 6124 Advanced Systems Analysis & Design  before you take ISM 6208 Data W arehousing . \nTake ISM 6225 Distributed Information Systems  before you take  ISM 6562 Big Data for Business\nApplications. \nTake QMB 6304 Analytical Methods for Business  before you take  ISM 6137 Statistical Data Mining . \nTake ISM 6136 Data Mining  before you take  ISM 6251 Data Science Programming  before you take ISM\n6564 T ext Analytics or ISM 6930 T echnical Foundations of AI\nNOTE 1: We have been a bit lax in enforcing prerequisites.  Starting in the Fall of 2023, we will strictly\nenforce prerequisites and remove students from courses if they have not met the prerequisites.\nNOTE 2 : With the increase in enrollment in the program, we cannot guarantee that we can of fer the core\ncourses (see next page) in every semester .  You should therefore take a core course whenever it is available\nand you are eligible to take it.  If you do not, you may not be able to graduate on time.\n \nElectives:\nWe have a wide range of departmental and non-departmental electives for you to choose from to enrich your\nlearning experience at USF . Note that you must complete 9 credits of departmental (BAIS) electives and\nanother 9 credits of BAIS and/or non-BAIS electives for your MS-BAIS degree. Non-departmental electives\nmust be pre-approved by Dr . Reichgelt before you register in those courses, and may require a permit from\nthe corresponding department. Departmental electives must satisfy prerequisites as described above.\nAny USF class may not count as ""electives"" for your 33-credit MS-BAIS degree. Classes that won\'t count\ninclude any undergraduate class, most 2 or 3-credit MBA  courses such as  ISM 6930 (Data Analytics for\nBusiness), QMB 6305, QMB 6358, QMB 6603, ISM 6021, ISM 6123, ISM 6436, ISM 6217, ISM 6565 and\nmany other Muma College of Business classes.\nAny classes out of our program MUST  be pre-approved by the SISM department before you can register for\nit and expect it to count toward your degree requirement. Contact Dr . Reichgelt ( muma-msbais@usf.edu\n(mailto:muma-msbais@usf.edu) ) for assistance with selecting electives to determine whether they will count\ntoward your degree.  The following non-BAIS course have already been pre-approved:\nEEL 6787: Data Networks, Systems and Security\n \nFIN 6406 Financial Management\nFIN 6246 The Financial System and FinT ech Innovation\nFIN 6416 Advanced Financial Management\nFIN 6455 Financial Modeling and Analytics\nFIN 6465 Financial Statement Analysis\nFIN 6515 Quantitative Investments\nFIN 6605 International Financial Management\nFIN 6778 Quantitative Analytics for Finance\nFIN 6779 FinT ech and Payment Technologies\n ']",The prerequisites for ISM 6137 Statistical Data Mining for the MS-BAIS degree are QMB 6304 Analytical Methods for Business.,reasoning,"[{'source': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How does the Master's program provide practical experience and incorporate industry trends and technologies?,"[' global community that provides a platform for networking, mentorship, and professional growth. As a graduate, you\'ll have access to alumni events, webinars, and other resources to stay connected with your peers and the institution.""\n\nTechnical Requirements and Resources\n\nQ01: ""What are the computing requirements for the program?""\n\nA01: ""Our program requires students to have a laptop with specific hardware configurations to handle data analytics and business intelligence software efficiently. Recommended specifications include a modern multi-core processor, at least 16GB of RAM, and a solid-state drive (SSD). Detailed requirements are available on our program\'s website.""\n\nQ02: ""Are there any software licenses provided for students in this program?""\n\nA02: ""Yes, enrolled students receive access to various professional software tools and platforms necessary for coursework, including statistical analysis, data visualization, and business intelligence software, at no additional cost. This is part of our commitment to ensure students have the necessary resources for their studies.""\n\nAdjusting to a New Environment\n\nQ01: ""How does the university assist international students in adjusting to life in a new country?""\n\n\n\nA01: ""Our international student office offers a range of services designed to help you adjust, including cultural orientation sessions, social events, and workshops on local customs and lifestyle. We also have student mentors who can provide guidance and support as you navigate your new surroundings.""\n\nQ02: ""What kind of health services are available on campus?""\n\nA02: ""Our campus health center provides a range of medical services, including general consultations, mental health support, and emergency care. We also offer health insurance plans suitable for international students, ensuring you have access to comprehensive healthcare during your stay.""\n\nProgram Structure and Content\n\nQ01: ""Can students customize their curriculum within the Master\'s program?""\n\nA01: ""Absolutely. While there are core courses that all students must complete, our program offers elective courses allowing you to tailor your studies to your interests and career goals. Additionally, students can engage in independent study projects or research under faculty supervision for a more customized academic experience.""\n\nQ02: ""Is there an opportunity to study abroad or participate in international projects?""\n\nA02: ""Yes, our program includes opportunities for international study and collaboration through exchange programs, global consulting projects, and internships. These experiences are designed to enhance your global perspective and understanding of international business practices.""\n\nNetworking and Professional Development\n\nQ01: ""How does the program facilitate networking opportunities with industry professionals?""\n\nA01: ""Our program hosts regular networking events, guest lectures, and industry panels featuring alumni and professionals from the fields of business analytics and information systems. These events are excellent opportunities to build connections, gain insights into industry trends, and explore potential career paths.""\n\nQ02: ""Does the university offer career fairs or recruitment events for business analytics students?""\n\nA02: ""Yes, we organize career fairs and recruitment events specifically tailored to business analytics and information systems students. These events attract top employers in the industry looking to hire for internships and full-time positions. We also provide support in preparing for these events, including resume reviews and interview coaching.""\n\nSupport Systems\n\nQ01: ""What kind of academic support is available for students who may struggle with advanced coursework?""\n\n\n\nA01: ""We provide a comprehensive academic support system that includes tutoring services, study groups, and workshops on advanced topics in business analytics and information systems. Faculty members are also available for office hours to provide additional assistance and guidance.""\n\nQ02: ""Are there any mentorship programs available for new students?""\n\nA02: ""Yes, we offer a mentorship program that pairs new students with upperclassmen or alumni who can provide guidance, share their experiences, and offer advice on navigating both the academic and social aspects of the program. This program is designed to help new students transition smoothly into their graduate studies.""\n\nCertainly, Dr. Smith. Further expanding the range of inquiries, the following set of questions and answers delves into more specific and practical aspects that students might consider when applying for and participating in a Master of Business Analytics and Information Systems program.\n\nPractical Experience and Application\n\nQ01: ""Are there opportunities for practical experience within the program?""\n\nA01: ""Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience.""\n\nQ02: ""How does the program incorporate the latest industry trends and technologies?""\n\nA02: ""Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on']","Yes, the Master's program provides practical experience through hands-on projects, case studies, and internships with industry partners. The curriculum is continuously updated to incorporate the latest industry trends and technologies, with collaboration with industry leaders and alumni and hosting of tech talks and workshops.",reasoning,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
What are the benefits of retrieval-enhanced models and how does fine-tuning improve coordination between the retriever and generator?,"['training of autoregressive language models constitutes a\npromising avenue, marrying sophisticated retrieval tech-\nniques with expansive language models to yield more precise\nand efficient language generation.\nThe benefits of augmented pre-training include a robust\nfoundational model that outperforms standard GPT models\nin perplexity, text generation quality, and task-specific per-\nformance, all while utilizing fewer parameters. This method\nis particularly adept at handling knowledge-intensive tasks\nand facilitates the development of domain-specific models\nthrough training on specialized corpora.\nNonetheless, this approach faces challenges such as the\nnecessity for extensive pre-training datasets and resources,\nas well as diminished update frequencies with increasing\nmodel sizes. Despite these hurdles, the approach offers\nsignificant advantages in model resilience. Once trained,\nretrieval-enhanced models can operate independently of ex-\nternal libraries, enhancing generation speed and operational\nefficiency. The potential gains identified render this method-\nology a compelling subject for ongoing investigation and in-\nnovation in artificial intelligence and machine learning.\nFine-tuning Stage\nRAG and Fine-tuning are powerful tools for enhancing\nLLMs, and combining the two can meet the needs of more\nspecific scenarios. On one hand, fine-tuning allows for the\nretrieval of documents with a unique style, achieving bet-\nter semantic expression and aligning the differences between\nqueries and documents. This ensures that the output of the\nretriever is more aptly suited to the scenario at hand. On\nthe other hand, fine-tuning can fulfill the generation needs of\nmaking stylized and targeted adjustments. Furthermore, fine-\ntuning can also be used to align the retriever and generator for\nimproved model synergy.\nThe main goal of fine-tuning the retriever is to improve\nthe quality of semantic representations, achieved by directly\nfine-tuning the Embedding model using a corpus [Liu, 2023 ].\nBy aligning the retriever’s capabilities with the prefer-\nences of the LLMs through feedback signals, both can\nbe better coordinated [Yuet al. , 2023b, Izacard et al. , 2022,\nYang et al. , 2023b, Shi et al. , 2023 ]. Fine-tuning the retriever\nfor specific downstream tasks can lead to improved adapt-\nability [cite]. The introduction of task-agnostic fine-tuning\naims to enhance the retriever’s versatility in multi-task sce-\nnarios [Cheng et al. , 2023a ].\nFine-tuning generator can result in outputs that are\nmore stylized and customized. On one hand, it allows\nfor specialized adaptation to different input data formats.\nFor example, fine-tuning LLMs to fit the structure of\nknowledge graphs [Kang et al. , 2023 ], the structure of text\npairs [Kang et al. , 2023, Cheng et al. , 2023b ], and other spe-\ncific structures [Liet al. , 2023d ]. On the other hand, by con-\nstructing directive datasets, one can demand LLMs to gen-\nerate specific formats content. For instance, in adaptive or\niterative retrieval scenarios, LLMs are fine-tuned to generate\ncontent that will help determine the timing for the next step\nof action [Jiang et al. , 2023b, Asai et al. , 2023 ].\nBy synergistically fine-tuning both the retriever and the\ngenerator, we can enhance the model’s generalization capa-bilities and avoid overfitting that may arise from training them\nseparately. However, joint fine-tuning also leads to increased\nresource consumption. RA-DIT [Linet al. , 2023 ]presents\na lightweight, dual-instruction tuning framework that can\neffectively add retrieval capabilities to any LLMs. The\nretrieval-enhanced directive fine-tuning updates the LLM,\nguiding it to make more efficient use of the information re-\ntrieved and to disregard distracting content.\nDespite its advantages, fine-tuning has limitations, includ-\ning the need for specialized datasets for RAG fine-tuning\nand the requirement for significant computational resources.\nHowever, this stage allows for customizing models to specific\nneeds and data formats, potentially reducing resource usage\ncompared to the pre-training phase while still being able to\nfine-tune the model’s output style.\nIn summary, the fine-tuning stage is essential for the adap-\ntation of RAG models to specific tasks, enabling the refine-\nment of both retrievers and generators. This stage enhances\nthe model’s versatility and adaptability to various tasks, de-\n', 'Figure 4: Taxonomy of RAG’s core components\nretrieval-based strategies. The REALM model adopts a struc-\ntured, interpretable method for knowledge embedding, fram-\ning pre-training, and fine-tuning as a retrieve-then-predict\nworkflow within the masked language model (MLM) frame-\nwork [Arora et al. , 2023 ].\nRETRO [Borgeaud et al. , 2022 ]leverages retrieval aug-\nmentation for large-scale pre-training from scratch, achieving\na reduction in model parameters while surpassing standard\nGPT models in terms of perplexity. RETRO distinguishes it-\nself with an additional encoder designed to process features\nof entities retrieved from an external knowledge base, build-\ning on the foundational structure of GPT models.\nAtlas [Izacard et al. , 2022 ]also incorporates a retrieval\nmechanism into the T5 architecture [Raffel et al. , 2020 ]in\nboth the pre-training and fine-tuning stages. It uses a pre-\ntrained T5 to initialize the encoder-decoder language model\nand a pre-trained Contriever for the dense retriever, improv-\ning its efficiency for complex language modeling tasks.Furthermore, COG [Lanet al. , 2022 ]introduces a novel\ntext generation methodology that emulates copying text frag-\nments from pre-existing collections. Utilizing efficient vector\nsearch tools, COG computes and indexes contextually mean-\ningful representations of text fragments, demonstrating supe-\nrior performance in domains such as question-answering and\ndomain adaptation when compared to RETRO.\nThe advent of scaling laws has catalyzed the growth of\nmodel parameters, propelling autoregressive models into the\nmainstream. Researchers are expanding the RAG approach to\npretrained larger models, with RETRO++ exemplifying this\ntrend by scaling up the model parameters while preserving or\nenhancing performance [Wang et al. , 2023b ].\nEmpirical evidence underscores marked improvements in\ntext generation quality, factual accuracy, reduced toxicity,\nand downstream task proficiency, especially in knowledge-\nintensive applications like open-domain QA. These results\nimply that integrating retrieval mechanisms into the pre-']","Retrieval-enhanced models offer benefits such as improved model resilience, enhanced generation speed and operational efficiency, and the ability to operate independently of external libraries. Fine-tuning improves coordination between the retriever and generator by aligning their capabilities through feedback signals and allowing for specialized adaptation and customization of the output. It also enhances the model's generalization capabilities and avoids overfitting.",reasoning,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 12, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 11, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the prerequisites for ISM 6137 Statistical Data Mining for the MS-BAIS degree?,"['In addition, we strongly suggest that you take courses in a specific sequence.  Past experience has shown\nthat students who have not taken the courses in the suggested sequence are less successful.\nTake ISM 6124 Advanced Systems Analysis & Design  before you take ISM 6208 Data W arehousing . \nTake ISM 6225 Distributed Information Systems  before you take  ISM 6562 Big Data for Business\nApplications. \nTake QMB 6304 Analytical Methods for Business  before you take  ISM 6137 Statistical Data Mining . \nTake ISM 6136 Data Mining  before you take  ISM 6251 Data Science Programming  before you take ISM\n6564 T ext Analytics or ISM 6930 T echnical Foundations of AI\nNOTE 1: We have been a bit lax in enforcing prerequisites.  Starting in the Fall of 2023, we will strictly\nenforce prerequisites and remove students from courses if they have not met the prerequisites.\nNOTE 2 : With the increase in enrollment in the program, we cannot guarantee that we can of fer the core\ncourses (see next page) in every semester .  You should therefore take a core course whenever it is available\nand you are eligible to take it.  If you do not, you may not be able to graduate on time.\n \nElectives:\nWe have a wide range of departmental and non-departmental electives for you to choose from to enrich your\nlearning experience at USF . Note that you must complete 9 credits of departmental (BAIS) electives and\nanother 9 credits of BAIS and/or non-BAIS electives for your MS-BAIS degree. Non-departmental electives\nmust be pre-approved by Dr . Reichgelt before you register in those courses, and may require a permit from\nthe corresponding department. Departmental electives must satisfy prerequisites as described above.\nAny USF class may not count as ""electives"" for your 33-credit MS-BAIS degree. Classes that won\'t count\ninclude any undergraduate class, most 2 or 3-credit MBA  courses such as  ISM 6930 (Data Analytics for\nBusiness), QMB 6305, QMB 6358, QMB 6603, ISM 6021, ISM 6123, ISM 6436, ISM 6217, ISM 6565 and\nmany other Muma College of Business classes.\nAny classes out of our program MUST  be pre-approved by the SISM department before you can register for\nit and expect it to count toward your degree requirement. Contact Dr . Reichgelt ( muma-msbais@usf.edu\n(mailto:muma-msbais@usf.edu) ) for assistance with selecting electives to determine whether they will count\ntoward your degree.  The following non-BAIS course have already been pre-approved:\nEEL 6787: Data Networks, Systems and Security\n \nFIN 6406 Financial Management\nFIN 6246 The Financial System and FinT ech Innovation\nFIN 6416 Advanced Financial Management\nFIN 6455 Financial Modeling and Analytics\nFIN 6465 Financial Statement Analysis\nFIN 6515 Quantitative Investments\nFIN 6605 International Financial Management\nFIN 6778 Quantitative Analytics for Finance\nFIN 6779 FinT ech and Payment Technologies\n ']",The prerequisites for ISM 6137 Statistical Data Mining for the MS-BAIS degree are QMB 6304 Analytical Methods for Business.,reasoning,"[{'source': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
When and how can I register for the GEB 6527 Lean Six Sigma class?,"[""You can see courses of fered in future semesters by using USF staff search\n(http://usfweb.usf.edu/DSS/StaffScheduleSearch) , but keep in mind that this is a tentative schedule that is\nsubject to change. The final course schedule will be available 1-2 months before the start of the semester .\n \nWhat courses are of fered in summer?\nMost of our students do internships in summer . Hence, we have relatively few course of ferings in the\nsummer . Most elective classes, and well as many core classes, are not of fered in summer . We may also\ncancel classes that have very few students. Hence, if you plan to graduate in summer , plan your coursework\ncarefully to ensure that you can register for the classes you need to graduate in summer . \n \nHow do we register for the GEB 6527 Lean Six Sigma class?  \nThe Lean Six Sigma class is usually of fered the week before the start of the Fall semester but is considered\nan alternate calendar fall class.  It's also frequently of fered in the spring, during the week of spring break.  A\npermit is needed to register (see the link in the schedule search) and tuition waivers don't cover this class. \nNOTE: W e do not control the permits for this course and you should therefore not email us asking for a\npermit.\n ""]","The Lean Six Sigma class is usually offered the week before the start of the Fall semester and is also frequently offered in the spring, during the week of spring break. A permit is needed to register for this class, and tuition waivers do not cover it. Please note that the permits for this course are not controlled by us, so please do not email us asking for a permit.",reasoning,"[{'source': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 3, 'filename': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How does RAG enhance LLMs and what are the key steps in the workflow?,"['perspectives. Additionally, we anticipate future direc-\ntions for RAG, emphasizing potential enhancements to\ntackle current challenges, expansions into multi-modal\nsettings, and the development of its ecosystem.\nThe paper unfolds as follows: Section 2 and 3 define RAG\nand detail its developmental process. Section 4 through 6 ex-\nplore core components—Retrieval, “Generation” and “Aug-\nmentation”—highlighting diverse embedded technologies.\nSection 7 focuses on RAG’s evaluation system. Section 8\ncompare RAG with other LLM optimization methods and\nsuggest potential directions for its evolution. The paper con-\ncludes in Section 9.\n2 Definition\nThe definition of RAG can be summarized from its workflow.\nFigure 2 depicts a typical RAG application workflow. In this\nscenario, a user inquires ChatGPT about a recent high-profile\nevent (i.e., the abrupt dismissal and reinstatement of Ope-\nnAI’s CEO) which generated considerable public discourse.\nChatGPT as the most renowned and widely utilized LLM,\nconstrained by its pretraining data, lacks knowledge of re-\ncent events. RAG addresses this gap by retrieving up-to-date\ndocument excerpts from external knowledge bases. In this in-\nstance, it procures a selection of news articles pertinent to the\ninquiry. These articles, alongside the initial question, are then\namalgamated into an enriched prompt that enables ChatGPT\nto synthesize an informed response. This example illustrates\nthe RAG process, demonstrating its capability to enhance the\nmodel’s responses with real-time information retrieval.\nTechnologically, RAG has been enriched through various\ninnovative approaches addressing pivotal questions such as\n“what to retrieve” “when to retrieve” and “how to use the\nretrieved information”. For “what to retrieve” research has\nprogressed from simple token [Khandelwal et al. , 2019 ]and\nentity retrieval [Nishikawa et al. , 2022 ]to more complex\nstructures like chunks [Ram et al. , 2023 ]and knowledge\ngraph [Kang et al. , 2023 ], with studies focusing on the\ngranularity of retrieval and the level of data structur-\ning. Coarse granularity brings more information but\nwith lower precision. Retrieving structured text provides\nmore information while sacrificing efficiency. The ques-\ntion of “when to retrieve” has led to strategies ranging\nfrom single [Wang et al. , 2023e, Shi et al. , 2023 ]to adap-\ntive [Jiang et al. , 2023b, Huang et al. , 2023 ]and multiple\nretrieval [Izacard et al. , 2022 ]methods. High frequency of\nretrieval brings more information and lower efficiency. As\nfor ”how to use” the retrieved data, integration techniques\nhave been developed across various levels of the model\narchitecture, including the input [Khattab et al. , 2022 ],\nintermediate [Borgeaud et al. , 2022 ], and output lay-\ners[Liang et al. , 2023 ]. Although the “intermediate” and\n“output layers” are more effective, there are problems with\nthe need for training and low efficiency.\nRAG is a paradigm that enhances LLMs by integrating ex-\nternal knowledge bases. It employs a synergistic approach,\ncombining information retrieval mechanisms and In-Context\nLearning (ICL) to bolster the LLM’s performance. In this\nframework, a query initiated by a user prompts the retrieval ofpertinent information via search algorithms. This information\nis then woven into the LLM’s prompts, providing additional\ncontext for the generation process. RAG’s key advantage lies\nin its obviation of the need for retraining of LLMs for task-\nspecific applications. Developers can instead append an ex-\nternal knowledge repository, enriching the input and thereby\nrefining the model’s output precision. RAG has become one\nof the most popular architectures in LLMs’ systems, due to\nits high practicality and low barrier to entry, with many con-\nversational products being built almost entirely on RAG.\nThe RAG workflow comprises three key steps. First, the\ncorpus is partitioned into discrete chunks, upon which vec-\ntor indices are constructed utilizing an encoder model. Sec-\nond, RAG identifies and retrieves chunks based on their vec-\ntor similarity to the query and indexed chunks. Finally, the\nmodel synthesizes a response conditioned on the contextual\ninformation gleaned from the retrieved chunks']","RAG enhances LLMs by integrating external knowledge bases and employing a synergistic approach that combines information retrieval mechanisms and In-Context Learning (ICL). The key steps in the RAG workflow are: 1) partitioning the corpus into discrete chunks and constructing vector indices using an encoder model, 2) identifying and retrieving chunks based on their vector similarity to the query and indexed chunks, and 3) synthesizing a response conditioned on the contextual information gleaned from the retrieved chunks.",reasoning,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 2, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
"What are the enrollment requirements for internships in a semester, considering the type and duration?","[""time. During this time, we will not allow you to be distracted by internships, GA/T A-ship, or other activities.\nNOTE: If you are an international students, and you have completed all the requirements for the program,\nyou cannot apply for an internship unless you also register for another course.  In other words, you cannot\npostpone your graduation by enrolling for an internship alone.\n \nWhat are the rules and restrictions on doing CPT internships? \nInternships may be full-time or part-time. You are allowed to do full-time or part-time internships for a\nmaximum of 364 days . Exceeding this limit will disqualify you from participating in the  Optional Practical\nTraining (OPT) upon completion of your degree. If you are an international student, you will need those 18\nmonths of OPT  to transition from the F1 student visa to a H1B worker's visa. You are therefore allowed a\nmaximum of 3 credits for CPT  internships.\nFor both full-time and part-time internships, you will have to register for the ISM 6945 (BAIS Internship)\ncourse for each semester that you do the internship, and demonstrate what curriculum-related knowledge\nyou acquired from the internship. Because all USF courses (including ISM 6945) are organized by\nsemesters, if you are doing an internship that starts in say July (Summer) and ends in September (Fall), then\nyou will need to register for ISM 6945 twice: for Summer and then again for Fall, for this internship, and this\ninternship will consume two of the three credit hours allowed for internships. You can use the same of fer\nletter for both internship applications, but the application for each semester must be submitted and\nprocessed separately .\nCPT internship positions must be for at least 8 weeks . If you have a Summer internship that is say 6 weeks\nlong, we will approve it only if it is also part of a Fall internship that is also at least 6 weeks in length. In this\ncase, you must fill out two internship applications, for the Summer and Fall semesters, and take a 1 credit\nclass in each semester .  \nWe allow some flexibility in your start and end dates for internships. You can start your internship up to two\nweeks before  the semester , as long as these dates don't overlap with a prior term, and end it up to two\nweeks after  the end of the semester , except in your graduating (last) semester at USF . In your final\n(graduating) semester , your internship must be completed by the of ficial end of that semester .\nYou are not allowed to do an internship and hold a GA  position in the same semester . You have to choose\nwhether you want the internship or the GA  position. W e do not want to recruit you as a GA  is you cannot\ndemonstrate your commitment to the GA  position and will quit it the moment you get a more lucrative\ninternship. W e will not approve your internship request once you are on USF payroll for your GA  job.\nYou are also not allowed to do a full-time internship, independent study , and register for classes (online or in-\nperson) in the same semester . This is to ensure that you spend adequate time and do a good job in\nwhatever you registered in for that semester .\n \nWhat are the course enrollment requirements for doing full-time or part-time internships in a given\nsemester?\nThe course enrollment requirements vary based on whether you are doing a full-time or part-time internship,\nand whether you are doing this internship in Fall, Spring, or Summer semesters.""]","The enrollment requirements for internships in a semester depend on the type and duration of the internship. For full-time or part-time internships in Fall, Spring, or Summer semesters, you will need to register for the ISM 6945 (BAIS Internship) course for each semester that you do the internship. Additionally, you must demonstrate curriculum-related knowledge acquired from the internship. The internship must be for at least 8 weeks, and if it is less than 8 weeks, it must be part of a longer internship in the same semester. You can start the internship up to two weeks before the semester and end it up to two weeks after the end of the semester, except in your graduating semester where it must be completed by the official end of the semester. You are not allowed to do an internship and hold a GA position in the same semester, and you are also not allowed to do a full-time internship, independent study, and register for classes in the same semester.",reasoning,"[{'source': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
Which course comes before ISM 6564 or ISM 6930 in the suggested sequence?,"['In addition, we strongly suggest that you take courses in a specific sequence.  Past experience has shown\nthat students who have not taken the courses in the suggested sequence are less successful.\nTake ISM 6124 Advanced Systems Analysis & Design  before you take ISM 6208 Data W arehousing . \nTake ISM 6225 Distributed Information Systems  before you take  ISM 6562 Big Data for Business\nApplications. \nTake QMB 6304 Analytical Methods for Business  before you take  ISM 6137 Statistical Data Mining . \nTake ISM 6136 Data Mining  before you take  ISM 6251 Data Science Programming  before you take ISM\n6564 T ext Analytics or ISM 6930 T echnical Foundations of AI\nNOTE 1: We have been a bit lax in enforcing prerequisites.  Starting in the Fall of 2023, we will strictly\nenforce prerequisites and remove students from courses if they have not met the prerequisites.\nNOTE 2 : With the increase in enrollment in the program, we cannot guarantee that we can of fer the core\ncourses (see next page) in every semester .  You should therefore take a core course whenever it is available\nand you are eligible to take it.  If you do not, you may not be able to graduate on time.\n \nElectives:\nWe have a wide range of departmental and non-departmental electives for you to choose from to enrich your\nlearning experience at USF . Note that you must complete 9 credits of departmental (BAIS) electives and\nanother 9 credits of BAIS and/or non-BAIS electives for your MS-BAIS degree. Non-departmental electives\nmust be pre-approved by Dr . Reichgelt before you register in those courses, and may require a permit from\nthe corresponding department. Departmental electives must satisfy prerequisites as described above.\nAny USF class may not count as ""electives"" for your 33-credit MS-BAIS degree. Classes that won\'t count\ninclude any undergraduate class, most 2 or 3-credit MBA  courses such as  ISM 6930 (Data Analytics for\nBusiness), QMB 6305, QMB 6358, QMB 6603, ISM 6021, ISM 6123, ISM 6436, ISM 6217, ISM 6565 and\nmany other Muma College of Business classes.\nAny classes out of our program MUST  be pre-approved by the SISM department before you can register for\nit and expect it to count toward your degree requirement. Contact Dr . Reichgelt ( muma-msbais@usf.edu\n(mailto:muma-msbais@usf.edu) ) for assistance with selecting electives to determine whether they will count\ntoward your degree.  The following non-BAIS course have already been pre-approved:\nEEL 6787: Data Networks, Systems and Security\n \nFIN 6406 Financial Management\nFIN 6246 The Financial System and FinT ech Innovation\nFIN 6416 Advanced Financial Management\nFIN 6455 Financial Modeling and Analytics\nFIN 6465 Financial Statement Analysis\nFIN 6515 Quantitative Investments\nFIN 6605 International Financial Management\nFIN 6778 Quantitative Analytics for Finance\nFIN 6779 FinT ech and Payment Technologies\n ']",ISM 6251 Data Science Programming,multi_context,"[{'source': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What strategies has Advanced RAG implemented to improve indexing challenges and address retrieval and generation issues?,"['and post-retrieval strategies. To address the indexing chal-\nlenges experienced by Naive RAG, Advanced RAG has re-\nfined its indexing approach using techniques such as slid-\ning window, fine-grained segmentation, and metadata. It has\nalso introduced various methods to optimize the retrieval pro-\ncess [ILIN, 2023 ].\nPre-Retrieval Process\nOptimizing Data Indexing .The goal of optimizing data index-\ning is to enhance the quality of the content being indexed.\nThis involves five primary strategies: enhancing data gran-\nularity, optimizing index structures, adding metadata, align-\nment optimization, and mixed retrieval.\nEnhancing data granularity aims to elevate text standard-\nization, consistency, factual accuracy, and rich context to im-\nprove the RAG system’s performance. This includes remov-\ning irrelevant information, dispelling ambiguity in entities\nand terms, confirming factual accuracy, maintaining context,\nand updating outdated documents.\nOptimizing index structures involves adjusting the size of\nchunks to capture relevant context, querying across multiple\nindex paths, and incorporating information from the graph\nstructure to capture relevant context by leveraging relation-\nships between nodes in a graph data index.\nAdding metadata information involves integrating refer-\nenced metadata, such as dates and purposes, into chunks for\nfiltering purposes, and incorporating metadata like chapters\nand subsections of references to improve retrieval efficiency.\nAlignment optimization addresses alignment issues and\ndisparities between documents by introducing “hypothetical\nquestions” [Liet al. , 2023d ]into documents to rectify align-\nment issues and differences.\nRetrieval\nDuring the retrieval stage, the primary focus is on identifying\nthe appropriate context by calculating the similarity between\nthe query and chunks. The embedding model is central to\nthis process. In the advanced RAG, there is potential for op-\ntimization of the embedding models.\nFine-tuning Embedding . Fine-tuning embedding models\nsignificantly impact the relevance of retrieved content in RAG\nsystems. This process involves customizing embedding mod-\nels to enhance retrieval relevance in domain-specific contexts,\nespecially for professional domains dealing with evolving or\nrare terms. The BGE embedding model [BAAI, 2023 ], such\nas BGE-large-EN developed by BAAI2, is an example of a\nhigh-performance embedding model that can be fine-tuned\nto optimize retrieval relevance. Training data for fine-tuning\ncan be generated using language models like GPT-3.5-turbo\nto formulate questions grounded on document chunks, which\nare then used as fine-tuning pairs.\nDynamic Embedding adapts to the context in which words\nare used, unlike static embedding, which uses a single vec-\ntor for each word [Karpukhin et al. , 2020 ]. For example,\nin transformer models like BERT, the same word can have\nvaried embeddings depending on surrounding words. Ope-\nnAI’s embeddings-ada-02 model3, built upon the principles\n2https://huggingface.co/BAAI/bge-large-en\n3https://platform.openai.com/docs/guides/embeddingsof LLMs like GPT, is a sophisticated dynamic embedding\nmodel that captures contextual understanding. However, it\nmay not exhibit the same sensitivity to context as the latest\nfull-size language models like GPT-4.\nPost-Retrieval Process\nAfter retrieving valuable context from the database, it is es-\nsential to merge it with the query as an input into LLMs while\naddressing challenges posed by context window limits. Sim-\nply presenting all relevant documents to the LLM at once may\nexceed the context window limit, introduce noise, and hinder\nthe focus on crucial information. Additional processing of the\nretrieved content is necessary to address these issues.\nRe-Ranking . Re-ranking the retrieved information to re-\nlocate the most relevant content to the edges of the prompt\nis a key strategy. This concept has been implemented\nin frameworks such as LlamaIndex4, LangChain5, and\nHayStack [Blagojevi, 2023 ]. For example, Diversity Ranker6\nprioritizes reordering based on document diversity, while\nLostInTheMiddleRanker alternates placing the best docu-\nment at the beginning and end of the context window. Ad-\nditionally, approaches like cohereAI rerank [Cohere, 2023 ],\nbge-rerank7, and LongLLMLingua [Jiang et al. , 20']","Advanced RAG has implemented several strategies to improve indexing challenges and address retrieval and generation issues. These strategies include refining the indexing approach using techniques such as sliding window, fine-grained segmentation, and metadata. They have also introduced methods to optimize the retrieval process, such as enhancing data granularity, optimizing index structures, adding metadata, alignment optimization, and mixed retrieval. Additionally, Advanced RAG focuses on fine-tuning embedding models and utilizing dynamic embedding to improve retrieval relevance. In the post-retrieval process, re-ranking the retrieved information is implemented to relocate the most relevant content to the edges of the prompt.",multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 4, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What practical experience opportunities are available and how does the program incorporate industry trends and technologies?,"['Pre-Application Phase\n\nUnderstanding Program Fit and Outcomes\n\nQ01: ""How do I know if the Master of Business Analytics and Information Systems program is right for me?""\n\nA01: ""This program is ideal for individuals who have a strong interest in data analysis, technology, and business decision-making. If you\'re passionate about leveraging data to solve complex business problems and drive strategic decisions, this program can provide the skills and knowledge you need. We recommend reviewing our curriculum and speaking with current students or alumni to gauge how well the program aligns with your career goals.""\n\nQ02: ""What specializations are available in the Master of Business Analytics and Information Systems program?""\n\nA1: ""Our program offers several specializations, including Data Analytics, Information Systems Management, Business Intelligence, and more. Each path is designed to equip students with in-demand skills and knowledge relevant to the current job market.""\n\nApplication Strategy\n\nQ01: ""What can I do to strengthen my application?""\n\nA01: ""To strengthen your application, focus on highlighting your quantitative and analytical skills, any relevant work experience, and your passion for the field of business analytics. Letters of recommendation should come from individuals who can speak to your academic and professional abilities. A well-crafted statement of purpose that clearly articulates your career goals and how the program can help you achieve them is also crucial.""\n\nQ02: ""What are the prerequisites for applying to this program?""\n\nA02: ""Applicants are expected to have a bachelor\'s degree from an accredited institution, a fundamental understanding of statistics and computer programming, and a competitive GPA. Additional requirements include letters of recommendation, a statement of purpose, and a resume.""\n\nQ03: ""How can I apply as an international student?""\n\nA03: ""International students can apply through our online application portal. You\'ll need to submit your academic transcripts, proof of English language proficiency (TOEFL/IELTS), financial support documents, and a copy of your passport, among other requirements.""\n\nProgram Differentiators\n\n\n\nQ01: ""What sets your Master of Business Analytics and Information Systems program apart from others?""\n\nA01: ""Our program stands out due to its strong emphasis on practical, hands-on experience, its integration with the latest technologies and industry practices, and the extensive network of alumni and industry partners. Additionally, our faculty includes leading experts in business analytics and information systems, who bring real-world insights and research into the classroom.""\n\nFinancial Planning\n\nQ01: ""What kind of financial aid is available for students?""\n\nA01: ""Our institution offers a variety of financial aid options for students, including scholarships, grants, work-study opportunities, and loans. We recommend prospective students apply for financial aid early to maximize their chances of receiving support. Our financial aid office is available to help you navigate the process and identify the best options for your situation.""\n\nPreparing for the Program\n\nQ01: ""How can I prepare academically for the program?""\n\nA01: ""To prepare academically, we recommend brushing up on your quantitative skills, particularly in statistics and mathematics. Familiarity with programming languages such as Python or R, and database management systems, will also be beneficial. Engaging in online courses or workshops that cover these areas can be a great way to prepare.""\n\nApplication Timing and Deadlines\n\nQ01: ""Is there an advantage to applying early to the program?""\n\nA01: ""Applying early can have several advantages, including receiving an earlier decision, having more time to plan for relocation and financing, and in some cases, being considered for early scholarship awards. We encourage applicants to submit their materials as soon as they are ready to take advantage of these benefits.""\n\nProgram Expectations\n\nQ01: ""What is expected from students in the Master of Business Analytics and Information Systems program?""\n\nA01: ""We expect our students to demonstrate a strong commitment to their studies, a willingness to engage in collaborative and individual projects, and an eagerness to learn and apply new concepts and technologies. Successful students typically possess strong analytical skills, effective communication abilities, and the capacity to think critically and solve complex problems.""\n\nApplication Process\n\n\n\nQ01: ""What documents do I need for the student visa application?""\n\nA01: ""You\'ll need a valid passport, the acceptance letter from our institution, proof of financial support, completed visa application forms, and a passport-sized photograph. Depending on your country, additional documents may be required.""\n\nQ02: ""Is there a deadline for applying to the Master\'s program?""\n\nA02: ""Yes, our application deadlines are as follows: Fall semester - May 1st, Spring semester - October 1st. We recommend applying early to ensure sufficient time for visa processing.""\n\nPost-Acceptance and Pre-Arrival\n\nQ01', ' global community that provides a platform for networking, mentorship, and professional growth. As a graduate, you\'ll have access to alumni events, webinars, and other resources to stay connected with your peers and the institution.""\n\nTechnical Requirements and Resources\n\nQ01: ""What are the computing requirements for the program?""\n\nA01: ""Our program requires students to have a laptop with specific hardware configurations to handle data analytics and business intelligence software efficiently. Recommended specifications include a modern multi-core processor, at least 16GB of RAM, and a solid-state drive (SSD). Detailed requirements are available on our program\'s website.""\n\nQ02: ""Are there any software licenses provided for students in this program?""\n\nA02: ""Yes, enrolled students receive access to various professional software tools and platforms necessary for coursework, including statistical analysis, data visualization, and business intelligence software, at no additional cost. This is part of our commitment to ensure students have the necessary resources for their studies.""\n\nAdjusting to a New Environment\n\nQ01: ""How does the university assist international students in adjusting to life in a new country?""\n\n\n\nA01: ""Our international student office offers a range of services designed to help you adjust, including cultural orientation sessions, social events, and workshops on local customs and lifestyle. We also have student mentors who can provide guidance and support as you navigate your new surroundings.""\n\nQ02: ""What kind of health services are available on campus?""\n\nA02: ""Our campus health center provides a range of medical services, including general consultations, mental health support, and emergency care. We also offer health insurance plans suitable for international students, ensuring you have access to comprehensive healthcare during your stay.""\n\nProgram Structure and Content\n\nQ01: ""Can students customize their curriculum within the Master\'s program?""\n\nA01: ""Absolutely. While there are core courses that all students must complete, our program offers elective courses allowing you to tailor your studies to your interests and career goals. Additionally, students can engage in independent study projects or research under faculty supervision for a more customized academic experience.""\n\nQ02: ""Is there an opportunity to study abroad or participate in international projects?""\n\nA02: ""Yes, our program includes opportunities for international study and collaboration through exchange programs, global consulting projects, and internships. These experiences are designed to enhance your global perspective and understanding of international business practices.""\n\nNetworking and Professional Development\n\nQ01: ""How does the program facilitate networking opportunities with industry professionals?""\n\nA01: ""Our program hosts regular networking events, guest lectures, and industry panels featuring alumni and professionals from the fields of business analytics and information systems. These events are excellent opportunities to build connections, gain insights into industry trends, and explore potential career paths.""\n\nQ02: ""Does the university offer career fairs or recruitment events for business analytics students?""\n\nA02: ""Yes, we organize career fairs and recruitment events specifically tailored to business analytics and information systems students. These events attract top employers in the industry looking to hire for internships and full-time positions. We also provide support in preparing for these events, including resume reviews and interview coaching.""\n\nSupport Systems\n\nQ01: ""What kind of academic support is available for students who may struggle with advanced coursework?""\n\n\n\nA01: ""We provide a comprehensive academic support system that includes tutoring services, study groups, and workshops on advanced topics in business analytics and information systems. Faculty members are also available for office hours to provide additional assistance and guidance.""\n\nQ02: ""Are there any mentorship programs available for new students?""\n\nA02: ""Yes, we offer a mentorship program that pairs new students with upperclassmen or alumni who can provide guidance, share their experiences, and offer advice on navigating both the academic and social aspects of the program. This program is designed to help new students transition smoothly into their graduate studies.""\n\nCertainly, Dr. Smith. Further expanding the range of inquiries, the following set of questions and answers delves into more specific and practical aspects that students might consider when applying for and participating in a Master of Business Analytics and Information Systems program.\n\nPractical Experience and Application\n\nQ01: ""Are there opportunities for practical experience within the program?""\n\nA01: ""Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience.""\n\nQ02: ""How does the program incorporate the latest industry trends and technologies?""\n\nA02: ""Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on']","Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience. Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on industry trends and technologies.",multi_context,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}, {'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
"What are the two types of ""reflection tokens"" in the Self-RAG model and their contribution to the decision-making process?","['Zhang, 2023 ]. Graph-Toolformer, for instance, divides its re-\ntrieval process into distinct steps where LLMs proactively use\nretrievers, apply Self-Ask techniques, and employ few-shot\nprompts to initiate search queries. This proactive stance al-\nlows LLMs to decide when to search for necessary informa-\ntion, akin to how an agent utilizes tools.\nWebGPT [Nakano et al. , 2021 ]integrates a reinforcement\nlearning framework to train the GPT-3 model in au-\ntonomously using a search engine during text generation.\nIt navigates this process using special tokens that facili-\ntate actions such as search engine queries, browsing results,\nand citing references, thereby expanding GPT-3’s capabilities\nthrough the use of external search engines.\nFlare automates timing retrieval by monitoring the confi-\ndence of the generation process, as indicated by the probabil-\nity of generated terms [Jiang et al. , 2023b ]. When the prob-\nability falls below a certain threshold would activates the re-\ntrieval system to collect relevant information, thus optimizing\nthe retrieval cycle.\nSelf-RAG [Asai et al. , 2023 ]introduces “reflection to-\nkens” that allow the model to introspect its outputs. These\ntokens come in two varieties: “retrieve” and “critic”. The\nmodel autonomously decides when to activate retrieval, or\nalternatively, a predefined threshold may trigger the pro-\ncess. During retrieval, the generator conducts a fragment-\nlevel beam search across multiple paragraphs to derive the\nmost coherent sequence. Critic scores are used to update the\nsubdivision scores, with the flexibility to adjust these weights\nduring inference, tailoring the model’s behavior. Self-RAG’s\ndesign obviates the need for additional classifiers or reliance\non Natural Language Inference (NLI) models, thus stream-\nlining the decision-making process for when to engage re-\ntrieval mechanisms and improving the model’s autonomous\njudgment capabilities in generating accurate responses.\nLLM optimization has received significant attention due to\nits increasing prevalence. Techniques such as prompt engi-\nneering, Fine-Tuning (FT), and RAG each have distinct char-\nacteristics, visually represented in Figure 6. While prompt\nengineering leverages a model’s inherent capabilities, opti-\nmizing LLMs often requires the application of both RAG and\nFT methods. The choice between RAG and FT should be\nbased on the specific requirements of the scenario and the in-\nherent properties of each approach. A detailed comparison of\nRAG and FT is presented in Table 1.\n6.4 RAG vs Fine-Tuning\nRAG is like giving a model a textbook for tailored informa-\ntion retrieval, perfect for specific queries. On the other hand,\nFT is like a student internalizing knowledge over time, bet-\nter for replicating specific structures, styles, or formats. FT\ncan improve model performance and efficiency by reinforc-\ning base model knowledge, adjusting outputs, and teaching\ncomplex instructions. However, it is not as good for integrat-\ning new knowledge or rapidly iterating new use cases.\nThe two methods, RAG and FT, are not mutually exclusive\nand can be complementary, augmenting a model’s capabil-\nities at different levels. In some cases, their combined use\nmay yield optimal performance. The optimization processinvolving RAG and FT can necessitate multiple iterations to\nachieve satisfactory results.\n7 RAG Evaluation\nThe rapid advancement and growing adoption of RAG in the\nfield of Natural Language Processing (NLP) have propelled\nthe evaluation of RAG models to the forefront of research in\nthe LLMs community. The primary objective of this evalua-\ntion is to comprehend and optimize the performance of RAG\nmodels across diverse application scenarios.\nHistorically, RAG models assessments have centered\non their execution in specific downstream tasks. These\nevaluations employ established metrics suitable to the tasks\nat hand. For instance, question answering evaluations\nmight rely on EM and F1 scores [Wang et al. , 2023a,\nShiet al. , 2023, Feng et al. , 2023, Ma et al. , 2023a ], whereas\nfact-checking tasks often hinge on accuracy as the pri-\nmary metric [Lewis et al. , 2020, Izacard et al. , 2022,\nShao et al. , 2023 ]. Tools like RALLE, designed for the auto-\nmatic evaluation of RAG applications, similarly base their as-\nsessments on these task-']","The two types of ""reflection tokens"" in the Self-RAG model are ""retrieve"" and ""critic"". These tokens allow the model to introspect its outputs and autonomously decide when to activate retrieval. During retrieval, the generator conducts a fragment-level beam search across multiple paragraphs to derive the most coherent sequence. Critic scores are used to update the subdivision scores, improving the model's autonomous judgment capabilities in generating accurate responses.",multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 15, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What opportunities are there for practical experience and staying up-to-date in the Master of Business Analytics and Information Systems program?,"[': ""What are the next steps after receiving my acceptance letter?""\n\nA01: ""Congratulations on your acceptance! The next steps include securing your student visa, arranging for housing, registering for classes, and attending the international student orientation. Detailed information will be provided in your acceptance package.""\n\nQ02: ""How do I find accommodation?""\n\nA02: ""Our institution offers on-campus housing options, including dormitories and apartments. Alternatively, you can opt for off-campus housing. Our student services office provides resources and assistance to help you find suitable accommodation.""\n\nOrientation and First Semester\n\nQ01: ""What should I expect during the orientation week?""\n\nA01: ""Orientation week includes campus tours, registration assistance, workshops on academic success, and social events to meet fellow students and faculty. It\'s a great opportunity to get acclimated to the campus and the community.""\n\nQ02: ""How can I register for courses?""\n\nA02: ""Course registration can be completed online through the student portal. If you need guidance on selecting courses relevant to your specialization, academic advisors are available to assist you.""\n\nContinuous Support\n\nQ01: ""Where can I get help if I\'m struggling with my coursework?""\n\nA01: ""We offer a range of support services, including tutoring, study groups, and academic advising. Don\'t hesitate to reach out for help; our goal is to ensure your success.""\n\n\n\nFinancial Information and Scholarships\n\nQ01: ""Are there scholarship opportunities for international students in the Master\'s program?""\n\nA01: ""Yes, our institution offers a range of scholarships for international students based on academic merit, financial need, and leadership qualities. We encourage you to apply early and visit our financial aid website for detailed information on eligibility and application procedures.""\n\nQ02: ""What is the estimated cost of attendance for the Master\'s program?""\n\nA02: ""The estimated cost of attendance includes tuition fees, accommodation, books and supplies, and living expenses. For the upcoming academic year, the total estimated cost is approximately $XX,XXX. Please note, this figure is subject to change and varies based on personal spending habits and accommodation choices.""\n\nVisa and Immigration\n\nQ01: ""What should I do if my student visa gets denied?""\n\nA01: ""In the event of a visa denial, it\'s important to understand the reason for the denial. You may reapply if you believe that your circumstances have changed or if you can provide additional information that was not presented in the initial application. Our international student office can provide guidance on the reapplication process.""\n\nQ02: ""Can I work while studying in the program?""\n\nA02: ""International students on a student visa are allowed to work on-campus for up to 20 hours per week during the academic term and full-time during breaks. Off-campus employment opportunities are subject to specific visa regulations and typically require authorization.""\n\nAcademic Life\n\nQ01: ""How can I get involved in research projects or internships during my studies?""\n\nA01: ""Our program encourages practical experience through research projects and internships. You can express your interest to faculty members, visit the career services office, or attend job fairs and networking events to explore opportunities.""\n\nQ02: ""What kind of support services are available for international students?""\n\nA02: ""We offer a wide range of support services including academic advising, career services, counseling, health services, and an international student office dedicated to assisting with visa issues, cultural adjustment, and other specific needs.""\n\nCampus Life and Community\n\nQ01: ""Are there any clubs or organizations I can join as an international student?""\n\n\n\nA01: ""Yes, our campus has a vibrant community with various clubs and organizations, including cultural associations, professional societies, and interest-based clubs. Joining these groups is a great way to meet people, develop new skills, and integrate into the campus community.""\n\nQ02: ""What resources are available to help me improve my English language skills?""\n\nA02: ""Our institution offers English language support services including ESL (English as a Second Language) courses, tutoring, writing workshops, and conversation practice sessions. These resources are designed to help non-native speakers enhance their academic and social communication skills.""\n\nAfter Graduation\n\nQ01: ""What are the career prospects after completing this Master\'s program?""\n\nA01: ""Graduates of our program have gone on to successful careers in data analysis, IT management, consulting, business intelligence, and more. Our career services office provides career counseling, resume workshops, interview preparation, and job placement assistance to support your professional development.""\n\nQ02: ""Is there an alumni network I can join after graduation?""\n\nA02: ""Absolutely. Our alumni network is a', ' global community that provides a platform for networking, mentorship, and professional growth. As a graduate, you\'ll have access to alumni events, webinars, and other resources to stay connected with your peers and the institution.""\n\nTechnical Requirements and Resources\n\nQ01: ""What are the computing requirements for the program?""\n\nA01: ""Our program requires students to have a laptop with specific hardware configurations to handle data analytics and business intelligence software efficiently. Recommended specifications include a modern multi-core processor, at least 16GB of RAM, and a solid-state drive (SSD). Detailed requirements are available on our program\'s website.""\n\nQ02: ""Are there any software licenses provided for students in this program?""\n\nA02: ""Yes, enrolled students receive access to various professional software tools and platforms necessary for coursework, including statistical analysis, data visualization, and business intelligence software, at no additional cost. This is part of our commitment to ensure students have the necessary resources for their studies.""\n\nAdjusting to a New Environment\n\nQ01: ""How does the university assist international students in adjusting to life in a new country?""\n\n\n\nA01: ""Our international student office offers a range of services designed to help you adjust, including cultural orientation sessions, social events, and workshops on local customs and lifestyle. We also have student mentors who can provide guidance and support as you navigate your new surroundings.""\n\nQ02: ""What kind of health services are available on campus?""\n\nA02: ""Our campus health center provides a range of medical services, including general consultations, mental health support, and emergency care. We also offer health insurance plans suitable for international students, ensuring you have access to comprehensive healthcare during your stay.""\n\nProgram Structure and Content\n\nQ01: ""Can students customize their curriculum within the Master\'s program?""\n\nA01: ""Absolutely. While there are core courses that all students must complete, our program offers elective courses allowing you to tailor your studies to your interests and career goals. Additionally, students can engage in independent study projects or research under faculty supervision for a more customized academic experience.""\n\nQ02: ""Is there an opportunity to study abroad or participate in international projects?""\n\nA02: ""Yes, our program includes opportunities for international study and collaboration through exchange programs, global consulting projects, and internships. These experiences are designed to enhance your global perspective and understanding of international business practices.""\n\nNetworking and Professional Development\n\nQ01: ""How does the program facilitate networking opportunities with industry professionals?""\n\nA01: ""Our program hosts regular networking events, guest lectures, and industry panels featuring alumni and professionals from the fields of business analytics and information systems. These events are excellent opportunities to build connections, gain insights into industry trends, and explore potential career paths.""\n\nQ02: ""Does the university offer career fairs or recruitment events for business analytics students?""\n\nA02: ""Yes, we organize career fairs and recruitment events specifically tailored to business analytics and information systems students. These events attract top employers in the industry looking to hire for internships and full-time positions. We also provide support in preparing for these events, including resume reviews and interview coaching.""\n\nSupport Systems\n\nQ01: ""What kind of academic support is available for students who may struggle with advanced coursework?""\n\n\n\nA01: ""We provide a comprehensive academic support system that includes tutoring services, study groups, and workshops on advanced topics in business analytics and information systems. Faculty members are also available for office hours to provide additional assistance and guidance.""\n\nQ02: ""Are there any mentorship programs available for new students?""\n\nA02: ""Yes, we offer a mentorship program that pairs new students with upperclassmen or alumni who can provide guidance, share their experiences, and offer advice on navigating both the academic and social aspects of the program. This program is designed to help new students transition smoothly into their graduate studies.""\n\nCertainly, Dr. Smith. Further expanding the range of inquiries, the following set of questions and answers delves into more specific and practical aspects that students might consider when applying for and participating in a Master of Business Analytics and Information Systems program.\n\nPractical Experience and Application\n\nQ01: ""Are there opportunities for practical experience within the program?""\n\nA01: ""Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience.""\n\nQ02: ""How does the program incorporate the latest industry trends and technologies?""\n\nA02: ""Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on']","Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience. Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on emerging technologies.",multi_context,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}, {'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
What are the eligibility criteria and rules for CPT internships in relation to the BAIS program at USF?,"[""CPT Internships\nWhat are CPT internships?\nCurricular Practical Training (CPT) are training/learning opportunities related to your curriculum (business\nanalytics & information systems) in real-world businesses. These internships may be paid or unpaid, on-site\nor remote, full-time (more than 20 hours/week) or part-time (20 hours or less  per week), and can be done in\nany semester of the year (Summer , Fall, or Spring). There are dif ferent course registration requirements for\nfull-time vs. part-time internships, so read on below . Note that we do not authorize unpaid internships, and\nwe also do not approve internships that are unrelated to your curriculum (e.g., internships in finance or\nmarketing).\nCPT internships are not required to graduate from the BAIS program, but are strongly encouraged, as they\nare an opportunity for you to showcase your skills in a professional workplace and build domain knowledge,\nwhich are both invaluable in securing employment after graduation, and they provide you with an additional\nsource of income. W e have seen numerous instances where internship employers of fered their interns full-\ntime positions upon graduation.\nAlso note that CPT  internship is NOT  a job; it's a learning opportunity related to your curriculum outside of\ntraditional class lectures, or in other words, it is a practicum course (ISM 6945: BAIS Internship; 1 credit).\nHence, we must certify your internship as part of your curriculum and must ensure that you learned some\ncurriculum-related practical knowledge/experience from that internship. For this reason, CPT  internships will\nalso require you to sign up for the BAIS internship course (ISM 6945), specify which other BAIS courses\nhelped you build the skills needed for this internship, and meet the requirements of this course (e.g., first day\nattendance, end-of-term project report, etc.). At the end of the semester , you will get a\nSatisfactory/Unsatisfactory (S/U) grade in the course. You need a satisfactory grade to receive credit for this\ncourse as part of the 33-credit requirement for the BAIS degree. Note that both full-time and part-time\ninternships are 1-credit per semester .\n \nWho is eligible for CPT internships?\nCPT internships at USF are now administered by the student's major department, which in your case, is the\nSchool of Information Systems & Management (SISM). Any student who meets the following criteria is\neligible to do a BAIS internship.\n1. Complete two semesters  (Fall and Spring) of full-time coursework in residence. Students entering in Fall\nare eligible for internship in their first summer . However , students entering in Spring who have completed\nonly one semester of coursework in Spring are NOT  eligible for summer internship in their first summer at\nUSF (sorry , but this is a USCIS ruling over which we have no control).\n2. Complete the following two courses before applying for an internship: (a) QMB 6304  (Analytical Methods\nin Business) and (b) ISM 6218  (Advanced Database Management). Most students take these classes in their\nfirst semester in the BAIS program. However you still have to complete the two-semester residency\nrequirement before you are eligible for CPT  internships.\n3. Maintain a  GPA of 3.0 or higher . If your GP A falls below this level, then you are on academic probation.\nWe will need to work with you to create an action plan to improve your grades so that you can graduate on""]","To be eligible for CPT internships in relation to the BAIS program at USF, students must complete two semesters of full-time coursework in residence, complete the courses QMB 6304 (Analytical Methods in Business) and ISM 6218 (Advanced Database Management), and maintain a GPA of 3.0 or higher. Students entering in Fall are eligible for internships in their first summer, but students entering in Spring who have completed only one semester of coursework in Spring are not eligible for summer internships in their first summer at USF. CPT internships are not required to graduate from the BAIS program, but are strongly encouraged.",multi_context,"[{'source': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What prerequisites are there for ISM 6251 and ISM 6930?,"[""8. ISM 6156: ERP  & BPM\n9. ISM 6316: Project Management\n10. ISM 6930: Text Analytics (Prerequisite: ISM 6251)\n11. ISM 6577: Business Continuity and Recovery Planning\n12. ISM 6945: BAIS Internship (1 credit for both full-time and part-time internships, max 3 credits for 3\nsemesters)\n13. ISM 6905: Independent Study (1 or 2 credits)\nPrerequisites for any class must be completed in a PREVIOUS semester . Concurrent enrollment in a class\nAND its prerequisite in the same semester is not allowed. If you need help with prerequisites, please e-mail\nDr. Reichgelt.\n \nAre there any ISM/QMB classes that can't be used towards graduation?  \nYes. Classes that can't be used as MS BAIS electives include a ny undergraduate class, most 2 or 3 credit\nMBA  courses or MBA  sections of MS-BAIS courses such as ISM 6930-Data Analytics for Business,  QMB\n6305, QMB 6358, QMB 6603,  ISM 6021, ISM 6123 (Fund of Data Mgmt & Analysis),  ISM 6436,  ISM\n6217.  Some other graduate College of Business classes may be ineligible.  Please contact Dr . Johannes\nReichgelt if you plan to register for any of these courses or have any questions in this regard.\n \nHow many credits can I register for?  \nThere is a limit to the number of courses you can register for .  In the regular semesters, i.e. Fall and Spring,\nyou can register for at most 4 courses (12 credits).  In the Summer , you can register for at most 2 courses (6\ncredits).  There are additional rules that apply when you have a full-time internship and these rules are\nexplained in the CPT  module.  USF insists that you enroll for at least 2 credits in your graduating semester . \nThis includes the Summer semester .\nThe Lean Six Sigma course counts towards the 12 credits if you take in the Spring, but not if you take it in\nthe Fall.  The Spring course is in the middle of the semester; the fall course is of fered before the Fall\nsemester starts.\n \nHow can I register for alternate calendar classes?  \nUse this link: https://www .usf.edu/registrar/register/altcalendar .aspx\n(https://www.usf.edu/registrar/register/altcalendar.aspx)  \nContact the registrar's of fice at 974-2000 for if you have concerns about late add fees.  You should be able to\ndrop alternate classes during the first scheduled week without penalty , but again - this is the registrar's\ndomain, so always check with them to confirm.\n \nSome courses require a permit.   How do I get one?  \nIf you look up the course on https://usfweb.usf.edu/DSS/StaffScheduleSearch\n(https://usfweb.usf.edu/DSS/StaffScheduleSearch) , you will see link in the description of the course.  Click that""]",nan,multi_context,"[{'source': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/MS-BAIS Advising FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How to improve retriever output alignment with LLM preferences in RAG pipeline?,"[' using an\nencoder-decoder architecture. This is achieved by identifying\nthe LM’s preferred documents through FiD cross-attention\nscores. Subsequently, the retriever undergoes fine-tuning\nwith hard negative sampling and standard cross-entropy loss.\nUltimately, the refined retriever can be directly applied to en-\nhance unseen target LMs, resulting in improved performance\nin the target task. Additionally, it is suggested that LLMs\nmay have a preference for focusing on readable rather than\ninformation-rich documents.\nREPLUG [Shiet al. , 2023 ]utilizes a retriever and an LLM\nto calculate the probability distributions of the retrieved doc-\numents and then performs supervised training by computing\nthe KL divergence. This straightforward and effective train-\ning method enhances the performance of the retrieval model\nby using an LM as the supervisory signal, eliminating the\nneed for specific cross-attention mechanisms.\nUPRISE [Cheng et al. , 2023a ]also employs frozen LLMs\nto fine-tune the prompt retriever. Both the LLM and the re-\ntriever take prompt-input pairs as inputs and utilize the scores\nprovided by the LLM to supervise the retriever’s training, ef-\nfectively treating the LLM as a dataset labeler. In addition,\nAtlas [Izacard et al. , 2022 ]proposes four methods of super-\nvised fine-tuning embedding models:\n•Attention Distillation . This approach employs cross-\nattention scores generated by the LLM during output to\ndistill the model’s knowledge.\n•EMDR2 . By using the Expectation-Maximization algo-\nrithm, this method trains the model with retrieved docu-\nments as latent variables.\n•Perplexity Distillation directly trains the model using the\nperplexity of generated tokens as an indicator.', 'While these methods improve semantic representation\nby incorporating domain knowledge and task-specific fine-\ntuning, retrievers may not always exhibit optimal compatibil-\nity with certain LLMs. To address this, some researchers have\nexplored direct supervision of the fine-tuning process using\nfeedback from LLMs. This direct supervision seeks to align\nthe retriever more closely with the LLM, thereby improving\nperformance on downstream tasks. A more comprehensive\ndiscussion on this topic is presented in Section 4.3.\n4.2 Aligning Queries and Documents\nIn the context of RAG applications, retrievers may utilize\na single embedding model for encoding both the query and\nthe documents, or employ separate models for each. Addi-\ntionally, the user’s original query may suffer from imprecise\nphrasing and lack of semantic information. Therefore, it is\ncrucial to align the semantic space of the user’s query with\nthose of the documents. This section introduces two funda-\nmental techniques aimed at achieving this alignment.\nQuery Rewriting\nQuery rewriting is a fundamental approach for aligning\nthe semantics of a query and a document. Methods\nsuch as Query2Doc and ITER-RETGEN leverage LLMs\nto create a pseudo-document by combining the origi-\nnal query with additional guidance [Wang et al. , 2023c,\nShao et al. , 2023 ]. HyDE constructs query vectors using\ntextual cues to generate a “hypothetical” document captur-\ning essential patterns [Gao et al. , 2022 ]. RRR introduces a\nframework that reverses the traditional retrieval and read-\ning order, focusing on query rewriting [Maet al. , 2023a ].\nSTEP-BACKPROMPTING enables LLMs to perform ab-\nstract reasoning and retrieval based on high-level con-\ncepts [Zheng et al. , 2023 ]. Additionally, the multi-query re-\ntrieval method utilizes LLMs to generate and execute multiple\nsearch queries simultaneously, advantageous for addressing\ncomplex problems with multiple sub-problems.\nEmbedding Transformation\nBeyond broad strategies such as query rewriting, there exist\nmore granular techniques specifically designed for embed-\nding transformations. LlamaIndex [Liu, 2023 ]exemplifies\nthis by introducing an adapter module that can be integrated\nfollowing the query encoder. This adapter facilitates fine-\ntuning, thereby optimizing the representation of query em-\nbeddings to map them into a latent space that is more closely\naligned with the intended tasks.\nThe challenge of aligning queries with structured exter-\nnal documents, particularly when addressing the incongruity\nbetween structured and unstructured data, is addressed by\nSANTA [Liet al. , 2023d ]. It enhances the retriever’s sen-\nsitivity to structured information through two pre-training\nstrategies: first, by leveraging the intrinsic alignment between\nstructured and unstructured data to inform contrastive learn-\ning in a structured-aware pre-training scheme; and second, by\nimplementing Masked Entity Prediction. The latter utilizes\nan entity-centric masking strategy that encourages language\nmodels to predict and fill in the masked entities, thereby fos-\ntering a deeper understanding of structured data.The issue of aligning queries with structured exter-\nnal documents, especially when dealing with the dispar-\nity between structured and unstructured data, is tackled by\nSANTA [Liet al. , 2023d ]. This approach improves the re-\ntriever’s ability to recognize structured information through\ntwo pre-training strategies: firstly, by utilizing the inher-\nent alignment between structured and unstructured data to\nguide contrastive learning in a structured-aware pre-training\nscheme; and secondly, by employing Masked Entity Predic-\ntion. The latter uses an entity-centric masking strategy to\nprompt language models to predict and complete the masked\nentities, thus promoting a more profound comprehension of\nstructured data.\n4.3 Aligning Retriever and LLM\nIn the RAG pipeline, enhancing retrieval hit rate through var-\nious techniques may not necessarily improve the final out-\ncome, as the retrieved documents may not align with the spe-\ncific requirements of the LLMs. Therefore, this section in-\ntroduces two methods aimed at aligning the retriever outputs\nwith the preferences of the LLMs.\nFine-tuning Retrievers\nSeveral studies utilize feedback signals from LLMs to refine\nretrieval models. For instance, AAR [Yuet al. , 2023b ]intro-\nduces supervisory signals for a pre-trained retriever']","This section introduces two methods aimed at aligning the retriever outputs with the preferences of the LLMs. One method is fine-tuning retrievers using feedback signals from LLMs to refine retrieval models. Another method is direct supervision of the fine-tuning process using feedback from LLMs to align the retriever more closely with the LLM, thereby improving performance on downstream tasks.",multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 8, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 8, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What happens if academic integrity is violated at USF and what actions are taken for different offenses?,"['Academic Integrity\nThe MS-BAIS program follow USF\'s of ficial policies on academic integrity , which are described in detail at\nhttps://www .usf.edu/undergrad/students/ethics-integrity .aspx\n(https://www.usf.edu/undergrad/students/ethics-integrity.aspx) . We encourage you to read through this page\nto familiarize yourself of our of ficial policy and consequences for violations. Students are routinely expelled\nfrom USF (without degree) every year for violations of our of ficial academic integrity policies. ""I did not know""\nor ""This is not considered plagiarism in the culture where I\'m from"" will not be considered an acceptable\nexcuse if you happen to be involved in any of these transgressions. \n \nWhat are violations of academic integrity?\nCheating : Cheating is using or attempting to use materials, information, notes, study aids, or other\nassistance in any assignment, group work, examination, or evaluation that have not been authorized by the\ninstructor .\nPlagiarism : Plagiarism is representing someone else\'s work as your own. For example, you download\nmaterials from the internet for your class project and did not cite or give credit to the original source where\nwe took the material from. Whether intentional or not, plagiarism is an of fense liable under USF academic\nintegrity policies.\n \nWhy is this a big deal?\nThe job of a university is not only to teach, but build responsible and productive members of our society . We\ndon\'t believe we can accomplish the second goal if we allow or overlook ethical transgressions in the\nconduct of our academic and extracurricular activities. W e understand that students don\'t start with an\nintention to cheat, but are forced to do so because of circumstances such as taking too many courses in one\nsemester , try to work full-time while also taking a full academic load, and trying to be perfect for their friends\nand family . These things can put a good person in a bad situation. Before soon, ""I would never cheat""\nbecomes ""W ell, just this once"" which turns into repeated instances of cheating. It is a slippery slope from\nwhere you can\'t get out. W e must intervene to arrest the moral and intellectual slide, and hence, we\nrigorously enforce our academic integrity policies.\n \nWhat are the consequences of academic integrity violations?\nFirst, both cheating and plagiarism have the same penalty and are cumulative throughout your stay at USF ,\nmeaning they accrue over your dif ferent classes with dif ferent professors. The USF of ficial policy for\ntransgressions can be found at https://usf.app.box.com/v/usfregulation3027\n(https://usf.app.box.com/v/usfregulation3027)\nIn general, we follow the following rules:\nFirst of fense:\nZero in the concerned assignment or exam.']","The consequences for violations of academic integrity at USF include receiving a zero on the concerned assignment or exam for a first offense. The penalties are cumulative throughout a student's stay at USF, meaning they accrue over different classes with different professors. More information on the official policy can be found at https://usf.app.box.com/v/usfregulation3027.",multi_context,"[{'source': 'data/pdfs/Academic Integrity_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Academic Integrity_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What are the requirements for a reduced course load in your last semester and its impact on CPT eligibility?,"['Reduced Course Loads\nInternational students will typically have to maintain a full-time course load of 9 credits.  The only exception is\nyour last semester .  In your last semester , you can take less than 9 credits.  However , in order to be able to\ndo so, you will have to complete a Reduced Course Load form.  Contact Of fice of International Services for\nDetails ( https://www .usf.edu/world/international-services/index.aspx\n(https://www.usf.edu/world/international-services/index.aspx) ).\nNOTE 1: At least one of the courses you take on an RCL  has to be either on-campus or hybrid.  If you want\nto take a second, it can be online.\nNOTE 2: Immigration requires you to take the majority of credits on your home campus, which is Tampa. \nYou therefore should be careful before you enroll in classes that are of fered on the St Pete or\nSarasota/Manatee campus.\nNOTE 3: An RCL  form can only be approved if you have met all program prerequisites that were assigned to\nyou when you were admitted to the program.  Obviously , if you received an email that you had met all\nprogram prerequisites, then this is not relevant.\nIf you decide to take a reduced course load, please only register for the course(s) you want to take.  Do not\nregister for any additional courses.  Doing so will lead to a delay in the approval of the RCL.\nWhen you complete the RCL  form, list muma-msbais@usf.edu  (mailto:muma-msbais@usf.edu) as the\napprover .\nIf, notwithstanding the previous paragraph, you enrolled for more than the course(s) you want to take, you\nwill have to send an email to muma-msbais@usf.edu  (mailto:muma-msbais@usf.edu) indicating which\ncourses you want to take in the last semester .  We will not be able to complete the RCL  form without that\ninformation. \nAlso, do not send us any emails asking him to approve your RCL.  He will do so within 48 hours of getting a\nrequest from Of fice of International Services to approve the RCL.\nA full-time CPT  internship counts as a full course load. So, if you have a full-time internship, you do not need\nan RCL.  \nAlso, once an RCL  has been approved, you cannot later register for an internship (CPT).\nThe deadline for submitting RCL  requests is the W ednesday of the first week of the semester .  This applies\neven if your classes start later in the semester .']","In the last semester, international students can take less than 9 credits as a reduced course load (RCL) but need to complete a Reduced Course Load form. At least one of the courses taken on an RCL has to be either on-campus or hybrid. Taking a full-time CPT internship counts as a full course load and does not require an RCL. Once an RCL has been approved, registering for an internship (CPT) is not allowed. The deadline for submitting RCL requests is the Wednesday of the first week of the semester.",multi_context,"[{'source': 'data/pdfs/Reduced Course Loads_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/Reduced Course Loads_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
"What components and aspects are used to assess RAG model quality, and what benchmarks and tools are available for evaluation?","['specific metrics [Hoshi et al. , 2023 ].\nDespite this, there is a notable paucity of research dedicated\nto evaluating the distinct characteristics of RAG models, with\nonly a handful of related studies.\nThe following section shifts the focus from task-specific\nevaluation methods and metrics to provide a synthesis of the\nexisting literature based on their unique attributes. This ex-\nploration covers the objectives of RAG evaluation, the aspects\nalong which these models are assessed, and the benchmarks\nand tools available for such evaluations. The aim is to offer a\ncomprehensive overview of RAG model evaluation, outlining\nthe methodologies that specifically address the unique aspects\nof these advanced generative systems.\n7.1 Evaluation Targets\nThe assessment of RAG models mainly revolves around two\nkey components: the retrieval and generation modules. This\ndivision ensures a thorough evaluation of both the quality of\ncontext provided and the quality of content produced.\nRetrieval Quality\nEvaluating the retrieval quality is crucial for determining the\neffectiveness of the context sourced by the retriever com-\nponent. Standard metrics from the domains of search en-\ngines, recommendation systems, and information retrieval\nsystems are employed to measure the performance of the\nRAG retrieval module. Metrics such as Hit Rate, MRR, and\nNDCG are commonly utilized for this purpose [Liu, 2023,\nNguyen, 2023 ].\nGeneration Quality\nThe assessment of generation quality centers on the gener-\nator’s capacity to synthesize coherent and relevant answers\nfrom the retrieved context. This evaluation can be catego-\nrized based on the content’s objectives: unlabeled and la-\nbeled content. For unlabeled content, the evaluation encom-\npasses the faithfulness, relevance, and non-harmfulness of the\ngenerated answers. In contrast, for labeled content, the fo-\ncus is on the accuracy of the information produced by the', 'Figure 6: RAG compared with other model optimization methods\nand avoiding contradictions.\nAnswer Relevance requires that the generated answers are\ndirectly pertinent to the posed questions, effectively address-\ning the core inquiry.\nRequired Abilities\nRAG evaluation also encompasses four abilities indicative of\nits adaptability and efficiency: noise robustness, negative re-\njection, information integration, and counterfactual robust-\nness [Chen et al. , 2023b, Liu et al. , 2023b ]. These abilities\nare critical for the model’s performance under various chal-\nlenges and complex scenarios, impacting the quality scores.\nNoise Robustness appraises the model’s capability to man-\nage noise documents that are question-related but lack sub-\nstantive information.\nNegative Rejection assesses the model’s discernment in re-\nfraining from responding when the retrieved documents do\nnot contain the necessary knowledge to answer a question.\nInformation Integration evaluates the model’s proficiency\nin synthesizing information from multiple documents to ad-\ndress complex questions.\nCounterfactual Robustness tests the model’s ability to rec-\nognize and disregard known inaccuracies within documents,\neven when instructed about potential misinformation.\nContext relevance and noise robustness are important for\nevaluating the quality of retrieval, while answer faithfulness,\nanswer relevance, negative rejection, information integration,\nand counterfactual robustness are important for evaluating thequality of generation.\nThe specific metrics for each evaluation aspect are summa-\nrized in Table 2. It is essential to recognize that these metrics,\nderived from related work, are traditional measures and do\nnot yet represent a mature or standardized approach for quan-\ntifying RAG evaluation aspects. Custom metrics tailored to\nthe nuances of RAG models, though not included here, have\nalso been developed in some evaluation studies.\n7.3 Evaluation Benchmarks and Tools\nThis section delineates the evaluation framework for RAG\nmodels, comprising benchmark tests and automated eval-\nuation tools. These instruments furnish quantitative met-\nrics that not only gauge RAG model performance but also\nenhance comprehension of the model’s capabilities across\nvarious evaluation aspects. Prominent benchmarks such as\nRGB and RECALL [Chen et al. , 2023b, Liu et al. , 2023b ]\nfocus on appraising the essential abilities of RAG mod-\nels. Concurrently, state-of-the-art automated tools like RA-\nGAS [Eset al. , 2023 ], ARES [Saad-Falcon et al. , 2023 ], and\nTruLens8employ LLMs to adjudicate the quality scores.\nThese tools and benchmarks collectively form a robust frame-\nwork for the systematic evaluation of RAG models, as sum-\nmarized in Table 3.\n8https://www.trulens.org/trulens eval/core concepts ragtriad/']","The components used to assess RAG model quality are retrieval quality and generation quality. The aspects evaluated for retrieval quality include Hit Rate, MRR, and NDCG. The aspects evaluated for generation quality include answer faithfulness, answer relevance, negative rejection, information integration, and counterfactual robustness. The benchmarks and tools available for evaluation include RGB, RECALL, RAGAS, ARES, and TruLens.",multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 15, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 17, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the stages and sources in the augmentation process of RAG models and how do they contribute to training the language model?,"[' and\nsemantic nuances. The initial phase focuses on the retriever,\nwhere contrastive learning is harnessed to refine the query\nand document embeddings.\nSubsequently, the generator’s preliminary training stage\nemploys contrastive learning to align the structured data with\nits unstructured document descriptions. In a further stage of\ngenerator training, the model acknowledges the critical role\nof entity semantics in the representation learning of textual\ndata for retrieval, as highlighted by [Sciavolino et al. , 2021,\nZhang et al. , 2019 ]. This process commences with the identi-\nfication of entities within the structured data, followed by the\napplication of masks over these entities within the generator’s\ninput data, thus setting the stage for the model to anticipate\nand predict these masked elements.\nThe training regimen progresses with the model learning\nto reconstruct the masked entities by leveraging contextual\ninformation. This exercise cultivates the model’s comprehen-\nsion of the textual data’s structural semantics and facilitates\nthe alignment of pertinent entities within the structured data.\nThe overarching optimization goal is to train the language\nmodel to accurately restore the obscured spans, thereby en-\nriching its understanding of entity semantics [Yeet al. , 2020 ].\n6 Augmentation in RAG\nThis section is structured around three key aspects: the aug-\nmentation stage, sources of augmentation data, and the aug-\nmentation process. These facets elucidate the critical tech-\nnologies pivotal to RAG’s development. A taxonomy of\nRAG’s core components is presented in Figure 4.\n6.1 RAG in Augmentation Stages\nRAG, a knowledge-intensive endeavor, incorporates a vari-\nety of technical methodologies across the pre-training, fine-\ntuning, and inference stages of language model training.\nPre-training Stage\nDuring the pre-training stage, researchers have investigated\nmethods to bolster PTMs for open-domain QA through', 'various question-answering tasks.\nIn essence, these inference-stage enhancements provide\nlightweight, cost-effective alternatives that leverage the ca-\npabilities of pre-trained models without necessitating further\ntraining. The principal advantage is maintaining static LLM\nparameters while supplying contextually relevant information\nto meet specific task demands. Nevertheless, this approach is\nnot without limitations, as it requires meticulous data pro-\ncessing and optimization, and is bound by the foundational\nmodel’s intrinsic capabilities. To address diverse task require-\nments effectively, this method is often paired with procedural\noptimization techniques such as step-wise reasoning, iterative\nretrieval, and adaptive retrieval strategies.\n6.2 Augmentation Source\nThe effectiveness of RAG models is heavily impacted by the\nselection of data sources for augmentation. Different levels of\nknowledge and dimensions require distinct processing tech-\nniques. They are categorized as unstructured data, structured\ndata, and content generated by LLMs. The technology tree\nof representative RAG research with different augmentation\naspects is depicted in Figure 5. The leaves, colored in three\ndifferent shades, represent enhancements using various types\nof data: unstructured data, structured data, and content gener-\nated by LLMs. The diagram clearly shows that initially, aug-\nmentation was mainly achieved through unstructured data,\nsuch as pure text. This approach later expanded to include\nthe use of structured data (e.g. knowledge graph) for further\nimprovement. More recently, there has been a growing trend\nin research that utilizes content generated by the LLMs them-\nselves for retrieval and augmentation purposes.\nAugmented with Unstructured Data\nUnstructured text, is gathered from corpora, such as prompt\ndata for fine-tuning large models [Cheng et al. , 2023a ]and\ncross-lingual data [Liet al. , 2023b ]. Retrieval units vary from\ntokens (e.g., kNN-LM [Khandelwal et al. , 2019 ]) to phrases\n(e.g., NPM, COG [Leeet al. , 2020, Lan et al. , 2022 ]) and\ndocument paragraphs, with finer granularities offering pre-\ncision at the cost of increased retrieval complexity.\nFLARE [Jiang et al. , 2023b ]introduces an active re-\ntrieval approach, triggered by the LM’s generation of low-\nprobability words. It creates a temporary sentence for doc-\nument retrieval, then regenerates the sentence with the re-\ntrieved context to predict subsequent sentences. RETRO uses\nthe previous chunk to retrieve the nearest neighbor at the\nchunk level, combined with the previous chunk’s context, it\nguides the generation of the next chunk. To preserve causal-\nity, the generation of the next block Cionly utilizes the near-\nest neighbor of the previous block N(Ci−1)and not N(Ci).\nAugmented with Structured Data\nStructured data, such as knowledge graphs (KGs), pro-\nvide high-quality context and mitigate model hallucina-\ntions. RET-LLMs [Modarressi et al. , 2023 ]constructs a\nknowledge graph memory from past dialogues for future ref-\nerence. SUGRE [Kang et al. , 2023 ]employs Graph Neu-\nral Networks (GNNs) to encode relevant KG subgraphs,\nensuring consistency between retrieved facts and gener-\nated text through multi-modal contrastive learning. Knowl-edGPT [Wang et al. , 2023d ]generates KB search queries and\nstores knowledge in a personalized base, enhancing the RAG\nmodel’s knowledge richness and contextuality.\nLLMs-Generated Content in RAG\nAddressing the limitations of external auxiliary information\nin RAG, some research has focused on exploiting LLMs’ in-\nternal knowledge. SKR [Wang et al. , 2023e ]classifies ques-\ntions as known or unknown, applying retrieval enhancement\nselectively. GenRead [Yuet al. , 2022 ]replaces the retriever\nwith an LLM generator, finding that LLM-generated con-\ntexts often contain more accurate answers due to better align-\nment with the pre-training objectives of causal language mod-\neling. Selfmem [Cheng et al. , 2023b ]iteratively creates an\nunbounded memory pool with a retrieval-enhanced genera-\ntor, using a memory selector to choose outputs that serve as\ndual problems to the original question, thus self-enhancing\nthe generative model.\nThese methodologies']","The stages in the augmentation process of RAG models include the pre-training stage, fine-tuning stage, and inference stage. The sources of augmentation data include unstructured data, structured data (such as knowledge graphs), and content generated by LLMs. These stages and sources contribute to training the language model by providing contextually relevant information, improving retrieval and augmentation capabilities, enhancing knowledge richness and contextuality, and aligning with pre-training objectives of causal language modeling.",multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 10, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 13, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the criteria and resources for evaluating the RAG model?,"['Table 1: Comparison between RAG and Fine-Tuning\nFeature Comparison RAG Fine-Tuning\nKnowledge UpdatesDirectly updating the retrieval knowledge\nbase ensures that the information remains\ncurrent without the need for frequent retrain-\ning, making it well-suited for dynamic data\nenvironments.Stores static data, requiring retraining for\nknowledge and data updates.\nExternal KnowledgeProficient in leveraging external resources,\nparticularly suitable for accessing documents\nor other structured/unstructured databases.Can be utilized to align the externally ac-\nquired knowledge from pretraining with large\nlanguage models, but may be less practical\nfor frequently changing data sources.\nData ProcessingInvolves minimal data processing and han-\ndling.Depends on the creation of high-quality\ndatasets, and limited datasets may not result\nin significant performance improvements.\nModel CustomizationFocuses on information retrieval and inte-\ngrating external knowledge but may not fully\ncustomize model behavior or writing style.Allows adjustments of LLM behavior, writ-\ning style, or specific domain knowledge\nbased on specific tones or terms.\nInterpretabilityResponses can be traced back to specific data\nsources, providing higher interpretability and\ntraceability.Similar to a black box, it is not always clear\nwhy the model reacts a certain way, resulting\nin relatively lower interpretability.\nComputational ResourcesDepends on computational resources to sup-\nport retrieval strategies and technologies re-\nlated to databases. Additionally, it requires\nthe maintenance of external data source inte-\ngration and updates.The preparation and curation of high-quality\ntraining datasets, defining fine-tuning objec-\ntives, and providing corresponding computa-\ntional resources are necessary.\nLatency RequirementsInvolves data retrieval, which may lead to\nhigher latency.LLM after fine-tuning can respond without\nretrieval, resulting in lower latency.\nReducing HallucinationsInherently less prone to hallucinations as\neach answer is grounded in retrieved evi-\ndence.Can help reduce hallucinations by training\nthe model based on specific domain data but\nmay still exhibit hallucinations when faced\nwith unfamiliar input.\nEthical and Privacy IssuesEthical and privacy concerns arise from the\nstorage and retrieval of text from external\ndatabases.Ethical and privacy concerns may arise due\nto sensitive content in the training data.\nmodel [Liu, 2023 ]. Additionally, both retrieval and genera-\ntion quality assessments can be conducted through manual\nor automatic evaluation methods [Liu, 2023, Lan et al. , 2022,\nLeng et al. , 2023 ].\n7.2 Evaluation Aspects\nContemporary evaluation practices of RAG models empha-\nsize three primary quality scores and four essential abilities,\nwhich collectively inform the evaluation of the two principal\ntargets of the RAG model: retrieval and generation.\nQuality Scores\nQuality scores include context relevance, answer faith-\nfulness, and answer relevance. These quality scoresevaluate the efficiency of the RAG model from differ-\nent perspectives in the process of information retrieval\nand generation [Eset al. , 2023, Saad-Falcon et al. , 2023,\nJarvis and Allard, 2023 ]. The quality scores—context rele-\nvance, answer faithfulness, and answer relevance—assess the\nRAG model’s efficiency from various angles throughout the\ninformation retrieval and generation process [Eset al. , 2023,\nSaad-Falcon et al. , 2023, Jarvis and Allard, 2023 ].\nContext Relevance evaluates the precision and specificity\nof the retrieved context, ensuring relevance and minimizing\nprocessing costs associated with extraneous content.\nAnswer Faithfulness ensures that the generated answers re-\nmain true to the retrieved context, maintaining consistency']","Contemporary evaluation practices of RAG models emphasize three primary quality scores: context relevance, answer faithfulness, and answer relevance. These quality scores assess the efficiency of the RAG model from different perspectives in the process of information retrieval and generation. The criteria for evaluating the RAG model include precision and specificity of the retrieved context (context relevance) and consistency and accuracy of the generated answers (answer faithfulness). The evaluation resources can include manual or automatic evaluation methods.",multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 16, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What job opportunities are available for international students at USF after graduation and what work authorization is required?,"['O\x00ce of International Services/Student Employment/Hiring An International StudentStudent Employment\nOVERVIEW\nON-CAMPUS\nEMPLOYMENT\nOFF-CAMPUS\nEMPLOYMENT\nWORK AFTER\nGRADUATION\nSOCIAL SECURITY\nSEVERE ECONOMIC\nHARDSHIP\nSPECIAL STUDENT\nRELIEF (SSR)\nVOLUNTEERING\nHIRING AN\nINTERNATIONAL\nSTUDENTHIRING AN INTERNATIONAL STUDENT\nHIRING A USF INTERNATIONAL STUDENT TO\nWORK FOR\xa0USF\nBefore Graduation\nInternational students, with F-1 and J-1 visas, who are full-time\nenrolled are allowed to accept on campus employment for 20 hours\nper week during the regular semester. They can be employed on-\ncampus 40 hours per week during o\x00cial breaks, such as the winter\nbreak and summer.\nAfter Graduation\nUpon the date of graduation, F-1 and J-1 students may no longer work\nanywhere without special authorization. F-1 students must have a\nvalid Employment Authorization Document (EAD Card) and J-1\nstudents must have work authorization noted on page 1 of their DS-\n2019 to be eligible to work anywhere.\xa0\nHIRING AN INTERNATIONAL STUDENT FOR A JOB\nOUTSIDE\xa0USFOFFICE OF INTERNATIONAL\nSERVICES\nUSF WORLDGIVE NOW\nABOUT USINCOMING\nSTUDENTSIMMIGRATIONSTUDENT\nEMPLOYMENT\nSCHOLARSEMPLOYEESMyUSFDirectory UNIVERSITY OF SOUTH FLORIDA', 'O\x00ce of International Services/Student Employment/Work After GraduationStudent Employment\nOVERVIEW\nON-CAMPUS\nEMPLOYMENT\nOFF-CAMPUS\nEMPLOYMENT\nWORK AFTER\nGRADUATION\nSOCIAL SECURITY\nSEVERE ECONOMIC\nHARDSHIP\nSPECIAL STUDENT\nRELIEF (SSR)\nVOLUNTEERING\nHIRING AN\nINTERNATIONAL\nSTUDENTWORK AFTER GRADUATION\nF-1 STUDENTS\nIf you are an F-1 student\xa0who is graduating from your program of\nstudy, you are no longer eligible to work on or o\x00 campus as of\xa0your\ncommencement date unless you obtain permission. For F-1 students\nthis would be\xa0Post-Completion Optional Practical Training (OPT).\nYou can apply for OPT up to 90 days prior to commencement and 60\ndays after commencement. If you are in a STEM program you may beOFFICE OF INTERNATIONAL\nSERVICES\nUSF WORLDGIVE NOW\nABOUT USINCOMING\nSTUDENTSIMMIGRATIONSTUDENT\nEMPLOYMENT\nSCHOLARSEMPLOYEESMyUSFDirectory UNIVERSITY OF SOUTH FLORIDA']",nan,multi_context,"[{'source': 'data/pdfs/International Services _ Hiring An International Student.pdf', 'page': 0, 'filename': 'data/pdfs/International Services _ Hiring An International Student.pdf'}, {'source': 'data/pdfs/International Services _ Work After Graduation.pdf', 'page': 0, 'filename': 'data/pdfs/International Services _ Work After Graduation.pdf'}]",True
What is the recommended course sequence in the MS-BAIS program and what happens if it is not followed?,"['In addition, we strongly suggest that you take courses in a specific sequence.  Past experience has shown\nthat students who have not taken the courses in the suggested sequence are less successful.\nTake ISM 6124 Advanced Systems Analysis & Design  before you take ISM 6208 Data W arehousing . \nTake ISM 6225 Distributed Information Systems  before you take  ISM 6562 Big Data for Business\nApplications. \nTake QMB 6304 Analytical Methods for Business  before you take  ISM 6137 Statistical Data Mining . \nTake ISM 6136 Data Mining  before you take  ISM 6251 Data Science Programming  before you take ISM\n6564 T ext Analytics or ISM 6930 T echnical Foundations of AI\nNOTE 1: We have been a bit lax in enforcing prerequisites.  Starting in the Fall of 2023, we will strictly\nenforce prerequisites and remove students from courses if they have not met the prerequisites.\nNOTE 2 : With the increase in enrollment in the program, we cannot guarantee that we can of fer the core\ncourses (see next page) in every semester .  You should therefore take a core course whenever it is available\nand you are eligible to take it.  If you do not, you may not be able to graduate on time.\n \nElectives:\nWe have a wide range of departmental and non-departmental electives for you to choose from to enrich your\nlearning experience at USF . Note that you must complete 9 credits of departmental (BAIS) electives and\nanother 9 credits of BAIS and/or non-BAIS electives for your MS-BAIS degree. Non-departmental electives\nmust be pre-approved by Dr . Reichgelt before you register in those courses, and may require a permit from\nthe corresponding department. Departmental electives must satisfy prerequisites as described above.\nAny USF class may not count as ""electives"" for your 33-credit MS-BAIS degree. Classes that won\'t count\ninclude any undergraduate class, most 2 or 3-credit MBA  courses such as  ISM 6930 (Data Analytics for\nBusiness), QMB 6305, QMB 6358, QMB 6603, ISM 6021, ISM 6123, ISM 6436, ISM 6217, ISM 6565 and\nmany other Muma College of Business classes.\nAny classes out of our program MUST  be pre-approved by the SISM department before you can register for\nit and expect it to count toward your degree requirement. Contact Dr . Reichgelt ( muma-msbais@usf.edu\n(mailto:muma-msbais@usf.edu) ) for assistance with selecting electives to determine whether they will count\ntoward your degree.  The following non-BAIS course have already been pre-approved:\nEEL 6787: Data Networks, Systems and Security\n \nFIN 6406 Financial Management\nFIN 6246 The Financial System and FinT ech Innovation\nFIN 6416 Advanced Financial Management\nFIN 6455 Financial Modeling and Analytics\nFIN 6465 Financial Statement Analysis\nFIN 6515 Quantitative Investments\nFIN 6605 International Financial Management\nFIN 6778 Quantitative Analytics for Finance\nFIN 6779 FinT ech and Payment Technologies\n ']","We strongly suggest taking courses in a specific sequence. Past experience has shown that students who have not taken the courses in the suggested sequence are less successful. Starting in the Fall of 2023, prerequisites will be strictly enforced and students who have not met the prerequisites will be removed from courses. With the increase in enrollment, core courses may not be offered in every semester, so it is recommended to take a core course whenever it is available and eligible. Electives must be pre-approved and departmental electives must satisfy prerequisites. Any classes outside of the program must be pre-approved by the SISM department. Contact Dr. Reichgelt for assistance with selecting electives to determine if they will count towards the degree. The recommended course sequence is as follows: Take ISM 6124 Advanced Systems Analysis & Design before ISM 6208 Data Warehousing. Take ISM 6225 Distributed Information Systems before ISM 6562 Big Data for Business Applications. Take QMB 6304 Analytical Methods for Business before ISM 6137 Statistical Data Mining. Take ISM 6136 Data Mining before ISM 6251 Data Science Programming before ISM 6564 Text Analytics or ISM 6930 Technical Foundations of AI.",multi_context,"[{'source': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/Course Registration BAIS_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
How do retrieval-enhancing steps and aligning queries and documents contribute to contextually rich responses in the RAG process?,"[' of the process. This two-step re-\ntrieval method helps to strike a balance between efficiency\nand the delivery of contextually rich responses.\nStepBack-prompt approach encourages the LLM to move\naway from specific instances and engage in reasoning around\nbroader concepts and principles [Zheng et al. , 2023 ]. Experi-\nmental results demonstrate a significant performance increase\nin various challenging, inference-based tasks when backward\nprompts are used, highlighting their natural adaptability to the\nRAG process. These retrieval-enhancing steps can be applied\nboth in generating responses to backward prompts and in the\nfinal question-answering process.\nSub-Queries . Depending on the scenario, various query\nstrategies can be employed, such as using query engines\nprovided by frameworks like LlamaIndex, leveraging tree\nqueries, utilizing vector queries, or executing simple sequen-\ntial querying of chunks.\nHypothetical Document Embeddings . HyDE operates on\nthe belief that the answers generated might be closer in the\nembedding space than a direct query. Using the LLM, HyDE\ncreates a hypothetical document (answer) in response to a\nquery, embeds this document, and uses the resulting em-\nbedding to retrieve real documents similar to the hypotheti-\ncal one. Instead of seeking embedding similarity based on\nthe query, this approach focuses on the embedding similar-\nity from one answer to another [Gao et al. , 2022 ]. However,\nit might not consistently produce desirable outcomes, espe-\ncially when the language model is unfamiliar with the subject\nmatter, potentially leading to more instances with errors.\n4 Retrieval\nIn the context of RAG, it is crucial to efficiently retrieve rel-\nevant documents from the data source. However, creating a\nproficient retriever presents significant challenges. This sec-\ntionelves into three fundamental questions: 1) How can we\nachieve accurate semantic representations? 2) What methods', 'While these methods improve semantic representation\nby incorporating domain knowledge and task-specific fine-\ntuning, retrievers may not always exhibit optimal compatibil-\nity with certain LLMs. To address this, some researchers have\nexplored direct supervision of the fine-tuning process using\nfeedback from LLMs. This direct supervision seeks to align\nthe retriever more closely with the LLM, thereby improving\nperformance on downstream tasks. A more comprehensive\ndiscussion on this topic is presented in Section 4.3.\n4.2 Aligning Queries and Documents\nIn the context of RAG applications, retrievers may utilize\na single embedding model for encoding both the query and\nthe documents, or employ separate models for each. Addi-\ntionally, the user’s original query may suffer from imprecise\nphrasing and lack of semantic information. Therefore, it is\ncrucial to align the semantic space of the user’s query with\nthose of the documents. This section introduces two funda-\nmental techniques aimed at achieving this alignment.\nQuery Rewriting\nQuery rewriting is a fundamental approach for aligning\nthe semantics of a query and a document. Methods\nsuch as Query2Doc and ITER-RETGEN leverage LLMs\nto create a pseudo-document by combining the origi-\nnal query with additional guidance [Wang et al. , 2023c,\nShao et al. , 2023 ]. HyDE constructs query vectors using\ntextual cues to generate a “hypothetical” document captur-\ning essential patterns [Gao et al. , 2022 ]. RRR introduces a\nframework that reverses the traditional retrieval and read-\ning order, focusing on query rewriting [Maet al. , 2023a ].\nSTEP-BACKPROMPTING enables LLMs to perform ab-\nstract reasoning and retrieval based on high-level con-\ncepts [Zheng et al. , 2023 ]. Additionally, the multi-query re-\ntrieval method utilizes LLMs to generate and execute multiple\nsearch queries simultaneously, advantageous for addressing\ncomplex problems with multiple sub-problems.\nEmbedding Transformation\nBeyond broad strategies such as query rewriting, there exist\nmore granular techniques specifically designed for embed-\nding transformations. LlamaIndex [Liu, 2023 ]exemplifies\nthis by introducing an adapter module that can be integrated\nfollowing the query encoder. This adapter facilitates fine-\ntuning, thereby optimizing the representation of query em-\nbeddings to map them into a latent space that is more closely\naligned with the intended tasks.\nThe challenge of aligning queries with structured exter-\nnal documents, particularly when addressing the incongruity\nbetween structured and unstructured data, is addressed by\nSANTA [Liet al. , 2023d ]. It enhances the retriever’s sen-\nsitivity to structured information through two pre-training\nstrategies: first, by leveraging the intrinsic alignment between\nstructured and unstructured data to inform contrastive learn-\ning in a structured-aware pre-training scheme; and second, by\nimplementing Masked Entity Prediction. The latter utilizes\nan entity-centric masking strategy that encourages language\nmodels to predict and fill in the masked entities, thereby fos-\ntering a deeper understanding of structured data.The issue of aligning queries with structured exter-\nnal documents, especially when dealing with the dispar-\nity between structured and unstructured data, is tackled by\nSANTA [Liet al. , 2023d ]. This approach improves the re-\ntriever’s ability to recognize structured information through\ntwo pre-training strategies: firstly, by utilizing the inher-\nent alignment between structured and unstructured data to\nguide contrastive learning in a structured-aware pre-training\nscheme; and secondly, by employing Masked Entity Predic-\ntion. The latter uses an entity-centric masking strategy to\nprompt language models to predict and complete the masked\nentities, thus promoting a more profound comprehension of\nstructured data.\n4.3 Aligning Retriever and LLM\nIn the RAG pipeline, enhancing retrieval hit rate through var-\nious techniques may not necessarily improve the final out-\ncome, as the retrieved documents may not align with the spe-\ncific requirements of the LLMs. Therefore, this section in-\ntroduces two methods aimed at aligning the retriever outputs\nwith the preferences of the LLMs.\nFine-tuning Retrievers\nSeveral studies utilize feedback signals from LLMs to refine\nretrieval models. For instance, AAR [Yuet al. , 2023b ]intro-\nduces supervisory signals for a pre-trained retriever']","Retrieval-enhancing steps and aligning queries and documents contribute to contextually rich responses in the RAG process by improving semantic representation, aligning the semantic space of queries and documents, and aligning the retriever outputs with the preferences of the LLMs. These steps help to achieve accurate semantic representations, improve compatibility between retrievers and LLMs, and enhance the alignment between queries and documents. This ultimately leads to more efficient retrieval of relevant documents and the delivery of contextually rich responses.",multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 6, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 8, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What are the enrollment requirements for internships in a given semester?,"['CPT Internship F AQ\n1. How can I find an internship?\nUSF is using Handshake to help students find internships and full-time positions.  \nTo register and search openings go to https://usf.joinhandshake.com/login\n(https://usf.joinhandshake.com/login)  (https://usf.joinhandshake.com/login)\nSample search terms to use: Information systems, business analytics, data analytics, data science,\nprogramming, tech support, etc. \nFor help on using the system,  you can go to https://support.joinhandshake.com/hc/en-us\n(https://support.joinhandshake.com/hc/en-us) .  \n \n2. Can I do an internship in any semester (Summer , Fall, and Spring)?\nYes, as long as you meet the requirements of the internship (minimum two semesters of prior full-time\ncoursework, have a minimum GP A of 3.0, course prerequisites, etc.) and your internship is approved by us.\nFurthermore, your internship may be full-time or part-time, and you can do it for a maximum of 364 days.\n \n3. If I\'m working for a company and am paid by the company , why do I need USF\'s authorization to do\na CPT internship and why am I paying USF for a 1-credit class for the internship?\nInternational students on F1 student visa are NOT  allowed to work of f-campus (or even on-campus for more\nthan 20 hours/week) as a condition of your F1 visa. The only way in which you can work for an employer is if\nwe (USF) authorize that this ""work"" is related to the learning process (practical training) for which you are\nenrolled at USF . We must demonstrate to USCIS that your ""work"" is relevant to our curriculum. Hence,\ninternships are considered to be practicuum courses (ISM 6945), and you will have to register and pay for\nthis 1-credit internship course before you can join the internship, and submit a report at the end of the\nsemester to receive a grade for that course. Since USF courses are structured on a semester basis, if your\ninternship spans two semesters, you have to register separately and pay tuition for each of the two\nsemesters for which you are doing the internship.\n \n4. Can I change my CPT employer after accepting a prior of fer from a dif ferent employer?\nNo. iStart does not allow that. It also inconveniences the employer , brings disrepute to our university , and\nhurts our chances of securing internships for future students. If you do not like the terms or pay of your first\nCPT employer , do not accept their of fer and wait for the next employer . But you are not allowed to play\ngames like accept one of fer and ask for a change when you get a better of fer, or try to negotiate a better\npaying of fer by using one CPT  employer against another . If such situations come to light, we may penalize\nyou by not approving any of your CPT  applications for that semester and/or by revoking a previously\napproved CPT  application. A CPT  internship is NOT  a job that you can flip as often as you want. It is a\ncourse and if you want an internship, then you must respect the rules and meet the obligations of the course.', ""A CPT  internship is a privilege provided to international students by USCIS, and we will not allow any abuse\nof this privilege.\n \n5. Can I do a CPT internship and also do an on-campus job in the same semester?\nCurrent immigration interpretation by the Student Exchange V isitor Program (SEVP) does not address\nconcurrent CPT  and on-campus employment. But USF Of fice of International Services recommends that\nstudents who engage in concurrent CPT  and on-campus employment limit the total employment to 20\nhours/week during Fall and Spring . In light of this recommendation, we will not approve of concurrent CPT\nand on-campus employment during Fall or Spring semesters for a total of more than 20 hours/week. If a\nsituation comes to light where a student is doing 20 hours or more of internship and also doing an on-\ncampus job anywhere on USF campus, we will pull the student's internship for that semester and give that\nstudent an U grade for the internship course for violating our internship policies.\n \n6. Can I do a full-time (40-hour/week) internship and also register for classes at the same time?\nYes, you can, but in such cases, we made a decision to limit course enrollment to a maximum of 2 additional\n3-credit courses.  Note that you must register for at least 2 credits during Fall or Spring semesters, even with\na full-time internship, in order to maintain part-time student status.\n \n7. How many credit hours of coursework do I have to register for if I'm doing internship in a given\nsemester?\nThis depends on the semester and the number of hours per week of internship. If it is a summer semester ,\nyou do not have to register for any courses except the 1-credit internship course, irrespective of whether the\ninternship is full-time or part-time. In Fall or Spring semesters, if you are doing a part-time internship, then\nyou have to maintain full-time student status by registering for at least 9 credit hours of graduate classes. If\nyou are doing a full-time internship in a Fall or Spring semester , the full-time internship is viewed as\nequivalent of full-time, on-campus enrollment, but you still have to maintain part-time student status, which\nmeans at least 2 credits of enrollment that semester (including the 1-credit internship course). Note that both\nfull-time and part-time internships are 1 credit per semester . \n \n8. I registered for classes full-time (9 credit hours or more) and later on during the semester , I got an\ninternship of fer. The employer gave me a joining date in the middle of the semester . Can I join this\ninternship?\nIf you have a full-time course load, you cannot do a full-time internship (more than 20 hours) during that\nsemester .  In such case, you will have to inform your employer that your internship will be a maximum of 20\nhours, and your of fer letter must state that.  The only exception is if you were registered for 3 courses, and\none of the three courses runs over the first half of the semester so that you have completed it by the time the\ninternship starts.  In that case, we will allow you to do a full-time internship.\n \n9. Why was my internship application declined by the MS-BAIS director?"", ""time. During this time, we will not allow you to be distracted by internships, GA/T A-ship, or other activities.\nNOTE: If you are an international students, and you have completed all the requirements for the program,\nyou cannot apply for an internship unless you also register for another course.  In other words, you cannot\npostpone your graduation by enrolling for an internship alone.\n \nWhat are the rules and restrictions on doing CPT internships? \nInternships may be full-time or part-time. You are allowed to do full-time or part-time internships for a\nmaximum of 364 days . Exceeding this limit will disqualify you from participating in the  Optional Practical\nTraining (OPT) upon completion of your degree. If you are an international student, you will need those 18\nmonths of OPT  to transition from the F1 student visa to a H1B worker's visa. You are therefore allowed a\nmaximum of 3 credits for CPT  internships.\nFor both full-time and part-time internships, you will have to register for the ISM 6945 (BAIS Internship)\ncourse for each semester that you do the internship, and demonstrate what curriculum-related knowledge\nyou acquired from the internship. Because all USF courses (including ISM 6945) are organized by\nsemesters, if you are doing an internship that starts in say July (Summer) and ends in September (Fall), then\nyou will need to register for ISM 6945 twice: for Summer and then again for Fall, for this internship, and this\ninternship will consume two of the three credit hours allowed for internships. You can use the same of fer\nletter for both internship applications, but the application for each semester must be submitted and\nprocessed separately .\nCPT internship positions must be for at least 8 weeks . If you have a Summer internship that is say 6 weeks\nlong, we will approve it only if it is also part of a Fall internship that is also at least 6 weeks in length. In this\ncase, you must fill out two internship applications, for the Summer and Fall semesters, and take a 1 credit\nclass in each semester .  \nWe allow some flexibility in your start and end dates for internships. You can start your internship up to two\nweeks before  the semester , as long as these dates don't overlap with a prior term, and end it up to two\nweeks after  the end of the semester , except in your graduating (last) semester at USF . In your final\n(graduating) semester , your internship must be completed by the of ficial end of that semester .\nYou are not allowed to do an internship and hold a GA  position in the same semester . You have to choose\nwhether you want the internship or the GA  position. W e do not want to recruit you as a GA  is you cannot\ndemonstrate your commitment to the GA  position and will quit it the moment you get a more lucrative\ninternship. W e will not approve your internship request once you are on USF payroll for your GA  job.\nYou are also not allowed to do a full-time internship, independent study , and register for classes (online or in-\nperson) in the same semester . This is to ensure that you spend adequate time and do a good job in\nwhatever you registered in for that semester .\n \nWhat are the course enrollment requirements for doing full-time or part-time internships in a given\nsemester?\nThe course enrollment requirements vary based on whether you are doing a full-time or part-time internship,\nand whether you are doing this internship in Fall, Spring, or Summer semesters.""]","The course enrollment requirements vary based on whether you are doing a full-time or part-time internship, and whether you are doing this internship in Fall, Spring, or Summer semesters.",multi_context,"[{'source': 'data/pdfs/CPT Internship FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 0, 'filename': 'data/pdfs/CPT Internship FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}, {'source': 'data/pdfs/CPT Internship FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/CPT Internship FAQ_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}, {'source': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf', 'page': 1, 'filename': 'data/pdfs/CPT Internships_ ORG04655 _ MS-BAIS_AIBA Current Students.pdf'}]",True
What is the term for combining RAG with fine-tuning and what are the associated challenges?,"['Table 2: Summary of metrics applicable for evaluation aspects of RAG\nContext\nRelevanceFaithfulnessAnswer\nRelevanceNoise\nRobustnessNegative\nRejectionInformation\nIntegrationCounterfactual\nRobustness\nAccuracy ✓ ✓ ✓ ✓ ✓ ✓ ✓\nEM ✓\nRecall ✓\nPrecision ✓ ✓\nR-Rate ✓\nCosine Similarity ✓\nHit Rate ✓\nMRR ✓\nNDCG ✓\nTable 3: Summary of evaluation frameworks\nEvaluation Framework Evaluation Targets Evaluation Aspects Quantitative Metrics\nRGB† Retrieval Quality\nGeneration QualityNoise Robustness\nNegative Rejection\nInformation Integration\nCounterfactual RobustnessAccuracy\nEM\nAccuracy\nAccuracy\nRECALL†Generation Quality Counterfactual Robustness R-Rate (Reappearance Rate)\nRAGAS‡ Retrieval Quality\nGeneration QualityContext Relevance\nFaithfulness\nAnswer Relevance*\n*\nCosine Similarity\nARES‡ Retrieval Quality\nGeneration QualityContext Relevance\nFaithfulness\nAnswer RelevanceAccuracy\nAccuracy\nAccuracy\nTruLens‡ Retrieval Quality\nGeneration QualityContext Relevance\nFaithfulness\nAnswer Relevance*\n*\n*\n† represents a benchmark, and ‡ represents a tool. * denotes customized quantitative metrics, which deviate from traditional\nmetrics. Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these\nmetrics, as required.\n8 Future Prospects\nThis section explores three future prospects for RAG: future\nchallenges, modality expansion, and the RAG ecosystem.\n8.1 Future Challenges of RAG\nDespite the considerable progress in RAG technology, several\nchallenges persist that warrant in-depth research:\nContext Length . RAG’s efficacy is limited by the context\nwindow size of Large Language Models (LLMs). Balancing\nthe trade-off between a window that is too short, risking insuf-\nficient information, and one that is too long, risking informa-\ntion dilution, is crucial. With ongoing efforts to expand LLM\ncontext windows to virtually unlimited sizes, the adaptation\nof RAG to these changes presents a significant research ques-\ntion[Xuet al. , 2023c, Packer et al. , 2023, Xiao et al. , 2023 ].\nRobustness . The presence of noise or contradictory infor-\nmation during retrieval can detrimentally affect RAG’s out-put quality. This situation is figuratively referred to as “Mis-\ninformation can be worse than no information at all”. Im-\nproving RAG’s resistance to such adversarial or counterfac-\ntual inputs is gaining research momentum and has become a\nkey performance metric [Yuet al. , 2023a, Glass et al. , 2021,\nBaek et al. , 2023 ].\nHybrid Approaches (RAG+FT) . Combining RAG with\nfine-tuning is emerging as a leading strategy. Determining the\noptimal integration of RAG and fine-tuning whether sequen-\ntial, alternating, or through end-to-end joint training—and\nhow to harness both parameterized and non-parameterized\nadvantages are areas ripe for exploration [Linet al. , 2023 ].\nExpanding LLM Roles . Beyond generating final answers,\nLLMs are leveraged for retrieval and evaluation within RAG\nframeworks. Identifying ways to further unlock LLMs poten-\ntial in RAG systems is a growing research direction.\nScaling Laws . While scaling laws [Kaplan et al. , 2020 ]are\nestablished for LLMs, their applicability to RAG remains un-']","The term for combining RAG with fine-tuning is Hybrid Approaches (RAG+FT). The associated challenges include determining the optimal integration of RAG and fine-tuning, exploring different strategies such as sequential, alternating, or end-to-end joint training, and harnessing the advantages of both parameterized and non-parameterized approaches.",multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 18, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What topics are covered in the Sprintax webinars for international students and scholars about U.S. tax requirements?,"['The O\x00ce of International Services created a video called\nUnderstanding Taxes for International Students and Scholars. This\nvideo is meant for students and scholars who are completing taxes in\nthe United States for the \x00rst time, and covers general FAQ as well as\na brief Sprintax tutorial.\nSprintax Software Assistance Sessions (In-Person)\nOnce tax season has begun, the O\x00ce of International Services also\nhosts Sprintax Software Assistance Sessions multiple times a week to\nassist international students and scholars with utilizing the Sprintax\nNon-Resident Tax Prep tool. Sta\x00 will be available to help with\ninterpreting your immigration documents, clarifying instructions, and\nproviding a brief Sprintax tutorial.\nAssistance sessions for Spring 2024 (2023 tax year) will be o\x00ered in\nperson in BEH 255\xa0 February through April 2024 on the following days\nand times:\nTuesdays @ 2 pm to 4 pm in BEH 255\nFridays @ 10 am to 12 pm in BEH 255\nSprintax Webinars (Online)\nIf you would prefer to learn directly from the non-resident tax\nprofessionals at Sprintax, they are o\x00ering several webinars for\ninternational students and scholars throughout the tax season. These\nsessions are free to you, but you must RSVP at the links below. Topics\nto be covered include: an overview of taxes for nonresident students\nand scholars, who must \x00le a 2023 U.S. tax return, what income forms\nstudents/scholars may receive, forms that need to be completed and\nsent to the IRS, terms like FICA, ITIN and Form 1098-T, what happens if\nstudents don’t \x00le or mis\x00le, state tax returns, IRS stimulus payments,Tax Ov erview for International Students & Scholars Tax Ov erview for International Students & Scholars', 'any).\nWith U.S. Income: Sprintax will generate your ""tax return\ndocuments"", including either a 1040NR-EZ or a longer form\n1040NR, depending on your circumstances.\n4)\xa0 \xa0 \xa0 If required, complete your state tax return\xa0(with U.S. income\nonly)\xa0\nAfter you \x00nish your federal return, Sprintax will inform you if\nyou need to complete a state tax return. This will only apply to\nyou if you earned income in a state with an income tax in 2023;\nthe State of Florida has no state income tax . If this page applies\nto you, they will give you the option to use Sprintax for an\nindividual fee. However, it is your choice to use them or to do\nthe state tax return on your own.\n5)\xa0\xa0\xa0\xa0\xa0 Mail your completed federal and/or state forms to IRS\nand/or state tax authorities\nRemember to read the mailing instructions that Sprintax\nprovides. If you have dependents, each one must mail their\n8843 in a separate envelope.\nNeed Sprintax Support?\nIf you need help while using Sprintax, contact them:\n24/7 Live Chat Help\nRefer to their FAQs\nEmail at hello@sprintax.com\nSprintax Educational Tax Videos and Blog:\nYou also have access to the Sprintax YouTube account where there\nare a number of educational videos on\xa0Non-Resident taxes to provide\nfurther clarity on the subject of using Sprintax and Non-Resident\nTaxes. There is also a Sprintax Blog which go through tax-related\ntopics and can be of use to you.\nTax Resources at USF\nUnderstanding Tax Requirements in the U.S. for International\nStudents and Scholars']","The topics covered in the Sprintax webinars for international students and scholars about U.S. tax requirements include an overview of taxes for nonresident students and scholars, who must file a 2023 U.S. tax return, what income forms students/scholars may receive, forms that need to be completed and sent to the IRS, terms like FICA, ITIN and Form 1098-T, what happens if students don’t file or misfile, state tax returns, IRS stimulus payments, and any other tax-related topics that may be of use to international students and scholars.",multi_context,"[{'source': 'data/pdfs/International Services _ Taxes.pdf', 'page': 3, 'filename': 'data/pdfs/International Services _ Taxes.pdf'}, {'source': 'data/pdfs/International Services _ Taxes.pdf', 'page': 2, 'filename': 'data/pdfs/International Services _ Taxes.pdf'}]",True
What opportunities are there for students in the Master of Business Analytics and Information Systems program to gain practical experience and stay updated with industry trends and technologies?,"[' emerging tools and methodologies.""\n\nCollaboration and Teamwork\n\nQ01: ""What opportunities are there for teamwork and collaboration within the program?""\n\nA01: ""Teamwork is a cornerstone of our program. Students frequently work in teams on projects, presentations, and case competitions, mirroring the collaborative nature of the business analytics field. This fosters a community of learning and mutual support among students.""\n\nQ02: ""Can students collaborate with faculty on research projects?""\n\nA02: ""Absolutely. Our faculty members are actively involved in research, and we encourage students to collaborate on research projects. This can be an excellent way to deepen your knowledge in a specific area, contribute to the field, and co-author publications.""\n\n\n\nBalancing Work and Study\n\nQ01: ""Is it feasible to work part-time while enrolled in the program?""\n\nA01: ""While the program is rigorous, many students successfully balance part-time work, especially in roles related to their field of study. Time management and communication with your employers and professors are key to maintaining this balance.""\n\nQ02: ""Are there flexible learning options for working professionals?""\n\nA02: ""We understand the needs of working professionals and offer flexible learning options, including evening classes, online coursework, and part-time enrollment options. This allows students to advance their education without pausing their careers.""\n\nCultural and Social Integration\n\nQ01: ""How does the program foster a multicultural and inclusive environment?""\n\nA01: ""Diversity is at the heart of our program. We host cultural awareness workshops, international student forums, and social events that celebrate the diverse backgrounds of our student body. Our aim is to create an inclusive environment where every student feels valued and integrated.""\n\nQ02: ""What social activities are available to students in the program?""\n\nA02: ""Our program offers a variety of social activities, including welcome receptions, group outings, cultural nights, and sports events. These activities are great for relaxation, networking, and forming lasting friendships.""\n\nContinuous Learning and Development\n\nQ01: ""How does the program support continuous learning and professional development after graduation?""\n\nA01: ""Our commitment to our students extends beyond graduation. We offer alumni access to continued learning opportunities through webinars, online courses, and workshops. Our career services also remain available to support professional growth and job transitions.""\n\nQ02: ""Are there resources for entrepreneurial students interested in starting their own ventures?""\n\nA02: ""Yes, entrepreneurial students will find a wealth of resources, including business plan competitions, startup incubators, and mentorship from faculty and alumni entrepreneurs. We encourage and support students in turning innovative ideas into successful business ventures.""', ' global community that provides a platform for networking, mentorship, and professional growth. As a graduate, you\'ll have access to alumni events, webinars, and other resources to stay connected with your peers and the institution.""\n\nTechnical Requirements and Resources\n\nQ01: ""What are the computing requirements for the program?""\n\nA01: ""Our program requires students to have a laptop with specific hardware configurations to handle data analytics and business intelligence software efficiently. Recommended specifications include a modern multi-core processor, at least 16GB of RAM, and a solid-state drive (SSD). Detailed requirements are available on our program\'s website.""\n\nQ02: ""Are there any software licenses provided for students in this program?""\n\nA02: ""Yes, enrolled students receive access to various professional software tools and platforms necessary for coursework, including statistical analysis, data visualization, and business intelligence software, at no additional cost. This is part of our commitment to ensure students have the necessary resources for their studies.""\n\nAdjusting to a New Environment\n\nQ01: ""How does the university assist international students in adjusting to life in a new country?""\n\n\n\nA01: ""Our international student office offers a range of services designed to help you adjust, including cultural orientation sessions, social events, and workshops on local customs and lifestyle. We also have student mentors who can provide guidance and support as you navigate your new surroundings.""\n\nQ02: ""What kind of health services are available on campus?""\n\nA02: ""Our campus health center provides a range of medical services, including general consultations, mental health support, and emergency care. We also offer health insurance plans suitable for international students, ensuring you have access to comprehensive healthcare during your stay.""\n\nProgram Structure and Content\n\nQ01: ""Can students customize their curriculum within the Master\'s program?""\n\nA01: ""Absolutely. While there are core courses that all students must complete, our program offers elective courses allowing you to tailor your studies to your interests and career goals. Additionally, students can engage in independent study projects or research under faculty supervision for a more customized academic experience.""\n\nQ02: ""Is there an opportunity to study abroad or participate in international projects?""\n\nA02: ""Yes, our program includes opportunities for international study and collaboration through exchange programs, global consulting projects, and internships. These experiences are designed to enhance your global perspective and understanding of international business practices.""\n\nNetworking and Professional Development\n\nQ01: ""How does the program facilitate networking opportunities with industry professionals?""\n\nA01: ""Our program hosts regular networking events, guest lectures, and industry panels featuring alumni and professionals from the fields of business analytics and information systems. These events are excellent opportunities to build connections, gain insights into industry trends, and explore potential career paths.""\n\nQ02: ""Does the university offer career fairs or recruitment events for business analytics students?""\n\nA02: ""Yes, we organize career fairs and recruitment events specifically tailored to business analytics and information systems students. These events attract top employers in the industry looking to hire for internships and full-time positions. We also provide support in preparing for these events, including resume reviews and interview coaching.""\n\nSupport Systems\n\nQ01: ""What kind of academic support is available for students who may struggle with advanced coursework?""\n\n\n\nA01: ""We provide a comprehensive academic support system that includes tutoring services, study groups, and workshops on advanced topics in business analytics and information systems. Faculty members are also available for office hours to provide additional assistance and guidance.""\n\nQ02: ""Are there any mentorship programs available for new students?""\n\nA02: ""Yes, we offer a mentorship program that pairs new students with upperclassmen or alumni who can provide guidance, share their experiences, and offer advice on navigating both the academic and social aspects of the program. This program is designed to help new students transition smoothly into their graduate studies.""\n\nCertainly, Dr. Smith. Further expanding the range of inquiries, the following set of questions and answers delves into more specific and practical aspects that students might consider when applying for and participating in a Master of Business Analytics and Information Systems program.\n\nPractical Experience and Application\n\nQ01: ""Are there opportunities for practical experience within the program?""\n\nA01: ""Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience.""\n\nQ02: ""How does the program incorporate the latest industry trends and technologies?""\n\nA02: ""Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on']","Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience. Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on emerging tools and methodologies.",multi_context,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}, {'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
What are the CPT requirements and how to apply?,"[""BACK TO OIS HOME Please watch this overview presentation of CPT, its regulations, and\nthe application process.\nCPT ELIGIBILITY REQUIREMENTS\nTo be eligible for CPT, the following must be met:\nStudent must be in valid F-1 status.\nStudent must be enrolled in a Bachelor's, Master's, or Doctoral\ndegree program.\nStudent must have been enrolled for one academic year in a\ncurrent degree program at USF. Academic year is de\x00ned as a fall\nand spring semester (Summer not included). Time in Academic\nEnglish or Pathway programs does not count towards this\nrequirement.\nStudent must be making normal progress toward degree\ncompletion.\nCurricular Practical Training must be an integral part of the\nstudent’s degree program.\nStudent must have applied for and received a work authorization\non their I-20 prior to starting CPT.\nCPT COURSE REQUIREMENTS\nYour CPT course must be credit-bearing – Minimum of 1 credit. The\nnumber of credit hours for the CPT-related course is determined by\nthe department and o\x00cial course catalog.\xa0\nExamples of Courses acceptable for CPT Authorization:\nInternship course\nCooperative education course\nPracticum or \x00eld experience courseCPT  Overview CPT  Overview"", ""Dissertation or thesis course if the CPT experience is integral to\nthe student's research\nHOW TO APPLY\n1. View the CPT Presentation.\n2. Meet with graduate coordinator, academic advisor, or Center for\nCareer & Professional Development advisor to discuss their\nrequirements.\n3. Obtain an internship/job o\x00er letter (see section Job O\x00er Letter\nbelow for list of requirements and to view a sample letter).\n4. Login to iStart.usf.edu\na. Start the CPT Application located under F-1 Practical Training -\nApply. (Note: The CPT Application is only visible to current F-1\nstudents).\nb. View the CPT “How to Apply for CPT” video.\nc. Pass the CPT quiz.\nd. Upload the CPT Job O\x00er Letter that meets all requirements.\ne. After OIS approves the letter, submit the Academic Validation\nE-Form.\n1. While \x00lling out the Academic Validation E-Form, you will\nneed to upload proof that your internship, practicum, \x00eld\nexperience, etc. is an integral part of your curriculum. Each\ncategory of CPT requires a di\x00erent type of proof Please\nreview this document to see the examples of proof.\xa0\n5. Register for an appropriate CPT related course.\n6. Academic Advisor or Graduate Coordinator receives automatic\nemail and con\x00rms academic nature of work experience.\xa0\n7. When the CPT request is approved, a new I-20 with CPT\nauthorization is produced. OIS will send an e-mail to the student's\nUSF e-mail address with the CPT approved I-20 attached. (Note:\nOIS will process the CPT authorization within 10 business days\nafter the academic department approves the CPT.)\n8. Receive e-mail from OIS and a new I-20 with CPT authorization.\n9. Start employment only after receiving the I-20 with CPT\nauthorization and on or after the CPT start date listed on page\ntwo of your I-20.\nDo NOT start your CPT until you have obtained the CPT I-20 from\nthe O\x00ce of International Services and not before the CPT start\ndate.\nPlease watch the following step-by-step video for applying for CPT.\xa0""]","To be eligible for CPT, the student must be in valid F-1 status, enrolled in a Bachelor's, Master's, or Doctoral degree program, have been enrolled for one academic year in a current degree program at USF, be making normal progress toward degree completion, and have applied for and received work authorization on their I-20 prior to starting CPT. The CPT course must be credit-bearing, and the student must obtain an internship/job offer letter, pass the CPT quiz, and submit the Academic Validation E-Form. The CPT request is approved by the academic department, and a new I-20 with CPT authorization is produced.",multi_context,"[{'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 1, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}, {'source': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf', 'page': 2, 'filename': 'data/pdfs/International Services _ Curricular Practical Training (CPT).pdf'}]",True
What practical experience opportunities are available and how does the program incorporate industry trends and technologies?,"['Pre-Application Phase\n\nUnderstanding Program Fit and Outcomes\n\nQ01: ""How do I know if the Master of Business Analytics and Information Systems program is right for me?""\n\nA01: ""This program is ideal for individuals who have a strong interest in data analysis, technology, and business decision-making. If you\'re passionate about leveraging data to solve complex business problems and drive strategic decisions, this program can provide the skills and knowledge you need. We recommend reviewing our curriculum and speaking with current students or alumni to gauge how well the program aligns with your career goals.""\n\nQ02: ""What specializations are available in the Master of Business Analytics and Information Systems program?""\n\nA1: ""Our program offers several specializations, including Data Analytics, Information Systems Management, Business Intelligence, and more. Each path is designed to equip students with in-demand skills and knowledge relevant to the current job market.""\n\nApplication Strategy\n\nQ01: ""What can I do to strengthen my application?""\n\nA01: ""To strengthen your application, focus on highlighting your quantitative and analytical skills, any relevant work experience, and your passion for the field of business analytics. Letters of recommendation should come from individuals who can speak to your academic and professional abilities. A well-crafted statement of purpose that clearly articulates your career goals and how the program can help you achieve them is also crucial.""\n\nQ02: ""What are the prerequisites for applying to this program?""\n\nA02: ""Applicants are expected to have a bachelor\'s degree from an accredited institution, a fundamental understanding of statistics and computer programming, and a competitive GPA. Additional requirements include letters of recommendation, a statement of purpose, and a resume.""\n\nQ03: ""How can I apply as an international student?""\n\nA03: ""International students can apply through our online application portal. You\'ll need to submit your academic transcripts, proof of English language proficiency (TOEFL/IELTS), financial support documents, and a copy of your passport, among other requirements.""\n\nProgram Differentiators\n\n\n\nQ01: ""What sets your Master of Business Analytics and Information Systems program apart from others?""\n\nA01: ""Our program stands out due to its strong emphasis on practical, hands-on experience, its integration with the latest technologies and industry practices, and the extensive network of alumni and industry partners. Additionally, our faculty includes leading experts in business analytics and information systems, who bring real-world insights and research into the classroom.""\n\nFinancial Planning\n\nQ01: ""What kind of financial aid is available for students?""\n\nA01: ""Our institution offers a variety of financial aid options for students, including scholarships, grants, work-study opportunities, and loans. We recommend prospective students apply for financial aid early to maximize their chances of receiving support. Our financial aid office is available to help you navigate the process and identify the best options for your situation.""\n\nPreparing for the Program\n\nQ01: ""How can I prepare academically for the program?""\n\nA01: ""To prepare academically, we recommend brushing up on your quantitative skills, particularly in statistics and mathematics. Familiarity with programming languages such as Python or R, and database management systems, will also be beneficial. Engaging in online courses or workshops that cover these areas can be a great way to prepare.""\n\nApplication Timing and Deadlines\n\nQ01: ""Is there an advantage to applying early to the program?""\n\nA01: ""Applying early can have several advantages, including receiving an earlier decision, having more time to plan for relocation and financing, and in some cases, being considered for early scholarship awards. We encourage applicants to submit their materials as soon as they are ready to take advantage of these benefits.""\n\nProgram Expectations\n\nQ01: ""What is expected from students in the Master of Business Analytics and Information Systems program?""\n\nA01: ""We expect our students to demonstrate a strong commitment to their studies, a willingness to engage in collaborative and individual projects, and an eagerness to learn and apply new concepts and technologies. Successful students typically possess strong analytical skills, effective communication abilities, and the capacity to think critically and solve complex problems.""\n\nApplication Process\n\n\n\nQ01: ""What documents do I need for the student visa application?""\n\nA01: ""You\'ll need a valid passport, the acceptance letter from our institution, proof of financial support, completed visa application forms, and a passport-sized photograph. Depending on your country, additional documents may be required.""\n\nQ02: ""Is there a deadline for applying to the Master\'s program?""\n\nA02: ""Yes, our application deadlines are as follows: Fall semester - May 1st, Spring semester - October 1st. We recommend applying early to ensure sufficient time for visa processing.""\n\nPost-Acceptance and Pre-Arrival\n\nQ01', ' global community that provides a platform for networking, mentorship, and professional growth. As a graduate, you\'ll have access to alumni events, webinars, and other resources to stay connected with your peers and the institution.""\n\nTechnical Requirements and Resources\n\nQ01: ""What are the computing requirements for the program?""\n\nA01: ""Our program requires students to have a laptop with specific hardware configurations to handle data analytics and business intelligence software efficiently. Recommended specifications include a modern multi-core processor, at least 16GB of RAM, and a solid-state drive (SSD). Detailed requirements are available on our program\'s website.""\n\nQ02: ""Are there any software licenses provided for students in this program?""\n\nA02: ""Yes, enrolled students receive access to various professional software tools and platforms necessary for coursework, including statistical analysis, data visualization, and business intelligence software, at no additional cost. This is part of our commitment to ensure students have the necessary resources for their studies.""\n\nAdjusting to a New Environment\n\nQ01: ""How does the university assist international students in adjusting to life in a new country?""\n\n\n\nA01: ""Our international student office offers a range of services designed to help you adjust, including cultural orientation sessions, social events, and workshops on local customs and lifestyle. We also have student mentors who can provide guidance and support as you navigate your new surroundings.""\n\nQ02: ""What kind of health services are available on campus?""\n\nA02: ""Our campus health center provides a range of medical services, including general consultations, mental health support, and emergency care. We also offer health insurance plans suitable for international students, ensuring you have access to comprehensive healthcare during your stay.""\n\nProgram Structure and Content\n\nQ01: ""Can students customize their curriculum within the Master\'s program?""\n\nA01: ""Absolutely. While there are core courses that all students must complete, our program offers elective courses allowing you to tailor your studies to your interests and career goals. Additionally, students can engage in independent study projects or research under faculty supervision for a more customized academic experience.""\n\nQ02: ""Is there an opportunity to study abroad or participate in international projects?""\n\nA02: ""Yes, our program includes opportunities for international study and collaboration through exchange programs, global consulting projects, and internships. These experiences are designed to enhance your global perspective and understanding of international business practices.""\n\nNetworking and Professional Development\n\nQ01: ""How does the program facilitate networking opportunities with industry professionals?""\n\nA01: ""Our program hosts regular networking events, guest lectures, and industry panels featuring alumni and professionals from the fields of business analytics and information systems. These events are excellent opportunities to build connections, gain insights into industry trends, and explore potential career paths.""\n\nQ02: ""Does the university offer career fairs or recruitment events for business analytics students?""\n\nA02: ""Yes, we organize career fairs and recruitment events specifically tailored to business analytics and information systems students. These events attract top employers in the industry looking to hire for internships and full-time positions. We also provide support in preparing for these events, including resume reviews and interview coaching.""\n\nSupport Systems\n\nQ01: ""What kind of academic support is available for students who may struggle with advanced coursework?""\n\n\n\nA01: ""We provide a comprehensive academic support system that includes tutoring services, study groups, and workshops on advanced topics in business analytics and information systems. Faculty members are also available for office hours to provide additional assistance and guidance.""\n\nQ02: ""Are there any mentorship programs available for new students?""\n\nA02: ""Yes, we offer a mentorship program that pairs new students with upperclassmen or alumni who can provide guidance, share their experiences, and offer advice on navigating both the academic and social aspects of the program. This program is designed to help new students transition smoothly into their graduate studies.""\n\nCertainly, Dr. Smith. Further expanding the range of inquiries, the following set of questions and answers delves into more specific and practical aspects that students might consider when applying for and participating in a Master of Business Analytics and Information Systems program.\n\nPractical Experience and Application\n\nQ01: ""Are there opportunities for practical experience within the program?""\n\nA01: ""Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience.""\n\nQ02: ""How does the program incorporate the latest industry trends and technologies?""\n\nA02: ""Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on']","Yes, our program strongly emphasizes practical experience. We offer hands-on projects, case studies, and capstone projects that simulate real-world business analytics scenarios. Additionally, students can participate in internships with our industry partners to gain valuable work experience. Our curriculum is continuously updated to reflect the latest trends and technologies in business analytics and information systems. We collaborate with industry leaders and alumni to ensure our courses include cutting-edge content, and we regularly host tech talks and workshops on industry trends and technologies.",multi_context,"[{'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}, {'source': 'data/docx/Generate Mock Questions.docx', 'filename': 'data/docx/Generate Mock Questions.docx'}]",True
What engineering challenges need to be addressed for practical applications of LLMs?,"['Retrieval-Augmented Generation for Large Language Models: A Survey\nYunfan Gao1,Yun Xiong2,Xinyu Gao2,Kangxiang Jia2,Jinliu Pan2,Yuxi Bi3,Yi\nDai1,Jiawei Sun1,Qianyu Guo4,Meng Wang3and Haofen Wang1,3∗\n1Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University\n2Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n3College of Design and Innovation, Tongji University\n4School of Computer Science, Fudan University\nAbstract\nLarge Language Models (LLMs) demonstrate\nsignificant capabilities but face challenges such\nas hallucination, outdated knowledge, and non-\ntransparent, untraceable reasoning processes.\nRetrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating\nknowledge from external databases. This enhances\nthe accuracy and credibility of the models, particu-\nlarly for knowledge-intensive tasks, and allows for\ncontinuous knowledge updates and integration of\ndomain-specific information. RAG synergistically\nmerges LLMs’ intrinsic knowledge with the vast,\ndynamic repositories of external databases. This\ncomprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms,\nencompassing the Naive RAG, the Advanced RAG,\nand the Modular RAG. It meticulously scrutinizes\nthe tripartite foundation of RAG frameworks,\nwhich includes the retrieval , the generation and\nthe augmentation techniques. The paper highlights\nthe state-of-the-art technologies embedded in\neach of these critical components, providing a\nprofound understanding of the advancements in\nRAG systems. Furthermore, this paper introduces\nthe metrics and benchmarks for assessing RAG\nmodels, along with the most up-to-date evaluation\nframework. In conclusion, the paper delineates\nprospective avenues for research, including the\nidentification of challenges, the expansion of\nmulti-modalities, and the progression of the RAG\ninfrastructure and its ecosystem.1.\n1 Introduction\nLarge language models (LLMs) such as the GPT se-\nries[Brown et al. , 2020, OpenAI, 2023 ]and the LLama se-\nries [Touvron et al. , 2023 ], along with other models like\nGemini [Google, 2023 ], have achieved remarkable suc-\ncess in natural language processing, demonstrating supe-\n∗Corresponding Author.Email:haofen.wang@tongji.edu.cn\n1Resources are available at https://github.com/Tongji-KGLLM/\nRAG-Surveyrior performance on various benchmarks including Super-\nGLUE [Wang et al. , 2019 ], MMLU [Hendrycks et al. , 2020 ],\nand BIG-bench [Srivastava et al. , 2022 ]. Despite these\nadvancements, LLMs exhibit notable limitations, par-\nticularly in handling domain-specific or highly special-\nized queries [Kandpal et al. , 2023 ]. A common issue is\nthe generation of incorrect information, or ”hallucina-\ntions” [Zhang et al. , 2023b ], especially when queries extend\nbeyond the model’s training data or necessitate up-to-date in-\nformation. These shortcomings underscore the impractical-\nity of deploying LLMs as black-box solutions in real-world\nproduction environments without additional safeguards. One\npromising approach to mitigate these limitations is Retrieval-\nAugmented Generation (RAG), which integrates external\ndata retrieval into the generative process, thereby enhancing\nthe model’s ability to provide accurate and relevant responses.\nRAG, introduced by Lewis et al. [Lewis et al. , 2020 ]in\nmid-2020, stands as a paradigm within the realm of LLMs,\nenhancing generative tasks. Specifically, RAG involves an\ninitial retrieval step where the LLMs query an external data\nsource to obtain relevant information before proceeding to an-\nswer questions or generate text. This process not only informs\nthe subsequent generation phase but also ensures that the re-\nsponses are grounded in retrieved evidence, thereby signif-\nicantly enhancing the accuracy and relevance of the output.\nThe dynamic retrieval of information from knowledge bases\nduring the inference phase allows RAG to address issues such\nas the generation of factually incorrect content, commonly\nreferred to as “hallucinations.” The integration of RAG into\nLLMs has seen rapid adoption and has become a pivotal tech-\nnology in refining the capabilities of chat', 'certain. Initial studies [Wang et al. , 2023b ]have begun to ad-\ndress this, yet the parameter count in RAG models still lags\nbehind that of LLMs. The possibility of an Inverse Scaling\nLaw9, where smaller models outperform larger ones, is par-\nticularly intriguing and merits further investigation.\nProduction-Ready RAG . RAG’s practicality and alignment\nwith engineering requirements have facilitated its adoption.\nHowever, enhancing retrieval efficiency, improving document\nrecall in large knowledge bases, and ensuring data secu-\nrity—such as preventing inadvertent disclosure of document\nsources or metadata by LLMs—are critical engineering chal-\nlenges that remain to be addressed [Alon et al. , 2022 ].\nModality Extension of RAG\nRAG has transcended its initial text-based question-\nanswering confines, embracing a diverse array of modal data.\nThis expansion has spawned innovative multimodal models\nthat integrate RAG concepts across various domains:\nImage . RA-CM3 [Yasunaga et al. , 2022 ]stands as a pio-\nneering multimodal model of both retrieving and generating\ntext and images. BLIP-2 [Liet al. , 2023a ]leverages frozen\nimage encoders alongside LLMs for efficient visual language\npre-training, enabling zero-shot image-to-text conversions.\nThe “Visualize Before You Write” method [Zhuet al. , 2022 ]\nemploys image generation to steer the LM’s text generation,\nshowing promise in open-ended text generation tasks.\nAudio and Video . The GSS method retrieves and stitches\ntogether audio clips to convert machine-translated data into\nspeech-translated data [Zhao et al. , 2022 ]. UEOP marks\na significant advancement in end-to-end automatic speech\nrecognition by incorporating external, offline strategies for\nvoice-to-text conversion [Chan et al. , 2023 ]. Additionally,\nKNN-based attention fusion leverages audio embeddings and\nsemantically related text embeddings to refine ASR, thereby\naccelerating domain adaptation. Vid2Seq augments language\nmodels with specialized temporal markers, facilitating the\nprediction of event boundaries and textual descriptions within\na unified output sequence [Yang et al. , 2023a ].\nCode . RBPS [Nashid et al. , 2023 ]excels in small-scale\nlearning tasks by retrieving code examples that align with de-\nvelopers’ objectives through encoding and frequency analy-\nsis. This approach has demonstrated efficacy in tasks such as\ntest assertion generation and program repair. For structured\nknowledge, the CoK method [Liet al. , 2023c ]first extracts\nfacts pertinent to the input query from a knowledge graph,\nthen integrates these facts as hints within the input, enhancing\nperformance in knowledge graph question-answering tasks.\n8.2 Ecosystem of RAG\nDownstream Tasks and Evaluation\nRAG has shown considerable promise in enriching language\nmodels with the capacity to handle intricate queries and pro-\nduce detailed responses by leveraging extensive knowledge\nbases. Empirical evidence suggests that RAG excels in a\nvariety of downstream tasks, including open-ended question\nanswering and fact verification. The integration of RAG not\nonly bolsters the precision and relevance of responses but also\ntheir diversity and depth.\n9https://github.com/inverse-scaling/prizeThe scalability and versatility of RAG across multiple do-\nmains warrant further investigation, particularly in special-\nized fields such as medicine, law, and education. In these ar-\neas, RAG could potentially reduce training costs and enhance\nperformance compared to traditional fine-tuning approaches\nin professional domain knowledge question answering.\nConcurrently, refining the evaluation framework for RAG\nis essential to maximize its efficacy and utility across different\ntasks. This entails the development of nuanced metrics and\nassessment tools that can gauge aspects such as contextual\nrelevance, creativity of content, and non-maleficence.\nFurthermore, improving the interpretability of RAG-driven\nmodels continues to be a key goal. Doing so would allow\nusers to understand the reasoning behind the responses gener-\nated by the model, thereby promoting trust and transparency\nin the use of RAG applications.\nTechnical Stack\nThe development of the RAG ecosystem is greatly impacted\nby the progression of its technical stack. Key tools like\nLangChain and LLamaIndex have quickly gained popularity\nwith the emergence of ChatGPT, providing extensive RAG-\nrelated APIs and becoming essential in the realm of LLMs.\nEmerging technical stacks, while not as feature-rich']","Enhancing retrieval efficiency, improving document recall in large knowledge bases, and ensuring data security—such as preventing inadvertent disclosure of document sources or metadata by LLMs—are critical engineering challenges that need to be addressed for practical applications of LLMs.",multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 0, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 19, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
What's the approach that combines external data retrieval with generative tasks in large language models to improve accuracy and relevance?,"['various question-answering tasks.\nIn essence, these inference-stage enhancements provide\nlightweight, cost-effective alternatives that leverage the ca-\npabilities of pre-trained models without necessitating further\ntraining. The principal advantage is maintaining static LLM\nparameters while supplying contextually relevant information\nto meet specific task demands. Nevertheless, this approach is\nnot without limitations, as it requires meticulous data pro-\ncessing and optimization, and is bound by the foundational\nmodel’s intrinsic capabilities. To address diverse task require-\nments effectively, this method is often paired with procedural\noptimization techniques such as step-wise reasoning, iterative\nretrieval, and adaptive retrieval strategies.\n6.2 Augmentation Source\nThe effectiveness of RAG models is heavily impacted by the\nselection of data sources for augmentation. Different levels of\nknowledge and dimensions require distinct processing tech-\nniques. They are categorized as unstructured data, structured\ndata, and content generated by LLMs. The technology tree\nof representative RAG research with different augmentation\naspects is depicted in Figure 5. The leaves, colored in three\ndifferent shades, represent enhancements using various types\nof data: unstructured data, structured data, and content gener-\nated by LLMs. The diagram clearly shows that initially, aug-\nmentation was mainly achieved through unstructured data,\nsuch as pure text. This approach later expanded to include\nthe use of structured data (e.g. knowledge graph) for further\nimprovement. More recently, there has been a growing trend\nin research that utilizes content generated by the LLMs them-\nselves for retrieval and augmentation purposes.\nAugmented with Unstructured Data\nUnstructured text, is gathered from corpora, such as prompt\ndata for fine-tuning large models [Cheng et al. , 2023a ]and\ncross-lingual data [Liet al. , 2023b ]. Retrieval units vary from\ntokens (e.g., kNN-LM [Khandelwal et al. , 2019 ]) to phrases\n(e.g., NPM, COG [Leeet al. , 2020, Lan et al. , 2022 ]) and\ndocument paragraphs, with finer granularities offering pre-\ncision at the cost of increased retrieval complexity.\nFLARE [Jiang et al. , 2023b ]introduces an active re-\ntrieval approach, triggered by the LM’s generation of low-\nprobability words. It creates a temporary sentence for doc-\nument retrieval, then regenerates the sentence with the re-\ntrieved context to predict subsequent sentences. RETRO uses\nthe previous chunk to retrieve the nearest neighbor at the\nchunk level, combined with the previous chunk’s context, it\nguides the generation of the next chunk. To preserve causal-\nity, the generation of the next block Cionly utilizes the near-\nest neighbor of the previous block N(Ci−1)and not N(Ci).\nAugmented with Structured Data\nStructured data, such as knowledge graphs (KGs), pro-\nvide high-quality context and mitigate model hallucina-\ntions. RET-LLMs [Modarressi et al. , 2023 ]constructs a\nknowledge graph memory from past dialogues for future ref-\nerence. SUGRE [Kang et al. , 2023 ]employs Graph Neu-\nral Networks (GNNs) to encode relevant KG subgraphs,\nensuring consistency between retrieved facts and gener-\nated text through multi-modal contrastive learning. Knowl-edGPT [Wang et al. , 2023d ]generates KB search queries and\nstores knowledge in a personalized base, enhancing the RAG\nmodel’s knowledge richness and contextuality.\nLLMs-Generated Content in RAG\nAddressing the limitations of external auxiliary information\nin RAG, some research has focused on exploiting LLMs’ in-\nternal knowledge. SKR [Wang et al. , 2023e ]classifies ques-\ntions as known or unknown, applying retrieval enhancement\nselectively. GenRead [Yuet al. , 2022 ]replaces the retriever\nwith an LLM generator, finding that LLM-generated con-\ntexts often contain more accurate answers due to better align-\nment with the pre-training objectives of causal language mod-\neling. Selfmem [Cheng et al. , 2023b ]iteratively creates an\nunbounded memory pool with a retrieval-enhanced genera-\ntor, using a memory selector to choose outputs that serve as\ndual problems to the original question, thus self-enhancing\nthe generative model.\nThese methodologies', 'Retrieval-Augmented Generation for Large Language Models: A Survey\nYunfan Gao1,Yun Xiong2,Xinyu Gao2,Kangxiang Jia2,Jinliu Pan2,Yuxi Bi3,Yi\nDai1,Jiawei Sun1,Qianyu Guo4,Meng Wang3and Haofen Wang1,3∗\n1Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University\n2Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n3College of Design and Innovation, Tongji University\n4School of Computer Science, Fudan University\nAbstract\nLarge Language Models (LLMs) demonstrate\nsignificant capabilities but face challenges such\nas hallucination, outdated knowledge, and non-\ntransparent, untraceable reasoning processes.\nRetrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating\nknowledge from external databases. This enhances\nthe accuracy and credibility of the models, particu-\nlarly for knowledge-intensive tasks, and allows for\ncontinuous knowledge updates and integration of\ndomain-specific information. RAG synergistically\nmerges LLMs’ intrinsic knowledge with the vast,\ndynamic repositories of external databases. This\ncomprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms,\nencompassing the Naive RAG, the Advanced RAG,\nand the Modular RAG. It meticulously scrutinizes\nthe tripartite foundation of RAG frameworks,\nwhich includes the retrieval , the generation and\nthe augmentation techniques. The paper highlights\nthe state-of-the-art technologies embedded in\neach of these critical components, providing a\nprofound understanding of the advancements in\nRAG systems. Furthermore, this paper introduces\nthe metrics and benchmarks for assessing RAG\nmodels, along with the most up-to-date evaluation\nframework. In conclusion, the paper delineates\nprospective avenues for research, including the\nidentification of challenges, the expansion of\nmulti-modalities, and the progression of the RAG\ninfrastructure and its ecosystem.1.\n1 Introduction\nLarge language models (LLMs) such as the GPT se-\nries[Brown et al. , 2020, OpenAI, 2023 ]and the LLama se-\nries [Touvron et al. , 2023 ], along with other models like\nGemini [Google, 2023 ], have achieved remarkable suc-\ncess in natural language processing, demonstrating supe-\n∗Corresponding Author.Email:haofen.wang@tongji.edu.cn\n1Resources are available at https://github.com/Tongji-KGLLM/\nRAG-Surveyrior performance on various benchmarks including Super-\nGLUE [Wang et al. , 2019 ], MMLU [Hendrycks et al. , 2020 ],\nand BIG-bench [Srivastava et al. , 2022 ]. Despite these\nadvancements, LLMs exhibit notable limitations, par-\nticularly in handling domain-specific or highly special-\nized queries [Kandpal et al. , 2023 ]. A common issue is\nthe generation of incorrect information, or ”hallucina-\ntions” [Zhang et al. , 2023b ], especially when queries extend\nbeyond the model’s training data or necessitate up-to-date in-\nformation. These shortcomings underscore the impractical-\nity of deploying LLMs as black-box solutions in real-world\nproduction environments without additional safeguards. One\npromising approach to mitigate these limitations is Retrieval-\nAugmented Generation (RAG), which integrates external\ndata retrieval into the generative process, thereby enhancing\nthe model’s ability to provide accurate and relevant responses.\nRAG, introduced by Lewis et al. [Lewis et al. , 2020 ]in\nmid-2020, stands as a paradigm within the realm of LLMs,\nenhancing generative tasks. Specifically, RAG involves an\ninitial retrieval step where the LLMs query an external data\nsource to obtain relevant information before proceeding to an-\nswer questions or generate text. This process not only informs\nthe subsequent generation phase but also ensures that the re-\nsponses are grounded in retrieved evidence, thereby signif-\nicantly enhancing the accuracy and relevance of the output.\nThe dynamic retrieval of information from knowledge bases\nduring the inference phase allows RAG to address issues such\nas the generation of factually incorrect content, commonly\nreferred to as “hallucinations.” The integration of RAG into\nLLMs has seen rapid adoption and has become a pivotal tech-\nnology in refining the capabilities of chat']",Retrieval-Augmented Generation (RAG) is the approach that combines external data retrieval with generative tasks in large language models to improve accuracy and relevance.,multi_context,"[{'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 13, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}, {'source': 'data/pdfs/Gao_RAG_2024.pdf', 'page': 0, 'filename': 'data/pdfs/Gao_RAG_2024.pdf'}]",True
